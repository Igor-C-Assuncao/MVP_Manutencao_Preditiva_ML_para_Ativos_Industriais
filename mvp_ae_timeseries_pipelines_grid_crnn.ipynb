{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Igor-C-Assuncao/MVP_Series_temporais_NN/blob/main/mvp_ae_timeseries_pipelines_grid_crnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "115b6bb6",
      "metadata": {
        "id": "115b6bb6"
      },
      "source": [
        "# MVP – Pipelines + Grid Search (Baseline + CNN-AE + TCN-AE + CNN-RNN-CNN)\n",
        "\n",
        "### Checklist\n",
        "- [ ] GPU ativada (T4/L4 no Colab)\n",
        "- [ ] Dados disponíveis (carregados em `X_full` e opcional `y_full`)\n",
        "- [ ] Ajustei `WINDOW_SIZE`, `STRIDE`, `FOLDS` e `HAS_LABELS`\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U skorch"
      ],
      "metadata": {
        "id": "i66Z0y6K8BvE"
      },
      "id": "i66Z0y6K8BvE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configs rápidas (ajuste aqui)\n",
        "WINDOW_SIZE = 5\n",
        "STRIDE = 1\n",
        "FOLDS = 10\n",
        "HAS_LABELS = True  # True se você tiver y_full (0/1) por timestep\n",
        "THRESHOLD_Q = 0.995\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS_MAX = 100\n",
        "PATIENCE = 8\n",
        "LR_DEFAULT = 1e-3\n",
        "SCALER = \"robust\"  # 'robust' | 'standard'\n"
      ],
      "metadata": {
        "id": "pU65PRGLFpoC"
      },
      "id": "pU65PRGLFpoC",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "da305678",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da305678",
        "outputId": "4779bf12-c1bc-4b44-c6dc-d10d0afd9547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3915311074.py:10: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ziya07/industrial-iot-fault-detection-dataset?dataset_version_number=1&file_name=industrial_fault_detection_data_1000.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113k/113k [00:00<00:00, 865kB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape do dataframe: (1000, 7)\n",
            "Colunas: ['Timestamp', 'Vibration (mm/s)', 'Temperature (°C)', 'Pressure (bar)', 'RMS Vibration', 'Mean Temp', 'Fault Label']\n",
            "Primeiros 5 registros:\n",
            "             Timestamp  Vibration (mm/s)  Temperature (°C)  Pressure (bar)  \\\n",
            "0  2023-03-10 00:00:00          0.437086         64.810634        7.785117   \n",
            "1  2023-03-10 00:01:00          0.955643         93.352076        7.740936   \n",
            "2  2023-03-10 00:02:00          0.758795        119.835667        9.718764   \n",
            "3  2023-03-10 00:03:00          0.638793        108.577991        7.748639   \n",
            "4  2023-03-10 00:04:00          0.240417        114.524892        7.815849   \n",
            "\n",
            "   RMS Vibration  Mean Temp  Fault Label  \n",
            "0       0.601657  90.561384            1  \n",
            "1       0.601657  90.561384            1  \n",
            "2       0.601657  90.561384            0  \n",
            "3       0.601657  90.561384            1  \n",
            "4       0.601657  90.561384            0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Caminho do arquivo dentro do dataset Kaggle\n",
        "file_path = \"industrial_fault_detection_data_1000.csv\"\n",
        "\n",
        "# Carregar a base\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"ziya07/industrial-iot-fault-detection-dataset\",\n",
        "    file_path,\n",
        ")\n",
        "\n",
        "print(\"Shape do dataframe:\", df.shape)\n",
        "print(\"Colunas:\", df.columns.tolist())\n",
        "print(\"Primeiros 5 registros:\")\n",
        "print(df.head())\n",
        "\n",
        "df = df.drop(columns=['Timestamp'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " ## --- Separação em features (X) e rótulos (y) ---\n",
        "\n",
        "\n",
        "target_col = \"Fault Label\"\n",
        "if target_col in df.columns:\n",
        "   y_full = df[target_col].values.astype(np.int64)\n",
        "   X_full = df.drop(columns=[target_col]).values.astype(np.float32)\n",
        "\n",
        "else:\n",
        "    y_full = None\n",
        "    X_full = df.values.astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "multiclass = (len(np.unique(y_full)) > 2) if (HAS_LABELS and y_full is not None) else False\n",
        "print(\"HAS_LABELS:\", HAS_LABELS, \"| multiclass:\", multiclass)\n",
        "\n",
        "# Se quiser forçar binarização mesmo sendo multiclass (0 vs {1,2,3})\n",
        "USE_ONE_VS_ALL = False  # mude para True se quiser tornar 0/1\n",
        "y_full_bin = None\n",
        "if multiclass and USE_ONE_VS_ALL:\n",
        "    # 0 = normal; 1 = qualquer falha 1/2/3\n",
        "    y_full_bin = (y_full != 0).astype(np.int64)\n",
        "\n",
        "\n",
        "print(\"X_full shape:\", X_full.shape)\n",
        "print(\"y_full shape:\", None if y_full is None else y_full.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TTXt5GqFvSQ",
        "outputId": "e385fd0e-1dc6-44ec-f5e1-abe774f8f7e0"
      },
      "id": "8TTXt5GqFvSQ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HAS_LABELS: True | multiclass: True\n",
            "X_full shape: (1000, 5)\n",
            "y_full shape: (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c0e0ac6",
      "metadata": {
        "id": "4c0e0ac6"
      },
      "source": [
        "## Célula 1 — Funções necessárias para os modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e3f7335c",
      "metadata": {
        "id": "e3f7335c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn import metrics\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def simple_impute(X):\n",
        "    \"\"\"Imputação simples: forward-fill e mediana para inícios faltantes.\"\"\"\n",
        "    X = np.asarray(X).copy()\n",
        "    mask = np.isnan(X)\n",
        "    if mask.any():\n",
        "        for j in range(X.shape[1]):\n",
        "            col = X[:, j]\n",
        "            # forward-fill\n",
        "            last = np.nan\n",
        "            for i in range(len(col)):\n",
        "                if np.isnan(col[i]):\n",
        "                    col[i] = last\n",
        "                else:\n",
        "                    last = col[i]\n",
        "            # início NaN -> mediana\n",
        "            if np.isnan(col[0]):\n",
        "                med = np.nanmedian(col)\n",
        "                col[np.isnan(col)] = 0.0 if np.isnan(med) else med\n",
        "            X[:, j] = col\n",
        "    return X\n",
        "\n",
        "def make_windows(X_array, y_array=None, T=128, stride=16):\n",
        "    \"\"\"(T_total,F) -> (N,T,F) e opcional (N,) com regra 'max' na janela.\"\"\"\n",
        "    X_array = np.asarray(X_array)\n",
        "    T_total, F = X_array.shape\n",
        "    idxs = list(range(0, T_total - T + 1, stride))\n",
        "    X_win = np.stack([X_array[i:i+T, :] for i in idxs], axis=0).astype(np.float32)\n",
        "    if y_array is None:\n",
        "        return X_win, None\n",
        "    y_array = np.asarray(y_array)\n",
        "    y_win = np.array([y_array[i:i+T].max() for i in idxs]).astype(np.int64)\n",
        "    return X_win, y_win\n",
        "\n",
        "def mae_loss(x, y):\n",
        "    return torch.mean(torch.abs(x - y))\n",
        "\n",
        "class HuberLoss(nn.Module):\n",
        "    def __init__(self, delta=1.0):\n",
        "        super().__init__(); self.delta = delta\n",
        "    def forward(self, pred, target):\n",
        "        diff = torch.abs(pred - target)\n",
        "        mask = (diff <= self.delta).float()\n",
        "        return torch.mean(0.5*(diff**2)*mask + (self.delta*diff - 0.5*self.delta**2)*(1-mask))\n",
        "\n",
        "def reconstruct_errors(model, X_win, loss_kind=\"huber\"):\n",
        "    \"\"\"Erro por janela (MAE) usando o modelo dado.\"\"\"\n",
        "    model.eval()\n",
        "    xs = torch.tensor(X_win, dtype=torch.float32, device=DEVICE)\n",
        "    with torch.no_grad():\n",
        "        y = model(xs)\n",
        "        err = torch.mean(torch.abs(y - xs), dim=(1,2)).detach().cpu().numpy()\n",
        "    return err\n",
        "\n",
        "def calibrate_threshold(errs, q=0.995):\n",
        "    return float(np.quantile(errs, q))\n",
        "\n",
        "def get_scaler(name):\n",
        "    return RobustScaler() if name == \"robust\" else StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6720ba8f",
      "metadata": {
        "id": "6720ba8f"
      },
      "source": [
        "## Célula 2 — Classes dos modelos (Baseline + CNN-AE + TCN-AE + CNN-RNN-CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e50f0760",
      "metadata": {
        "id": "e50f0760"
      },
      "outputs": [],
      "source": [
        "def _act(name):\n",
        "    return nn.GELU() if str(name).lower()==\"gelu\" else nn.ReLU()\n",
        "\n",
        "class CNN_AE(nn.Module):\n",
        "    \"\"\"Modelo 1: CNN Autoencoder com stride e upsample.\"\"\"\n",
        "    def __init__(self, n_features, filters=(32,64,128), kernel_size=5, dropout=0.1, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        act = _act(activation)\n",
        "        enc = []; in_ch = n_features\n",
        "        for f in filters:\n",
        "            enc += [nn.Conv1d(in_ch, f, kernel_size, stride=2, padding=kernel_size//2),\n",
        "                    nn.BatchNorm1d(f), act, nn.Dropout(dropout)]\n",
        "            in_ch = f\n",
        "        self.encoder = nn.Sequential(*enc)\n",
        "        bottleneck = max(8, in_ch//2)\n",
        "        self.bottleneck = nn.Conv1d(in_ch, bottleneck, 1)\n",
        "        dec = []; chs = list(filters)[::-1]; in_ch = bottleneck\n",
        "        for f in chs:\n",
        "            dec += [nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                    nn.Conv1d(in_ch, f, kernel_size, padding=kernel_size//2),\n",
        "                    nn.BatchNorm1d(f), act]\n",
        "            in_ch = f\n",
        "        self.decoder = nn.Sequential(*dec)\n",
        "        self.out = nn.Conv1d(in_ch, n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (N,T,F) -> conv1d espera (N,F,T)\n",
        "        x = x.transpose(1,2)\n",
        "        z = self.encoder(x)\n",
        "        z = self.bottleneck(z)\n",
        "        y = self.decoder(z)\n",
        "        y = self.out(y)\n",
        "        y = y.transpose(1,2)\n",
        "        if y.shape[1] != x.shape[2]:\n",
        "            T_in = x.shape[2]; T_out = y.shape[1]\n",
        "            if T_out > T_in: y = y[:, :T_in, :]\n",
        "            else: y = nn.functional.pad(y, (0,0,0,T_in-T_out))\n",
        "        return y\n",
        "\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k, d=1, causal=True):\n",
        "        super().__init__(); self.causal=causal; self.pad=(k-1)*d if causal else (k//2)*d\n",
        "        self.conv = nn.Conv1d(in_ch, out_ch, k, dilation=d, padding=0 if causal else self.pad)\n",
        "    def forward(self, x):\n",
        "        if self.causal: x = nn.functional.pad(x, (self.pad,0))\n",
        "        return self.conv(x)\n",
        "\n",
        "class TCNBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, k=3, d=1, dropout=0.1, activation=\"gelu\", causal=True):\n",
        "        super().__init__(); act = _act(activation)\n",
        "        self.c1 = CausalConv1d(in_ch, out_ch, k, d, causal); self.b1 = nn.BatchNorm1d(out_ch)\n",
        "        self.a1 = act; self.do = nn.Dropout(dropout)\n",
        "        self.c2 = CausalConv1d(out_ch, out_ch, k, d, causal); self.b2 = nn.BatchNorm1d(out_ch)\n",
        "        self.skip = nn.Conv1d(in_ch, out_ch, 1) if in_ch!=out_ch else nn.Identity()\n",
        "        self.a_out = act\n",
        "    def forward(self, x):\n",
        "        r = x\n",
        "        y = self.a1(self.b1(self.c1(x))); y = self.do(y)\n",
        "        y = self.b2(self.c2(y))\n",
        "        r = self.skip(r)\n",
        "        return self.a_out(y + r)\n",
        "\n",
        "class TCN_AE(nn.Module):\n",
        "    \"\"\"Modelo 2: TCN Autoencoder com dilatações e residual.\"\"\"\n",
        "    def __init__(self, n_features, filters=(32,64), kernel_size=3, dilations=(1,2,4,8), dropout=0.1, activation=\"gelu\", causal=True):\n",
        "        super().__init__()\n",
        "        blocks = []; in_ch = n_features\n",
        "        for f in filters:\n",
        "            for d in dilations:\n",
        "                blocks.append(TCNBlock(in_ch, f, kernel_size, d, dropout, activation, causal))\n",
        "                in_ch = f\n",
        "        self.encoder = nn.Sequential(*blocks)\n",
        "        bottleneck = max(8, in_ch//2)\n",
        "        self.bottleneck = nn.Conv1d(in_ch, bottleneck, 1)\n",
        "        dec = []; chs = list(filters)[::-1]; in_ch = bottleneck\n",
        "        for f in chs:\n",
        "            dec += [nn.Conv1d(in_ch, f, kernel_size, padding=kernel_size//2),\n",
        "                    nn.BatchNorm1d(f), _act(activation), nn.Dropout(dropout)]\n",
        "            in_ch = f\n",
        "        self.decoder = nn.Sequential(*dec)\n",
        "        self.out = nn.Conv1d(in_ch, n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1,2)\n",
        "        z = self.encoder(x); z = self.bottleneck(z)\n",
        "        y = self.decoder(z); y = self.out(y)\n",
        "        return y.transpose(1,2)\n",
        "\n",
        "class CNN_RNN_CNN_AE(nn.Module):\n",
        "    \"\"\"Modelo 3: CNN -> (GRU/LSTM) -> CNN Autoencoder.\"\"\"\n",
        "    def __init__(self, n_features, filters=(32,64), kernel_size=3, rnn_type=\"gru\", rnn_units=64, dropout=0.1, activation=\"gelu\"):\n",
        "        super().__init__()\n",
        "        act = _act(activation)\n",
        "        # Encoder conv\n",
        "        enc = []; in_ch = n_features\n",
        "        for f in filters:\n",
        "            enc += [nn.Conv1d(in_ch, f, kernel_size, padding=kernel_size//2),\n",
        "                    nn.BatchNorm1d(f), act, nn.Dropout(dropout)]\n",
        "            in_ch = f\n",
        "        self.encoder = nn.Sequential(*enc)\n",
        "        # RNN\n",
        "        self.rnn_type = rnn_type.lower()\n",
        "        if self.rnn_type == \"lstm\":\n",
        "            self.rnn = nn.LSTM(input_size=in_ch, hidden_size=rnn_units, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.GRU(input_size=in_ch, hidden_size=rnn_units, batch_first=True)\n",
        "        self.proj = nn.Linear(rnn_units, rnn_units)\n",
        "        # Decoder conv\n",
        "        dec = []; in_ch = rnn_units\n",
        "        for f in reversed(filters):\n",
        "            dec += [nn.Conv1d(in_ch, f, kernel_size, padding=kernel_size//2),\n",
        "                    nn.BatchNorm1d(f), act]\n",
        "            in_ch = f\n",
        "        self.decoder = nn.Sequential(*dec)\n",
        "        self.out = nn.Conv1d(in_ch, n_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (N,T,F)\n",
        "        xc = x.transpose(1,2)     # (N,F,T)\n",
        "        feat = self.encoder(xc)   # (N,C,T)\n",
        "        ft = feat.transpose(1,2)  # (N,T,C)\n",
        "        seq, _ = self.rnn(ft)     # (N,T,U)\n",
        "        seq = self.proj(seq)\n",
        "        z = seq.transpose(1,2)    # (N,U,T)\n",
        "        y = self.decoder(z)       # (N,C',T)\n",
        "        y = self.out(y).transpose(1,2)  # (N,T,F)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d002afa",
      "metadata": {
        "id": "7d002afa"
      },
      "source": [
        "## Célula 3 — Pipelines de cada modelo (PCA, CNN-AE, TCN-AE, CNN-RNN-CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f1c38068",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1c38068",
        "outputId": "67d7f940-a692-489b-ba6b-cdbb6f5130c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipelines prontos: pca_pipeline, cnn_ae_pipeline, tcn_ae_pipeline, crnn_ae_pipeline\n"
          ]
        }
      ],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "class ImputerTransformer(TransformerMixin, BaseEstimator):\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X): return simple_impute(X)\n",
        "\n",
        "class ScalerTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, kind=\"robust\"): self.kind = kind\n",
        "    def fit(self, X, y=None):\n",
        "        self.scaler_ = RobustScaler() if self.kind==\"robust\" else StandardScaler()\n",
        "        self.scaler_.fit(X)\n",
        "        return self\n",
        "    def transform(self, X): return self.scaler_.transform(X)\n",
        "\n",
        "class WindowizerTransformer(TransformerMixin, BaseEstimator):\n",
        "    def __init__(self, window_size=128, stride=16): self.window_size=window_size; self.stride=stride\n",
        "    def fit(self, X, y=None): return self\n",
        "    def transform(self, X):\n",
        "        Xw, _ = make_windows(X, None, T=self.window_size, stride=self.stride)\n",
        "        return Xw\n",
        "\n",
        "# PCA Pipeline\n",
        "pca_pipeline = Pipeline([\n",
        "    (\"impute\", ImputerTransformer()),\n",
        "    (\"scale\", ScalerTransformer(kind=SCALER)),\n",
        "    (\"window\", WindowizerTransformer(window_size=WINDOW_SIZE, stride=STRIDE)),\n",
        "])\n",
        "\n",
        "# skorch wrappers\n",
        "try:\n",
        "    from skorch import NeuralNetRegressor\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Instale skorch no Colab: !pip install -U skorch\") from e\n",
        "\n",
        "def make_cnn_ae_net(n_features, filters=(32,64,128), kernel_size=5, dropout=0.1, activation=\"relu\", lr=1e-3):\n",
        "    module = CNN_AE\n",
        "    net = NeuralNetRegressor(module, module__n_features=n_features, criterion=nn.SmoothL1Loss, optimizer=torch.optim.Adam,\n",
        "                             lr=lr, max_epochs=EPOCHS_MAX, batch_size=BATCH_SIZE,\n",
        "                             train_split=None, device=DEVICE, iterator_train__shuffle=True)\n",
        "    return net\n",
        "\n",
        "def make_tcn_ae_net(n_features, filters=(32,64), kernel_size=3, dilations=(1,2,4,8), dropout=0.1, activation=\"gelu\", lr=1e-3):\n",
        "    module = TCN_AE\n",
        "    net = NeuralNetRegressor(module, module__n_features=n_features, criterion=nn.SmoothL1Loss, optimizer=torch.optim.Adam,\n",
        "                             lr=lr, max_epochs=EPOCHS_MAX, batch_size=BATCH_SIZE,\n",
        "                             train_split=None, device=DEVICE, iterator_train__shuffle=True)\n",
        "    return net\n",
        "\n",
        "def make_crnn_ae_net(n_features, filters=(32,64), kernel_size=3, rnn_type=\"gru\", rnn_units=64, dropout=0.1, activation=\"gelu\", lr=1e-3):\n",
        "    module = CNN_RNN_CNN_AE\n",
        "    net = NeuralNetRegressor(module, module__n_features=n_features, criterion=nn.SmoothL1Loss, optimizer=torch.optim.Adam,\n",
        "                             lr=lr, max_epochs=EPOCHS_MAX, batch_size=BATCH_SIZE,\n",
        "                             train_split=None, device=DEVICE, iterator_train__shuffle=True)\n",
        "    return net\n",
        "\n",
        "cnn_ae_pipeline = Pipeline([\n",
        "    (\"impute\", ImputerTransformer()),\n",
        "    (\"scale\", ScalerTransformer(kind=SCALER)),\n",
        "    (\"window\", WindowizerTransformer(window_size=WINDOW_SIZE, stride=STRIDE)),\n",
        "    (\"model\", make_cnn_ae_net(n_features=X_full.shape[1])),\n",
        "])\n",
        "\n",
        "tcn_ae_pipeline = Pipeline([\n",
        "    (\"impute\", ImputerTransformer()),\n",
        "    (\"scale\", ScalerTransformer(kind=SCALER)),\n",
        "    (\"window\", WindowizerTransformer(window_size=WINDOW_SIZE, stride=STRIDE)),\n",
        "    (\"model\", make_tcn_ae_net(n_features=X_full.shape[1])),\n",
        "])\n",
        "\n",
        "crnn_ae_pipeline = Pipeline([\n",
        "    (\"impute\", ImputerTransformer()),\n",
        "    (\"scale\", ScalerTransformer(kind=SCALER)),\n",
        "    (\"window\", WindowizerTransformer(window_size=WINDOW_SIZE, stride=STRIDE)),\n",
        "    (\"model\", make_crnn_ae_net(n_features=X_full.shape[1])),\n",
        "])\n",
        "\n",
        "print(\"Pipelines prontos: pca_pipeline, cnn_ae_pipeline, tcn_ae_pipeline, crnn_ae_pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94db21f1",
      "metadata": {
        "id": "94db21f1"
      },
      "source": [
        "## Célula 4 — Grid/Randomized Search com parte dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "285e9434",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "285e9434",
        "outputId": "b7a02d24-551a-41e7-a5c7-55b5e2c84e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1749\u001b[0m  0.3809\n",
            "      2        \u001b[36m0.1357\u001b[0m  0.0061\n",
            "      3        \u001b[36m0.1205\u001b[0m  0.0055\n",
            "      4        \u001b[36m0.1038\u001b[0m  0.0051\n",
            "      5        \u001b[36m0.0949\u001b[0m  0.0047\n",
            "      6        \u001b[36m0.0831\u001b[0m  0.0050\n",
            "      7        \u001b[36m0.0776\u001b[0m  0.0050\n",
            "      8        \u001b[36m0.0732\u001b[0m  0.0051\n",
            "      9        \u001b[36m0.0715\u001b[0m  0.0051\n",
            "     10        \u001b[36m0.0670\u001b[0m  0.0051\n",
            "     11        \u001b[36m0.0637\u001b[0m  0.0051\n",
            "     12        \u001b[36m0.0602\u001b[0m  0.0050\n",
            "     13        \u001b[36m0.0598\u001b[0m  0.0050\n",
            "     14        \u001b[36m0.0567\u001b[0m  0.0053\n",
            "     15        \u001b[36m0.0534\u001b[0m  0.0050\n",
            "     16        0.0541  0.0050\n",
            "     17        \u001b[36m0.0515\u001b[0m  0.0050\n",
            "     18        \u001b[36m0.0495\u001b[0m  0.0050\n",
            "     19        \u001b[36m0.0476\u001b[0m  0.0051\n",
            "     20        \u001b[36m0.0452\u001b[0m  0.0050\n",
            "     21        0.0457  0.0051\n",
            "     22        \u001b[36m0.0443\u001b[0m  0.0050\n",
            "     23        \u001b[36m0.0416\u001b[0m  0.0051\n",
            "     24        \u001b[36m0.0407\u001b[0m  0.0050\n",
            "     25        \u001b[36m0.0392\u001b[0m  0.0050\n",
            "     26        \u001b[36m0.0391\u001b[0m  0.0051\n",
            "     27        \u001b[36m0.0360\u001b[0m  0.0050\n",
            "     28        \u001b[36m0.0354\u001b[0m  0.0050\n",
            "     29        \u001b[36m0.0337\u001b[0m  0.0050\n",
            "     30        \u001b[36m0.0336\u001b[0m  0.0050\n",
            "     31        \u001b[36m0.0316\u001b[0m  0.0050\n",
            "     32        \u001b[36m0.0291\u001b[0m  0.0050\n",
            "     33        0.0323  0.0050\n",
            "     34        0.0294  0.0050\n",
            "     35        \u001b[36m0.0287\u001b[0m  0.0050\n",
            "     36        \u001b[36m0.0272\u001b[0m  0.0050\n",
            "     37        \u001b[36m0.0262\u001b[0m  0.0049\n",
            "     38        0.0264  0.0048\n",
            "     39        0.0262  0.0049\n",
            "     40        \u001b[36m0.0246\u001b[0m  0.0050\n",
            "     41        \u001b[36m0.0237\u001b[0m  0.0048\n",
            "     42        \u001b[36m0.0228\u001b[0m  0.0057\n",
            "     43        0.0237  0.0052\n",
            "     44        \u001b[36m0.0222\u001b[0m  0.0050\n",
            "     45        \u001b[36m0.0212\u001b[0m  0.0051\n",
            "     46        \u001b[36m0.0195\u001b[0m  0.0061\n",
            "     47        0.0201  0.0057\n",
            "     48        \u001b[36m0.0194\u001b[0m  0.0053\n",
            "     49        \u001b[36m0.0176\u001b[0m  0.0056\n",
            "     50        \u001b[36m0.0174\u001b[0m  0.0057\n",
            "     51        \u001b[36m0.0162\u001b[0m  0.0048\n",
            "     52        0.0172  0.0065\n",
            "     53        0.0164  0.0051\n",
            "     54        0.0168  0.0050\n",
            "     55        \u001b[36m0.0157\u001b[0m  0.0048\n",
            "     56        \u001b[36m0.0142\u001b[0m  0.0047\n",
            "     57        0.0148  0.0050\n",
            "     58        0.0150  0.0048\n",
            "     59        \u001b[36m0.0140\u001b[0m  0.0048\n",
            "     60        0.0148  0.0048\n",
            "     61        0.0148  0.0060\n",
            "     62        0.0144  0.0052\n",
            "     63        0.0144  0.0050\n",
            "     64        \u001b[36m0.0129\u001b[0m  0.0049\n",
            "     65        \u001b[36m0.0128\u001b[0m  0.0049\n",
            "     66        \u001b[36m0.0124\u001b[0m  0.0047\n",
            "     67        0.0125  0.0048\n",
            "     68        0.0127  0.0049\n",
            "     69        0.0127  0.0049\n",
            "     70        \u001b[36m0.0113\u001b[0m  0.0059\n",
            "     71        0.0119  0.0052\n",
            "     72        0.0123  0.0052\n",
            "     73        0.0122  0.0051\n",
            "     74        \u001b[36m0.0111\u001b[0m  0.0049\n",
            "     75        \u001b[36m0.0104\u001b[0m  0.0049\n",
            "     76        0.0110  0.0051\n",
            "     77        0.0107  0.0047\n",
            "     78        0.0109  0.0049\n",
            "     79        \u001b[36m0.0102\u001b[0m  0.0048\n",
            "     80        \u001b[36m0.0092\u001b[0m  0.0072\n",
            "     81        0.0114  0.0052\n",
            "     82        0.0111  0.0052\n",
            "     83        0.0095  0.0051\n",
            "     84        0.0099  0.0050\n",
            "     85        \u001b[36m0.0091\u001b[0m  0.0048\n",
            "     86        0.0093  0.0049\n",
            "     87        \u001b[36m0.0090\u001b[0m  0.0048\n",
            "     88        0.0093  0.0049\n",
            "     89        \u001b[36m0.0085\u001b[0m  0.0058\n",
            "     90        0.0086  0.0057\n",
            "     91        0.0094  0.0051\n",
            "     92        0.0088  0.0051\n",
            "     93        \u001b[36m0.0083\u001b[0m  0.0057\n",
            "     94        0.0086  0.0049\n",
            "     95        0.0087  0.0048\n",
            "     96        0.0085  0.0049\n",
            "     97        \u001b[36m0.0075\u001b[0m  0.0049\n",
            "     98        0.0083  0.0049\n",
            "     99        0.0077  0.0055\n",
            "    100        0.0090  0.0050\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.2014\u001b[0m  0.0396\n",
            "      2        \u001b[36m0.1360\u001b[0m  0.0095\n",
            "      3        \u001b[36m0.1081\u001b[0m  0.0092\n",
            "      4        \u001b[36m0.0955\u001b[0m  0.0092\n",
            "      5        \u001b[36m0.0870\u001b[0m  0.0090\n",
            "      6        \u001b[36m0.0820\u001b[0m  0.0112\n",
            "      7        \u001b[36m0.0785\u001b[0m  0.0089\n",
            "      8        \u001b[36m0.0753\u001b[0m  0.0096\n",
            "      9        \u001b[36m0.0707\u001b[0m  0.0090\n",
            "     10        \u001b[36m0.0685\u001b[0m  0.0096\n",
            "     11        \u001b[36m0.0652\u001b[0m  0.0090\n",
            "     12        \u001b[36m0.0619\u001b[0m  0.0090\n",
            "     13        \u001b[36m0.0601\u001b[0m  0.0095\n",
            "     14        \u001b[36m0.0562\u001b[0m  0.0104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     15        \u001b[36m0.0545\u001b[0m  0.0102\n",
            "     16        0.0545  0.0091\n",
            "     17        \u001b[36m0.0529\u001b[0m  0.0091\n",
            "     18        \u001b[36m0.0501\u001b[0m  0.0093\n",
            "     19        \u001b[36m0.0488\u001b[0m  0.0115\n",
            "     20        \u001b[36m0.0469\u001b[0m  0.0110\n",
            "     21        \u001b[36m0.0468\u001b[0m  0.0102\n",
            "     22        \u001b[36m0.0450\u001b[0m  0.0103\n",
            "     23        \u001b[36m0.0420\u001b[0m  0.0111\n",
            "     24        \u001b[36m0.0413\u001b[0m  0.0106\n",
            "     25        \u001b[36m0.0409\u001b[0m  0.0093\n",
            "     26        \u001b[36m0.0395\u001b[0m  0.0093\n",
            "     27        \u001b[36m0.0375\u001b[0m  0.0090\n",
            "     28        0.0376  0.0088\n",
            "     29        \u001b[36m0.0360\u001b[0m  0.0097\n",
            "     30        \u001b[36m0.0351\u001b[0m  0.0093\n",
            "     31        \u001b[36m0.0330\u001b[0m  0.0129\n",
            "     32        0.0333  0.0131\n",
            "     33        \u001b[36m0.0317\u001b[0m  0.0115\n",
            "     34        \u001b[36m0.0314\u001b[0m  0.0092\n",
            "     35        \u001b[36m0.0295\u001b[0m  0.0094\n",
            "     36        0.0301  0.0092\n",
            "     37        \u001b[36m0.0284\u001b[0m  0.0103\n",
            "     38        \u001b[36m0.0281\u001b[0m  0.0089\n",
            "     39        \u001b[36m0.0253\u001b[0m  0.0090\n",
            "     40        0.0259  0.0095\n",
            "     41        \u001b[36m0.0243\u001b[0m  0.0092\n",
            "     42        0.0250  0.0092\n",
            "     43        \u001b[36m0.0239\u001b[0m  0.0092\n",
            "     44        \u001b[36m0.0224\u001b[0m  0.0094\n",
            "     45        \u001b[36m0.0221\u001b[0m  0.0092\n",
            "     46        \u001b[36m0.0217\u001b[0m  0.0091\n",
            "     47        \u001b[36m0.0200\u001b[0m  0.0089\n",
            "     48        0.0211  0.0089\n",
            "     49        0.0209  0.0129\n",
            "     50        0.0203  0.0089\n",
            "     51        0.0202  0.0092\n",
            "     52        \u001b[36m0.0190\u001b[0m  0.0088\n",
            "     53        0.0196  0.0091\n",
            "     54        0.0194  0.0090\n",
            "     55        \u001b[36m0.0189\u001b[0m  0.0100\n",
            "     56        \u001b[36m0.0169\u001b[0m  0.0098\n",
            "     57        0.0187  0.0098\n",
            "     58        0.0191  0.0090\n",
            "     59        \u001b[36m0.0161\u001b[0m  0.0091\n",
            "     60        \u001b[36m0.0159\u001b[0m  0.0090\n",
            "     61        0.0168  0.0098\n",
            "     62        0.0164  0.0109\n",
            "     63        0.0169  0.0105\n",
            "     64        0.0164  0.0093\n",
            "     65        \u001b[36m0.0155\u001b[0m  0.0088\n",
            "     66        0.0161  0.0088\n",
            "     67        0.0155  0.0094\n",
            "     68        0.0162  0.0091\n",
            "     69        \u001b[36m0.0146\u001b[0m  0.0091\n",
            "     70        0.0148  0.0090\n",
            "     71        \u001b[36m0.0144\u001b[0m  0.0090\n",
            "     72        \u001b[36m0.0143\u001b[0m  0.0089\n",
            "     73        \u001b[36m0.0139\u001b[0m  0.0095\n",
            "     74        0.0158  0.0093\n",
            "     75        0.0142  0.0091\n",
            "     76        0.0147  0.0094\n",
            "     77        \u001b[36m0.0137\u001b[0m  0.0090\n",
            "     78        \u001b[36m0.0133\u001b[0m  0.0092\n",
            "     79        \u001b[36m0.0129\u001b[0m  0.0090\n",
            "     80        \u001b[36m0.0127\u001b[0m  0.0096\n",
            "     81        \u001b[36m0.0125\u001b[0m  0.0092\n",
            "     82        \u001b[36m0.0121\u001b[0m  0.0094\n",
            "     83        0.0133  0.0089\n",
            "     84        0.0138  0.0090\n",
            "     85        0.0130  0.0091\n",
            "     86        0.0125  0.0101\n",
            "     87        0.0122  0.0104\n",
            "     88        0.0127  0.0098\n",
            "     89        \u001b[36m0.0118\u001b[0m  0.0088\n",
            "     90        0.0121  0.0088\n",
            "     91        0.0128  0.0088\n",
            "     92        \u001b[36m0.0112\u001b[0m  0.0096\n",
            "     93        0.0122  0.0094\n",
            "     94        0.0129  0.0092\n",
            "     95        0.0121  0.0092\n",
            "     96        0.0114  0.0089\n",
            "     97        0.0117  0.0089\n",
            "     98        \u001b[36m0.0111\u001b[0m  0.0089\n",
            "     99        0.0121  0.0095\n",
            "    100        0.0121  0.0092\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1908\u001b[0m  0.0195\n",
            "      2        \u001b[36m0.1242\u001b[0m  0.0096\n",
            "      3        \u001b[36m0.0981\u001b[0m  0.0098\n",
            "      4        \u001b[36m0.0875\u001b[0m  0.0097\n",
            "      5        \u001b[36m0.0814\u001b[0m  0.0098\n",
            "      6        \u001b[36m0.0755\u001b[0m  0.0095\n",
            "      7        \u001b[36m0.0722\u001b[0m  0.0098\n",
            "      8        \u001b[36m0.0670\u001b[0m  0.0094\n",
            "      9        \u001b[36m0.0643\u001b[0m  0.0111\n",
            "     10        \u001b[36m0.0611\u001b[0m  0.0106\n",
            "     11        \u001b[36m0.0583\u001b[0m  0.0093\n",
            "     12        \u001b[36m0.0547\u001b[0m  0.0124\n",
            "     13        \u001b[36m0.0522\u001b[0m  0.0123\n",
            "     14        \u001b[36m0.0491\u001b[0m  0.0099\n",
            "     15        \u001b[36m0.0476\u001b[0m  0.0095\n",
            "     16        \u001b[36m0.0459\u001b[0m  0.0093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0442\u001b[0m  0.0104\n",
            "     18        \u001b[36m0.0407\u001b[0m  0.0100\n",
            "     19        \u001b[36m0.0397\u001b[0m  0.0105\n",
            "     20        \u001b[36m0.0384\u001b[0m  0.0101\n",
            "     21        \u001b[36m0.0362\u001b[0m  0.0094\n",
            "     22        \u001b[36m0.0343\u001b[0m  0.0097\n",
            "     23        \u001b[36m0.0329\u001b[0m  0.0107\n",
            "     24        \u001b[36m0.0315\u001b[0m  0.0098\n",
            "     25        \u001b[36m0.0305\u001b[0m  0.0096\n",
            "     26        \u001b[36m0.0287\u001b[0m  0.0104\n",
            "     27        \u001b[36m0.0284\u001b[0m  0.0122\n",
            "     28        \u001b[36m0.0271\u001b[0m  0.0149\n",
            "     29        \u001b[36m0.0258\u001b[0m  0.0140\n",
            "     30        \u001b[36m0.0248\u001b[0m  0.0110\n",
            "     31        \u001b[36m0.0235\u001b[0m  0.0094\n",
            "     32        \u001b[36m0.0225\u001b[0m  0.0116\n",
            "     33        \u001b[36m0.0222\u001b[0m  0.0102\n",
            "     34        \u001b[36m0.0211\u001b[0m  0.0097\n",
            "     35        \u001b[36m0.0207\u001b[0m  0.0095\n",
            "     36        \u001b[36m0.0195\u001b[0m  0.0095\n",
            "     37        0.0198  0.0093\n",
            "     38        \u001b[36m0.0183\u001b[0m  0.0101\n",
            "     39        \u001b[36m0.0180\u001b[0m  0.0095\n",
            "     40        0.0187  0.0098\n",
            "     41        \u001b[36m0.0168\u001b[0m  0.0095\n",
            "     42        0.0173  0.0095\n",
            "     43        \u001b[36m0.0165\u001b[0m  0.0096\n",
            "     44        \u001b[36m0.0158\u001b[0m  0.0103\n",
            "     45        \u001b[36m0.0158\u001b[0m  0.0098\n",
            "     46        \u001b[36m0.0157\u001b[0m  0.0094\n",
            "     47        \u001b[36m0.0147\u001b[0m  0.0095\n",
            "     48        \u001b[36m0.0145\u001b[0m  0.0096\n",
            "     49        0.0148  0.0102\n",
            "     50        \u001b[36m0.0135\u001b[0m  0.0098\n",
            "     51        0.0136  0.0098\n",
            "     52        0.0140  0.0099\n",
            "     53        \u001b[36m0.0134\u001b[0m  0.0098\n",
            "     54        \u001b[36m0.0127\u001b[0m  0.0095\n",
            "     55        0.0127  0.0096\n",
            "     56        \u001b[36m0.0121\u001b[0m  0.0118\n",
            "     57        0.0123  0.0111\n",
            "     58        0.0128  0.0099\n",
            "     59        \u001b[36m0.0119\u001b[0m  0.0096\n",
            "     60        0.0121  0.0094\n",
            "     61        \u001b[36m0.0118\u001b[0m  0.0094\n",
            "     62        \u001b[36m0.0114\u001b[0m  0.0093\n",
            "     63        \u001b[36m0.0114\u001b[0m  0.0101\n",
            "     64        \u001b[36m0.0105\u001b[0m  0.0097\n",
            "     65        0.0105  0.0095\n",
            "     66        0.0110  0.0093\n",
            "     67        0.0106  0.0093\n",
            "     68        \u001b[36m0.0102\u001b[0m  0.0102\n",
            "     69        0.0105  0.0119\n",
            "     70        \u001b[36m0.0100\u001b[0m  0.0098\n",
            "     71        0.0104  0.0098\n",
            "     72        0.0105  0.0094\n",
            "     73        0.0104  0.0097\n",
            "     74        \u001b[36m0.0100\u001b[0m  0.0095\n",
            "     75        0.0102  0.0093\n",
            "     76        0.0105  0.0094\n",
            "     77        \u001b[36m0.0100\u001b[0m  0.0107\n",
            "     78        \u001b[36m0.0098\u001b[0m  0.0097\n",
            "     79        \u001b[36m0.0093\u001b[0m  0.0101\n",
            "     80        0.0100  0.0105\n",
            "     81        0.0095  0.0094\n",
            "     82        0.0100  0.0095\n",
            "     83        0.0100  0.0097\n",
            "     84        \u001b[36m0.0092\u001b[0m  0.0098\n",
            "     85        0.0098  0.0093\n",
            "     86        0.0098  0.0094\n",
            "     87        \u001b[36m0.0092\u001b[0m  0.0093\n",
            "     88        0.0093  0.0104\n",
            "     89        0.0092  0.0099\n",
            "     90        \u001b[36m0.0085\u001b[0m  0.0096\n",
            "     91        0.0085  0.0093\n",
            "     92        0.0091  0.0094\n",
            "     93        0.0091  0.0104\n",
            "     94        \u001b[36m0.0084\u001b[0m  0.0106\n",
            "     95        \u001b[36m0.0083\u001b[0m  0.0098\n",
            "     96        0.0091  0.0098\n",
            "     97        0.0084  0.0103\n",
            "     98        0.0090  0.0093\n",
            "     99        0.0087  0.0092\n",
            "    100        0.0092  0.0106\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1763\u001b[0m  0.0216\n",
            "      2        \u001b[36m0.1360\u001b[0m  0.0076\n",
            "      3        \u001b[36m0.1165\u001b[0m  0.0062\n",
            "      4        \u001b[36m0.0981\u001b[0m  0.0064\n",
            "      5        \u001b[36m0.0976\u001b[0m  0.0057\n",
            "      6        \u001b[36m0.0879\u001b[0m  0.0058\n",
            "      7        \u001b[36m0.0862\u001b[0m  0.0057\n",
            "      8        \u001b[36m0.0836\u001b[0m  0.0058\n",
            "      9        \u001b[36m0.0806\u001b[0m  0.0059\n",
            "     10        \u001b[36m0.0764\u001b[0m  0.0069\n",
            "     11        \u001b[36m0.0755\u001b[0m  0.0062\n",
            "     12        \u001b[36m0.0723\u001b[0m  0.0061\n",
            "     13        \u001b[36m0.0702\u001b[0m  0.0057\n",
            "     14        \u001b[36m0.0693\u001b[0m  0.0059\n",
            "     15        \u001b[36m0.0667\u001b[0m  0.0057\n",
            "     16        \u001b[36m0.0657\u001b[0m  0.0059\n",
            "     17        \u001b[36m0.0628\u001b[0m  0.0060\n",
            "     18        \u001b[36m0.0603\u001b[0m  0.0088\n",
            "     19        \u001b[36m0.0591\u001b[0m  0.0062\n",
            "     20        \u001b[36m0.0584\u001b[0m  0.0065\n",
            "     21        \u001b[36m0.0557\u001b[0m  0.0057\n",
            "     22        0.0561  0.0057\n",
            "     23        \u001b[36m0.0512\u001b[0m  0.0054\n",
            "     24        \u001b[36m0.0507\u001b[0m  0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     25        \u001b[36m0.0495\u001b[0m  0.0073\n",
            "     26        \u001b[36m0.0477\u001b[0m  0.0080\n",
            "     27        \u001b[36m0.0454\u001b[0m  0.0062\n",
            "     28        0.0463  0.0059\n",
            "     29        \u001b[36m0.0444\u001b[0m  0.0058\n",
            "     30        \u001b[36m0.0411\u001b[0m  0.0059\n",
            "     31        0.0436  0.0060\n",
            "     32        0.0416  0.0106\n",
            "     33        \u001b[36m0.0405\u001b[0m  0.0095\n",
            "     34        \u001b[36m0.0380\u001b[0m  0.0090\n",
            "     35        0.0382  0.0062\n",
            "     36        \u001b[36m0.0367\u001b[0m  0.0067\n",
            "     37        \u001b[36m0.0350\u001b[0m  0.0060\n",
            "     38        \u001b[36m0.0335\u001b[0m  0.0061\n",
            "     39        0.0338  0.0058\n",
            "     40        \u001b[36m0.0313\u001b[0m  0.0057\n",
            "     41        \u001b[36m0.0310\u001b[0m  0.0058\n",
            "     42        \u001b[36m0.0309\u001b[0m  0.0057\n",
            "     43        \u001b[36m0.0287\u001b[0m  0.0058\n",
            "     44        0.0288  0.0073\n",
            "     45        \u001b[36m0.0284\u001b[0m  0.0060\n",
            "     46        \u001b[36m0.0281\u001b[0m  0.0061\n",
            "     47        \u001b[36m0.0267\u001b[0m  0.0061\n",
            "     48        \u001b[36m0.0248\u001b[0m  0.0058\n",
            "     49        0.0250  0.0057\n",
            "     50        \u001b[36m0.0236\u001b[0m  0.0057\n",
            "     51        \u001b[36m0.0216\u001b[0m  0.0057\n",
            "     52        0.0224  0.0056\n",
            "     53        0.0228  0.0077\n",
            "     54        0.0222  0.0065\n",
            "     55        \u001b[36m0.0211\u001b[0m  0.0060\n",
            "     56        \u001b[36m0.0199\u001b[0m  0.0057\n",
            "     57        0.0211  0.0057\n",
            "     58        \u001b[36m0.0189\u001b[0m  0.0056\n",
            "     59        0.0189  0.0058\n",
            "     60        \u001b[36m0.0185\u001b[0m  0.0059\n",
            "     61        0.0191  0.0073\n",
            "     62        0.0186  0.0061\n",
            "     63        \u001b[36m0.0158\u001b[0m  0.0061\n",
            "     64        0.0174  0.0057\n",
            "     65        0.0160  0.0057\n",
            "     66        0.0161  0.0058\n",
            "     67        \u001b[36m0.0148\u001b[0m  0.0057\n",
            "     68        \u001b[36m0.0148\u001b[0m  0.0057\n",
            "     69        \u001b[36m0.0136\u001b[0m  0.0075\n",
            "     70        0.0145  0.0067\n",
            "     71        0.0158  0.0063\n",
            "     72        0.0139  0.0063\n",
            "     73        \u001b[36m0.0125\u001b[0m  0.0071\n",
            "     74        \u001b[36m0.0125\u001b[0m  0.0069\n",
            "     75        \u001b[36m0.0123\u001b[0m  0.0066\n",
            "     76        0.0124  0.0059\n",
            "     77        0.0124  0.0062\n",
            "     78        0.0133  0.0060\n",
            "     79        \u001b[36m0.0114\u001b[0m  0.0061\n",
            "     80        0.0118  0.0061\n",
            "     81        0.0136  0.0057\n",
            "     82        0.0118  0.0057\n",
            "     83        \u001b[36m0.0111\u001b[0m  0.0056\n",
            "     84        \u001b[36m0.0099\u001b[0m  0.0056\n",
            "     85        0.0109  0.0075\n",
            "     86        0.0114  0.0066\n",
            "     87        \u001b[36m0.0094\u001b[0m  0.0066\n",
            "     88        0.0107  0.0060\n",
            "     89        0.0110  0.0057\n",
            "     90        0.0103  0.0058\n",
            "     91        \u001b[36m0.0091\u001b[0m  0.0057\n",
            "     92        0.0106  0.0057\n",
            "     93        0.0094  0.0072\n",
            "     94        0.0093  0.0062\n",
            "     95        0.0104  0.0063\n",
            "     96        \u001b[36m0.0082\u001b[0m  0.0057\n",
            "     97        0.0093  0.0057\n",
            "     98        0.0097  0.0058\n",
            "     99        0.0089  0.0057\n",
            "    100        0.0094  0.0058\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1835\u001b[0m  0.0406\n",
            "      2        \u001b[36m0.1284\u001b[0m  0.0129\n",
            "      3        \u001b[36m0.1085\u001b[0m  0.0115\n",
            "      4        \u001b[36m0.0993\u001b[0m  0.0114\n",
            "      5        \u001b[36m0.0964\u001b[0m  0.0107\n",
            "      6        \u001b[36m0.0925\u001b[0m  0.0109\n",
            "      7        \u001b[36m0.0883\u001b[0m  0.0113\n",
            "      8        \u001b[36m0.0854\u001b[0m  0.0110\n",
            "      9        \u001b[36m0.0834\u001b[0m  0.0114\n",
            "     10        \u001b[36m0.0822\u001b[0m  0.0109\n",
            "     11        \u001b[36m0.0783\u001b[0m  0.0112\n",
            "     12        \u001b[36m0.0758\u001b[0m  0.0130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0747\u001b[0m  0.0124\n",
            "     14        \u001b[36m0.0730\u001b[0m  0.0120\n",
            "     15        \u001b[36m0.0699\u001b[0m  0.0121\n",
            "     16        \u001b[36m0.0681\u001b[0m  0.0106\n",
            "     17        \u001b[36m0.0666\u001b[0m  0.0105\n",
            "     18        \u001b[36m0.0656\u001b[0m  0.0112\n",
            "     19        \u001b[36m0.0638\u001b[0m  0.0111\n",
            "     20        \u001b[36m0.0616\u001b[0m  0.0111\n",
            "     21        \u001b[36m0.0584\u001b[0m  0.0108\n",
            "     22        \u001b[36m0.0583\u001b[0m  0.0108\n",
            "     23        \u001b[36m0.0560\u001b[0m  0.0129\n",
            "     24        \u001b[36m0.0536\u001b[0m  0.0114\n",
            "     25        \u001b[36m0.0530\u001b[0m  0.0117\n",
            "     26        \u001b[36m0.0517\u001b[0m  0.0109\n",
            "     27        \u001b[36m0.0502\u001b[0m  0.0109\n",
            "     28        \u001b[36m0.0480\u001b[0m  0.0116\n",
            "     29        \u001b[36m0.0471\u001b[0m  0.0115\n",
            "     30        \u001b[36m0.0458\u001b[0m  0.0115\n",
            "     31        \u001b[36m0.0450\u001b[0m  0.0111\n",
            "     32        \u001b[36m0.0432\u001b[0m  0.0111\n",
            "     33        0.0436  0.0116\n",
            "     34        \u001b[36m0.0424\u001b[0m  0.0112\n",
            "     35        \u001b[36m0.0403\u001b[0m  0.0113\n",
            "     36        \u001b[36m0.0393\u001b[0m  0.0113\n",
            "     37        \u001b[36m0.0383\u001b[0m  0.0110\n",
            "     38        0.0384  0.0119\n",
            "     39        \u001b[36m0.0372\u001b[0m  0.0116\n",
            "     40        \u001b[36m0.0351\u001b[0m  0.0114\n",
            "     41        0.0351  0.0115\n",
            "     42        0.0356  0.0156\n",
            "     43        \u001b[36m0.0346\u001b[0m  0.0172\n",
            "     44        \u001b[36m0.0322\u001b[0m  0.0141\n",
            "     45        0.0336  0.0125\n",
            "     46        \u001b[36m0.0315\u001b[0m  0.0111\n",
            "     47        \u001b[36m0.0301\u001b[0m  0.0109\n",
            "     48        \u001b[36m0.0280\u001b[0m  0.0117\n",
            "     49        0.0283  0.0115\n",
            "     50        \u001b[36m0.0272\u001b[0m  0.0116\n",
            "     51        \u001b[36m0.0272\u001b[0m  0.0113\n",
            "     52        \u001b[36m0.0263\u001b[0m  0.0113\n",
            "     53        0.0269  0.0110\n",
            "     54        0.0266  0.0111\n",
            "     55        \u001b[36m0.0250\u001b[0m  0.0122\n",
            "     56        \u001b[36m0.0249\u001b[0m  0.0112\n",
            "     57        0.0255  0.0112\n",
            "     58        \u001b[36m0.0231\u001b[0m  0.0110\n",
            "     59        \u001b[36m0.0229\u001b[0m  0.0107\n",
            "     60        \u001b[36m0.0226\u001b[0m  0.0115\n",
            "     61        0.0234  0.0113\n",
            "     62        \u001b[36m0.0218\u001b[0m  0.0113\n",
            "     63        0.0227  0.0121\n",
            "     64        0.0219  0.0113\n",
            "     65        \u001b[36m0.0210\u001b[0m  0.0127\n",
            "     66        0.0220  0.0109\n",
            "     67        0.0212  0.0109\n",
            "     68        \u001b[36m0.0201\u001b[0m  0.0120\n",
            "     69        \u001b[36m0.0193\u001b[0m  0.0112\n",
            "     70        0.0207  0.0113\n",
            "     71        \u001b[36m0.0191\u001b[0m  0.0110\n",
            "     72        0.0203  0.0112\n",
            "     73        0.0195  0.0115\n",
            "     74        0.0197  0.0112\n",
            "     75        \u001b[36m0.0183\u001b[0m  0.0112\n",
            "     76        0.0195  0.0109\n",
            "     77        0.0184  0.0109\n",
            "     78        0.0184  0.0116\n",
            "     79        0.0187  0.0115\n",
            "     80        \u001b[36m0.0169\u001b[0m  0.0114\n",
            "     81        0.0177  0.0114\n",
            "     82        \u001b[36m0.0168\u001b[0m  0.0109\n",
            "     83        0.0169  0.0118\n",
            "     84        \u001b[36m0.0165\u001b[0m  0.0113\n",
            "     85        0.0165  0.0115\n",
            "     86        0.0173  0.0124\n",
            "     87        0.0166  0.0113\n",
            "     88        \u001b[36m0.0162\u001b[0m  0.0110\n",
            "     89        \u001b[36m0.0158\u001b[0m  0.0110\n",
            "     90        \u001b[36m0.0157\u001b[0m  0.0116\n",
            "     91        0.0169  0.0112\n",
            "     92        0.0167  0.0113\n",
            "     93        \u001b[36m0.0155\u001b[0m  0.0121\n",
            "     94        \u001b[36m0.0150\u001b[0m  0.0122\n",
            "     95        \u001b[36m0.0149\u001b[0m  0.0106\n",
            "     96        0.0159  0.0138\n",
            "     97        0.0158  0.0120\n",
            "     98        0.0154  0.0114\n",
            "     99        \u001b[36m0.0148\u001b[0m  0.0109\n",
            "    100        \u001b[36m0.0145\u001b[0m  0.0109\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1780\u001b[0m  0.0218\n",
            "      2        \u001b[36m0.1215\u001b[0m  0.0116\n",
            "      3        \u001b[36m0.1032\u001b[0m  0.0131\n",
            "      4        \u001b[36m0.0927\u001b[0m  0.0132\n",
            "      5        \u001b[36m0.0888\u001b[0m  0.0116\n",
            "      6        \u001b[36m0.0825\u001b[0m  0.0114\n",
            "      7        \u001b[36m0.0800\u001b[0m  0.0157\n",
            "      8        \u001b[36m0.0763\u001b[0m  0.0119\n",
            "      9        \u001b[36m0.0743\u001b[0m  0.0118\n",
            "     10        \u001b[36m0.0706\u001b[0m  0.0115\n",
            "     11        \u001b[36m0.0687\u001b[0m  0.0113\n",
            "     12        \u001b[36m0.0666\u001b[0m  0.0126\n",
            "     13        \u001b[36m0.0642\u001b[0m  0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     14        \u001b[36m0.0616\u001b[0m  0.0126\n",
            "     15        \u001b[36m0.0606\u001b[0m  0.0118\n",
            "     16        \u001b[36m0.0567\u001b[0m  0.0114\n",
            "     17        \u001b[36m0.0544\u001b[0m  0.0127\n",
            "     18        \u001b[36m0.0539\u001b[0m  0.0119\n",
            "     19        \u001b[36m0.0510\u001b[0m  0.0117\n",
            "     20        \u001b[36m0.0481\u001b[0m  0.0115\n",
            "     21        0.0481  0.0114\n",
            "     22        \u001b[36m0.0460\u001b[0m  0.0136\n",
            "     23        \u001b[36m0.0441\u001b[0m  0.0168\n",
            "     24        \u001b[36m0.0437\u001b[0m  0.0165\n",
            "     25        \u001b[36m0.0418\u001b[0m  0.0121\n",
            "     26        \u001b[36m0.0390\u001b[0m  0.0120\n",
            "     27        \u001b[36m0.0382\u001b[0m  0.0117\n",
            "     28        \u001b[36m0.0358\u001b[0m  0.0134\n",
            "     29        \u001b[36m0.0349\u001b[0m  0.0117\n",
            "     30        \u001b[36m0.0342\u001b[0m  0.0119\n",
            "     31        \u001b[36m0.0329\u001b[0m  0.0130\n",
            "     32        \u001b[36m0.0321\u001b[0m  0.0117\n",
            "     33        \u001b[36m0.0306\u001b[0m  0.0119\n",
            "     34        \u001b[36m0.0301\u001b[0m  0.0112\n",
            "     35        \u001b[36m0.0281\u001b[0m  0.0114\n",
            "     36        \u001b[36m0.0275\u001b[0m  0.0128\n",
            "     37        \u001b[36m0.0263\u001b[0m  0.0127\n",
            "     38        \u001b[36m0.0248\u001b[0m  0.0123\n",
            "     39        0.0262  0.0112\n",
            "     40        \u001b[36m0.0233\u001b[0m  0.0114\n",
            "     41        \u001b[36m0.0226\u001b[0m  0.0127\n",
            "     42        \u001b[36m0.0218\u001b[0m  0.0121\n",
            "     43        \u001b[36m0.0214\u001b[0m  0.0138\n",
            "     44        0.0216  0.0111\n",
            "     45        \u001b[36m0.0196\u001b[0m  0.0117\n",
            "     46        \u001b[36m0.0195\u001b[0m  0.0135\n",
            "     47        \u001b[36m0.0189\u001b[0m  0.0116\n",
            "     48        0.0189  0.0118\n",
            "     49        \u001b[36m0.0175\u001b[0m  0.0115\n",
            "     50        0.0185  0.0112\n",
            "     51        0.0181  0.0123\n",
            "     52        \u001b[36m0.0161\u001b[0m  0.0124\n",
            "     53        0.0168  0.0121\n",
            "     54        \u001b[36m0.0157\u001b[0m  0.0125\n",
            "     55        0.0165  0.0119\n",
            "     56        \u001b[36m0.0156\u001b[0m  0.0120\n",
            "     57        \u001b[36m0.0153\u001b[0m  0.0126\n",
            "     58        \u001b[36m0.0147\u001b[0m  0.0119\n",
            "     59        \u001b[36m0.0147\u001b[0m  0.0114\n",
            "     60        0.0147  0.0114\n",
            "     61        \u001b[36m0.0144\u001b[0m  0.0124\n",
            "     62        0.0149  0.0120\n",
            "     63        \u001b[36m0.0140\u001b[0m  0.0131\n",
            "     64        \u001b[36m0.0137\u001b[0m  0.0121\n",
            "     65        \u001b[36m0.0135\u001b[0m  0.0120\n",
            "     66        \u001b[36m0.0131\u001b[0m  0.0113\n",
            "     67        0.0141  0.0118\n",
            "     68        \u001b[36m0.0126\u001b[0m  0.0130\n",
            "     69        \u001b[36m0.0123\u001b[0m  0.0131\n",
            "     70        0.0142  0.0119\n",
            "     71        0.0128  0.0119\n",
            "     72        0.0130  0.0488\n",
            "     73        0.0126  0.0386\n",
            "     74        0.0130  0.0291\n",
            "     75        \u001b[36m0.0118\u001b[0m  0.0317\n",
            "     76        \u001b[36m0.0115\u001b[0m  0.0428\n",
            "     77        0.0116  0.0250\n",
            "     78        0.0118  0.0295\n",
            "     79        \u001b[36m0.0114\u001b[0m  0.0121\n",
            "     80        0.0115  0.0116\n",
            "     81        0.0116  0.0120\n",
            "     82        0.0115  0.0125\n",
            "     83        \u001b[36m0.0113\u001b[0m  0.0121\n",
            "     84        \u001b[36m0.0108\u001b[0m  0.0117\n",
            "     85        0.0110  0.0118\n",
            "     86        0.0112  0.0113\n",
            "     87        \u001b[36m0.0106\u001b[0m  0.0115\n",
            "     88        0.0110  0.0198\n",
            "     89        \u001b[36m0.0103\u001b[0m  0.0167\n",
            "     90        0.0108  0.0140\n",
            "     91        \u001b[36m0.0101\u001b[0m  0.0125\n",
            "     92        0.0115  0.0120\n",
            "     93        0.0109  0.0118\n",
            "     94        0.0103  0.0118\n",
            "     95        0.0107  0.0113\n",
            "     96        0.0103  0.0114\n",
            "     97        \u001b[36m0.0100\u001b[0m  0.0124\n",
            "     98        0.0109  0.0118\n",
            "     99        0.0102  0.0120\n",
            "    100        \u001b[36m0.0095\u001b[0m  0.0119\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1619\u001b[0m  0.0067\n",
            "      2        \u001b[36m0.1241\u001b[0m  0.0058\n",
            "      3        \u001b[36m0.1112\u001b[0m  0.0066\n",
            "      4        \u001b[36m0.1025\u001b[0m  0.0061\n",
            "      5        \u001b[36m0.0927\u001b[0m  0.0058\n",
            "      6        \u001b[36m0.0877\u001b[0m  0.0058\n",
            "      7        \u001b[36m0.0840\u001b[0m  0.0059\n",
            "      8        \u001b[36m0.0795\u001b[0m  0.0067\n",
            "      9        \u001b[36m0.0765\u001b[0m  0.0075\n",
            "     10        \u001b[36m0.0744\u001b[0m  0.0071\n",
            "     11        \u001b[36m0.0723\u001b[0m  0.0062\n",
            "     12        \u001b[36m0.0695\u001b[0m  0.0059\n",
            "     13        \u001b[36m0.0676\u001b[0m  0.0082\n",
            "     14        \u001b[36m0.0648\u001b[0m  0.0060\n",
            "     15        \u001b[36m0.0633\u001b[0m  0.0059\n",
            "     16        0.0648  0.0065\n",
            "     17        \u001b[36m0.0592\u001b[0m  0.0069\n",
            "     18        0.0600  0.0063\n",
            "     19        \u001b[36m0.0570\u001b[0m  0.0064\n",
            "     20        \u001b[36m0.0563\u001b[0m  0.0060\n",
            "     21        \u001b[36m0.0542\u001b[0m  0.0081\n",
            "     22        \u001b[36m0.0541\u001b[0m  0.0054\n",
            "     23        \u001b[36m0.0531\u001b[0m  0.0058\n",
            "     24        \u001b[36m0.0503\u001b[0m  0.0061\n",
            "     25        \u001b[36m0.0489\u001b[0m  0.0056\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     26        \u001b[36m0.0488\u001b[0m  0.0064\n",
            "     27        \u001b[36m0.0456\u001b[0m  0.0073\n",
            "     28        0.0457  0.0062\n",
            "     29        \u001b[36m0.0439\u001b[0m  0.0059\n",
            "     30        \u001b[36m0.0424\u001b[0m  0.0059\n",
            "     31        \u001b[36m0.0405\u001b[0m  0.0347\n",
            "     32        0.0417  0.0174\n",
            "     33        0.0425  0.0120\n",
            "     34        \u001b[36m0.0403\u001b[0m  0.0148\n",
            "     35        \u001b[36m0.0375\u001b[0m  0.0188\n",
            "     36        \u001b[36m0.0372\u001b[0m  0.0199\n",
            "     37        \u001b[36m0.0346\u001b[0m  0.0143\n",
            "     38        0.0355  0.0213\n",
            "     39        \u001b[36m0.0343\u001b[0m  0.0086\n",
            "     40        \u001b[36m0.0332\u001b[0m  0.0132\n",
            "     41        0.0338  0.0117\n",
            "     42        \u001b[36m0.0321\u001b[0m  0.0074\n",
            "     43        \u001b[36m0.0305\u001b[0m  0.0112\n",
            "     44        \u001b[36m0.0303\u001b[0m  0.0087\n",
            "     45        0.0306  0.0075\n",
            "     46        \u001b[36m0.0282\u001b[0m  0.0094\n",
            "     47        0.0290  0.0071\n",
            "     48        \u001b[36m0.0256\u001b[0m  0.0089\n",
            "     49        0.0261  0.0065\n",
            "     50        \u001b[36m0.0252\u001b[0m  0.0060\n",
            "     51        \u001b[36m0.0243\u001b[0m  0.0061\n",
            "     52        \u001b[36m0.0226\u001b[0m  0.0062\n",
            "     53        \u001b[36m0.0220\u001b[0m  0.0059\n",
            "     54        \u001b[36m0.0219\u001b[0m  0.0057\n",
            "     55        \u001b[36m0.0216\u001b[0m  0.0059\n",
            "     56        0.0223  0.0057\n",
            "     57        \u001b[36m0.0208\u001b[0m  0.0072\n",
            "     58        0.0209  0.0082\n",
            "     59        \u001b[36m0.0199\u001b[0m  0.0080\n",
            "     60        0.0201  0.0062\n",
            "     61        0.0210  0.0063\n",
            "     62        \u001b[36m0.0197\u001b[0m  0.0063\n",
            "     63        \u001b[36m0.0185\u001b[0m  0.0057\n",
            "     64        \u001b[36m0.0174\u001b[0m  0.0062\n",
            "     65        0.0179  0.0059\n",
            "     66        0.0179  0.0059\n",
            "     67        \u001b[36m0.0162\u001b[0m  0.0058\n",
            "     68        \u001b[36m0.0152\u001b[0m  0.0081\n",
            "     69        0.0159  0.0063\n",
            "     70        0.0170  0.0060\n",
            "     71        0.0157  0.0061\n",
            "     72        0.0155  0.0060\n",
            "     73        \u001b[36m0.0148\u001b[0m  0.0058\n",
            "     74        \u001b[36m0.0141\u001b[0m  0.0063\n",
            "     75        0.0148  0.0086\n",
            "     76        \u001b[36m0.0137\u001b[0m  0.0063\n",
            "     77        \u001b[36m0.0126\u001b[0m  0.0063\n",
            "     78        0.0144  0.0058\n",
            "     79        0.0129  0.0058\n",
            "     80        \u001b[36m0.0126\u001b[0m  0.0059\n",
            "     81        \u001b[36m0.0113\u001b[0m  0.0059\n",
            "     82        0.0125  0.0057\n",
            "     83        0.0123  0.0059\n",
            "     84        0.0114  0.0083\n",
            "     85        0.0114  0.0067\n",
            "     86        0.0120  0.0064\n",
            "     87        0.0124  0.0058\n",
            "     88        \u001b[36m0.0110\u001b[0m  0.0060\n",
            "     89        \u001b[36m0.0109\u001b[0m  0.0060\n",
            "     90        0.0120  0.0069\n",
            "     91        \u001b[36m0.0108\u001b[0m  0.0089\n",
            "     92        \u001b[36m0.0099\u001b[0m  0.0088\n",
            "     93        \u001b[36m0.0092\u001b[0m  0.0109\n",
            "     94        0.0100  0.0098\n",
            "     95        0.0097  0.0053\n",
            "     96        0.0102  0.0058\n",
            "     97        0.0097  0.0058\n",
            "     98        \u001b[36m0.0090\u001b[0m  0.0058\n",
            "     99        0.0101  0.0082\n",
            "    100        0.0101  0.0063\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.2047\u001b[0m  0.0124\n",
            "      2        \u001b[36m0.1390\u001b[0m  0.0123\n",
            "      3        \u001b[36m0.1123\u001b[0m  0.0122\n",
            "      4        \u001b[36m0.1016\u001b[0m  0.0119\n",
            "      5        \u001b[36m0.0954\u001b[0m  0.0114\n",
            "      6        \u001b[36m0.0918\u001b[0m  0.0113\n",
            "      7        \u001b[36m0.0908\u001b[0m  0.0129\n",
            "      8        \u001b[36m0.0865\u001b[0m  0.0120\n",
            "      9        \u001b[36m0.0852\u001b[0m  0.0120\n",
            "     10        \u001b[36m0.0828\u001b[0m  0.0112\n",
            "     11        \u001b[36m0.0796\u001b[0m  0.0110\n",
            "     12        \u001b[36m0.0773\u001b[0m  0.0120\n",
            "     13        \u001b[36m0.0740\u001b[0m  0.0131\n",
            "     14        \u001b[36m0.0726\u001b[0m  0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     15        \u001b[36m0.0711\u001b[0m  0.0146\n",
            "     16        \u001b[36m0.0690\u001b[0m  0.0168\n",
            "     17        \u001b[36m0.0671\u001b[0m  0.0221\n",
            "     18        \u001b[36m0.0650\u001b[0m  0.0148\n",
            "     19        \u001b[36m0.0643\u001b[0m  0.0262\n",
            "     20        \u001b[36m0.0617\u001b[0m  0.0362\n",
            "     21        \u001b[36m0.0585\u001b[0m  0.0380\n",
            "     22        0.0588  0.0356\n",
            "     23        \u001b[36m0.0579\u001b[0m  0.0374\n",
            "     24        \u001b[36m0.0550\u001b[0m  0.0298\n",
            "     25        \u001b[36m0.0541\u001b[0m  0.0114\n",
            "     26        \u001b[36m0.0531\u001b[0m  0.0113\n",
            "     27        \u001b[36m0.0514\u001b[0m  0.0113\n",
            "     28        \u001b[36m0.0502\u001b[0m  0.0114\n",
            "     29        \u001b[36m0.0491\u001b[0m  0.0114\n",
            "     30        \u001b[36m0.0465\u001b[0m  0.0112\n",
            "     31        \u001b[36m0.0448\u001b[0m  0.0112\n",
            "     32        \u001b[36m0.0438\u001b[0m  0.0112\n",
            "     33        \u001b[36m0.0437\u001b[0m  0.0112\n",
            "     34        \u001b[36m0.0417\u001b[0m  0.0113\n",
            "     35        \u001b[36m0.0407\u001b[0m  0.0114\n",
            "     36        \u001b[36m0.0396\u001b[0m  0.0115\n",
            "     37        \u001b[36m0.0393\u001b[0m  0.0126\n",
            "     38        \u001b[36m0.0377\u001b[0m  0.0116\n",
            "     39        \u001b[36m0.0365\u001b[0m  0.0112\n",
            "     40        \u001b[36m0.0359\u001b[0m  0.0127\n",
            "     41        \u001b[36m0.0341\u001b[0m  0.0113\n",
            "     42        0.0355  0.0114\n",
            "     43        \u001b[36m0.0335\u001b[0m  0.0115\n",
            "     44        0.0344  0.0114\n",
            "     45        \u001b[36m0.0317\u001b[0m  0.0113\n",
            "     46        \u001b[36m0.0308\u001b[0m  0.0117\n",
            "     47        \u001b[36m0.0306\u001b[0m  0.0115\n",
            "     48        \u001b[36m0.0290\u001b[0m  0.0115\n",
            "     49        0.0296  0.0112\n",
            "     50        \u001b[36m0.0265\u001b[0m  0.0118\n",
            "     51        0.0293  0.0119\n",
            "     52        0.0273  0.0114\n",
            "     53        0.0272  0.0113\n",
            "     54        \u001b[36m0.0262\u001b[0m  0.0110\n",
            "     55        \u001b[36m0.0251\u001b[0m  0.0109\n",
            "     56        0.0267  0.0129\n",
            "     57        0.0259  0.0153\n",
            "     58        \u001b[36m0.0243\u001b[0m  0.0172\n",
            "     59        0.0265  0.0157\n",
            "     60        0.0247  0.0179\n",
            "     61        0.0247  0.0192\n",
            "     62        \u001b[36m0.0243\u001b[0m  0.0178\n",
            "     63        \u001b[36m0.0230\u001b[0m  0.0196\n",
            "     64        0.0241  0.0158\n",
            "     65        0.0231  0.0187\n",
            "     66        \u001b[36m0.0223\u001b[0m  0.0138\n",
            "     67        \u001b[36m0.0209\u001b[0m  0.0156\n",
            "     68        \u001b[36m0.0204\u001b[0m  0.0138\n",
            "     69        0.0225  0.0146\n",
            "     70        0.0208  0.0125\n",
            "     71        \u001b[36m0.0201\u001b[0m  0.0128\n",
            "     72        0.0216  0.0155\n",
            "     73        0.0214  0.0145\n",
            "     74        \u001b[36m0.0192\u001b[0m  0.0138\n",
            "     75        0.0206  0.0152\n",
            "     76        0.0194  0.0134\n",
            "     77        \u001b[36m0.0191\u001b[0m  0.0153\n",
            "     78        0.0193  0.0134\n",
            "     79        \u001b[36m0.0177\u001b[0m  0.0126\n",
            "     80        0.0180  0.0131\n",
            "     81        \u001b[36m0.0177\u001b[0m  0.0141\n",
            "     82        0.0187  0.0135\n",
            "     83        0.0200  0.0157\n",
            "     84        0.0180  0.0149\n",
            "     85        0.0178  0.0140\n",
            "     86        \u001b[36m0.0170\u001b[0m  0.0129\n",
            "     87        \u001b[36m0.0165\u001b[0m  0.0158\n",
            "     88        0.0167  0.0134\n",
            "     89        0.0171  0.0172\n",
            "     90        \u001b[36m0.0163\u001b[0m  0.0136\n",
            "     91        0.0166  0.0152\n",
            "     92        0.0167  0.0144\n",
            "     93        \u001b[36m0.0159\u001b[0m  0.0131\n",
            "     94        \u001b[36m0.0153\u001b[0m  0.0132\n",
            "     95        0.0162  0.0130\n",
            "     96        0.0162  0.0130\n",
            "     97        0.0170  0.0130\n",
            "     98        \u001b[36m0.0149\u001b[0m  0.0133\n",
            "     99        \u001b[36m0.0147\u001b[0m  0.0131\n",
            "    100        0.0158  0.0136\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1771\u001b[0m  0.0164\n",
            "      2        \u001b[36m0.1142\u001b[0m  0.0143\n",
            "      3        \u001b[36m0.0968\u001b[0m  0.0148\n",
            "      4        \u001b[36m0.0898\u001b[0m  0.0140\n",
            "      5        \u001b[36m0.0848\u001b[0m  0.0138\n",
            "      6        \u001b[36m0.0804\u001b[0m  0.0157\n",
            "      7        \u001b[36m0.0771\u001b[0m  0.0163\n",
            "      8        \u001b[36m0.0747\u001b[0m  0.0142\n",
            "      9        \u001b[36m0.0734\u001b[0m  0.0141\n",
            "     10        \u001b[36m0.0702\u001b[0m  0.0138\n",
            "     11        \u001b[36m0.0678\u001b[0m  0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0656\u001b[0m  0.0151\n",
            "     13        \u001b[36m0.0635\u001b[0m  0.0140\n",
            "     14        \u001b[36m0.0615\u001b[0m  0.0162\n",
            "     15        \u001b[36m0.0594\u001b[0m  0.0144\n",
            "     16        \u001b[36m0.0572\u001b[0m  0.0157\n",
            "     17        \u001b[36m0.0536\u001b[0m  0.0133\n",
            "     18        \u001b[36m0.0525\u001b[0m  0.0134\n",
            "     19        \u001b[36m0.0510\u001b[0m  0.0134\n",
            "     20        \u001b[36m0.0494\u001b[0m  0.0153\n",
            "     21        \u001b[36m0.0468\u001b[0m  0.0132\n",
            "     22        \u001b[36m0.0464\u001b[0m  0.0135\n",
            "     23        \u001b[36m0.0442\u001b[0m  0.0142\n",
            "     24        \u001b[36m0.0425\u001b[0m  0.0157\n",
            "     25        \u001b[36m0.0402\u001b[0m  0.0133\n",
            "     26        \u001b[36m0.0393\u001b[0m  0.0186\n",
            "     27        \u001b[36m0.0381\u001b[0m  0.0165\n",
            "     28        \u001b[36m0.0374\u001b[0m  0.0181\n",
            "     29        \u001b[36m0.0346\u001b[0m  0.0173\n",
            "     30        \u001b[36m0.0345\u001b[0m  0.0151\n",
            "     31        \u001b[36m0.0340\u001b[0m  0.0146\n",
            "     32        \u001b[36m0.0316\u001b[0m  0.0172\n",
            "     33        \u001b[36m0.0309\u001b[0m  0.0144\n",
            "     34        \u001b[36m0.0295\u001b[0m  0.0137\n",
            "     35        \u001b[36m0.0294\u001b[0m  0.0140\n",
            "     36        \u001b[36m0.0273\u001b[0m  0.0140\n",
            "     37        \u001b[36m0.0258\u001b[0m  0.0138\n",
            "     38        \u001b[36m0.0239\u001b[0m  0.0143\n",
            "     39        0.0240  0.0135\n",
            "     40        \u001b[36m0.0239\u001b[0m  0.0140\n",
            "     41        \u001b[36m0.0234\u001b[0m  0.0134\n",
            "     42        \u001b[36m0.0222\u001b[0m  0.0135\n",
            "     43        \u001b[36m0.0221\u001b[0m  0.0165\n",
            "     44        \u001b[36m0.0203\u001b[0m  0.0136\n",
            "     45        0.0207  0.0141\n",
            "     46        0.0206  0.0151\n",
            "     47        \u001b[36m0.0189\u001b[0m  0.0183\n",
            "     48        \u001b[36m0.0182\u001b[0m  0.0150\n",
            "     49        0.0187  0.0178\n",
            "     50        0.0189  0.0198\n",
            "     51        \u001b[36m0.0177\u001b[0m  0.0168\n",
            "     52        0.0180  0.0169\n",
            "     53        \u001b[36m0.0162\u001b[0m  0.0151\n",
            "     54        0.0170  0.0162\n",
            "     55        0.0163  0.0178\n",
            "     56        \u001b[36m0.0160\u001b[0m  0.0171\n",
            "     57        0.0161  0.0138\n",
            "     58        \u001b[36m0.0149\u001b[0m  0.0144\n",
            "     59        0.0150  0.0141\n",
            "     60        0.0155  0.0162\n",
            "     61        0.0156  0.0162\n",
            "     62        0.0150  0.0135\n",
            "     63        0.0150  0.0141\n",
            "     64        0.0151  0.0139\n",
            "     65        0.0149  0.0166\n",
            "     66        \u001b[36m0.0139\u001b[0m  0.0162\n",
            "     67        \u001b[36m0.0132\u001b[0m  0.0178\n",
            "     68        \u001b[36m0.0128\u001b[0m  0.0164\n",
            "     69        0.0132  0.0195\n",
            "     70        0.0131  0.0165\n",
            "     71        0.0132  0.0161\n",
            "     72        0.0132  0.0158\n",
            "     73        0.0131  0.0147\n",
            "     74        \u001b[36m0.0127\u001b[0m  0.0154\n",
            "     75        \u001b[36m0.0122\u001b[0m  0.0162\n",
            "     76        0.0124  0.0164\n",
            "     77        \u001b[36m0.0120\u001b[0m  0.0170\n",
            "     78        \u001b[36m0.0117\u001b[0m  0.0171\n",
            "     79        0.0124  0.0169\n",
            "     80        0.0124  0.0172\n",
            "     81        \u001b[36m0.0115\u001b[0m  0.0175\n",
            "     82        0.0115  0.0175\n",
            "     83        \u001b[36m0.0113\u001b[0m  0.0202\n",
            "     84        \u001b[36m0.0109\u001b[0m  0.0167\n",
            "     85        \u001b[36m0.0107\u001b[0m  0.0170\n",
            "     86        0.0109  0.0182\n",
            "     87        0.0109  0.0208\n",
            "     88        0.0122  0.0221\n",
            "     89        \u001b[36m0.0105\u001b[0m  0.0154\n",
            "     90        0.0108  0.0143\n",
            "     91        0.0106  0.0136\n",
            "     92        0.0107  0.0138\n",
            "     93        \u001b[36m0.0097\u001b[0m  0.0136\n",
            "     94        0.0108  0.0136\n",
            "     95        0.0103  0.0141\n",
            "     96        0.0102  0.0134\n",
            "     97        \u001b[36m0.0096\u001b[0m  0.0129\n",
            "     98        0.0104  0.0114\n",
            "     99        \u001b[36m0.0095\u001b[0m  0.0115\n",
            "    100        0.0100  0.0136\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1653\u001b[0m  0.0118\n",
            "      2        \u001b[36m0.1197\u001b[0m  0.0055\n",
            "      3        \u001b[36m0.0993\u001b[0m  0.0054\n",
            "      4        \u001b[36m0.0875\u001b[0m  0.0057\n",
            "      5        \u001b[36m0.0791\u001b[0m  0.0048\n",
            "      6        \u001b[36m0.0743\u001b[0m  0.0050\n",
            "      7        \u001b[36m0.0677\u001b[0m  0.0049\n",
            "      8        \u001b[36m0.0638\u001b[0m  0.0048\n",
            "      9        \u001b[36m0.0585\u001b[0m  0.0050\n",
            "     10        \u001b[36m0.0555\u001b[0m  0.0049\n",
            "     11        \u001b[36m0.0552\u001b[0m  0.0082\n",
            "     12        \u001b[36m0.0509\u001b[0m  0.0061\n",
            "     13        \u001b[36m0.0498\u001b[0m  0.0053\n",
            "     14        \u001b[36m0.0493\u001b[0m  0.0049\n",
            "     15        \u001b[36m0.0442\u001b[0m  0.0051\n",
            "     16        \u001b[36m0.0437\u001b[0m  0.0054\n",
            "     17        \u001b[36m0.0422\u001b[0m  0.0046\n",
            "     18        \u001b[36m0.0394\u001b[0m  0.0048\n",
            "     19        \u001b[36m0.0358\u001b[0m  0.0049\n",
            "     20        \u001b[36m0.0342\u001b[0m  0.0079\n",
            "     21        0.0347  0.0054\n",
            "     22        \u001b[36m0.0331\u001b[0m  0.0054\n",
            "     23        \u001b[36m0.0315\u001b[0m  0.0051\n",
            "     24        \u001b[36m0.0286\u001b[0m  0.0063\n",
            "     25        \u001b[36m0.0284\u001b[0m  0.0047\n",
            "     26        \u001b[36m0.0277\u001b[0m  0.0049\n",
            "     27        \u001b[36m0.0265\u001b[0m  0.0049\n",
            "     28        \u001b[36m0.0245\u001b[0m  0.0048\n",
            "     29        \u001b[36m0.0239\u001b[0m  0.0048\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     30        \u001b[36m0.0219\u001b[0m  0.0067\n",
            "     31        0.0220  0.0070\n",
            "     32        0.0226  0.0048\n",
            "     33        \u001b[36m0.0210\u001b[0m  0.0051\n",
            "     34        \u001b[36m0.0200\u001b[0m  0.0046\n",
            "     35        \u001b[36m0.0188\u001b[0m  0.0048\n",
            "     36        \u001b[36m0.0180\u001b[0m  0.0049\n",
            "     37        \u001b[36m0.0174\u001b[0m  0.0050\n",
            "     38        \u001b[36m0.0166\u001b[0m  0.0051\n",
            "     39        0.0170  0.0048\n",
            "     40        \u001b[36m0.0160\u001b[0m  0.0080\n",
            "     41        \u001b[36m0.0150\u001b[0m  0.0059\n",
            "     42        \u001b[36m0.0133\u001b[0m  0.0050\n",
            "     43        0.0149  0.0047\n",
            "     44        0.0148  0.0046\n",
            "     45        0.0133  0.0048\n",
            "     46        0.0142  0.0051\n",
            "     47        \u001b[36m0.0131\u001b[0m  0.0051\n",
            "     48        \u001b[36m0.0124\u001b[0m  0.0053\n",
            "     49        \u001b[36m0.0112\u001b[0m  0.0065\n",
            "     50        0.0117  0.0048\n",
            "     51        0.0128  0.0056\n",
            "     52        \u001b[36m0.0112\u001b[0m  0.0054\n",
            "     53        0.0112  0.0049\n",
            "     54        0.0123  0.0051\n",
            "     55        \u001b[36m0.0111\u001b[0m  0.0050\n",
            "     56        \u001b[36m0.0093\u001b[0m  0.0048\n",
            "     57        0.0112  0.0051\n",
            "     58        0.0112  0.0051\n",
            "     59        0.0102  0.0068\n",
            "     60        0.0103  0.0055\n",
            "     61        \u001b[36m0.0091\u001b[0m  0.0051\n",
            "     62        0.0094  0.0048\n",
            "     63        0.0098  0.0050\n",
            "     64        0.0097  0.0050\n",
            "     65        0.0093  0.0048\n",
            "     66        \u001b[36m0.0085\u001b[0m  0.0049\n",
            "     67        0.0089  0.0085\n",
            "     68        0.0103  0.0054\n",
            "     69        \u001b[36m0.0083\u001b[0m  0.0055\n",
            "     70        \u001b[36m0.0083\u001b[0m  0.0051\n",
            "     71        0.0088  0.0063\n",
            "     72        \u001b[36m0.0079\u001b[0m  0.0050\n",
            "     73        \u001b[36m0.0072\u001b[0m  0.0051\n",
            "     74        0.0084  0.0050\n",
            "     75        0.0079  0.0049\n",
            "     76        0.0099  0.0074\n",
            "     77        0.0081  0.0052\n",
            "     78        0.0086  0.0048\n",
            "     79        0.0077  0.0047\n",
            "     80        0.0080  0.0047\n",
            "     81        \u001b[36m0.0070\u001b[0m  0.0047\n",
            "     82        0.0072  0.0047\n",
            "     83        0.0075  0.0048\n",
            "     84        0.0071  0.0067\n",
            "     85        0.0073  0.0061\n",
            "     86        0.0073  0.0052\n",
            "     87        0.0070  0.0048\n",
            "     88        0.0073  0.0046\n",
            "     89        0.0070  0.0048\n",
            "     90        0.0070  0.0046\n",
            "     91        \u001b[36m0.0065\u001b[0m  0.0047\n",
            "     92        0.0065  0.0045\n",
            "     93        \u001b[36m0.0065\u001b[0m  0.0073\n",
            "     94        0.0073  0.0060\n",
            "     95        0.0072  0.0054\n",
            "     96        0.0068  0.0053\n",
            "     97        0.0074  0.0050\n",
            "     98        \u001b[36m0.0063\u001b[0m  0.0046\n",
            "     99        \u001b[36m0.0060\u001b[0m  0.0049\n",
            "    100        0.0068  0.0045\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1566\u001b[0m  0.0240\n",
            "      2        \u001b[36m0.1092\u001b[0m  0.0094\n",
            "      3        \u001b[36m0.0953\u001b[0m  0.0110\n",
            "      4        \u001b[36m0.0829\u001b[0m  0.0099\n",
            "      5        \u001b[36m0.0766\u001b[0m  0.0119\n",
            "      6        \u001b[36m0.0725\u001b[0m  0.0110\n",
            "      7        \u001b[36m0.0671\u001b[0m  0.0106\n",
            "      8        \u001b[36m0.0645\u001b[0m  0.0097\n",
            "      9        \u001b[36m0.0614\u001b[0m  0.0098\n",
            "     10        \u001b[36m0.0586\u001b[0m  0.0090\n",
            "     11        \u001b[36m0.0556\u001b[0m  0.0091\n",
            "     12        \u001b[36m0.0523\u001b[0m  0.0091\n",
            "     13        \u001b[36m0.0503\u001b[0m  0.0115\n",
            "     14        \u001b[36m0.0483\u001b[0m  0.0095\n",
            "     15        \u001b[36m0.0454\u001b[0m  0.0099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     16        0.0454  0.0140\n",
            "     17        \u001b[36m0.0419\u001b[0m  0.0151\n",
            "     18        \u001b[36m0.0417\u001b[0m  0.0099\n",
            "     19        \u001b[36m0.0396\u001b[0m  0.0098\n",
            "     20        \u001b[36m0.0389\u001b[0m  0.0092\n",
            "     21        \u001b[36m0.0349\u001b[0m  0.0093\n",
            "     22        \u001b[36m0.0339\u001b[0m  0.0091\n",
            "     23        0.0346  0.0119\n",
            "     24        \u001b[36m0.0317\u001b[0m  0.0098\n",
            "     25        0.0319  0.0096\n",
            "     26        \u001b[36m0.0309\u001b[0m  0.0095\n",
            "     27        \u001b[36m0.0292\u001b[0m  0.0099\n",
            "     28        \u001b[36m0.0281\u001b[0m  0.0107\n",
            "     29        \u001b[36m0.0270\u001b[0m  0.0091\n",
            "     30        \u001b[36m0.0270\u001b[0m  0.0102\n",
            "     31        \u001b[36m0.0254\u001b[0m  0.0091\n",
            "     32        \u001b[36m0.0244\u001b[0m  0.0114\n",
            "     33        \u001b[36m0.0240\u001b[0m  0.0095\n",
            "     34        \u001b[36m0.0225\u001b[0m  0.0091\n",
            "     35        0.0226  0.0091\n",
            "     36        \u001b[36m0.0213\u001b[0m  0.0091\n",
            "     37        \u001b[36m0.0207\u001b[0m  0.0111\n",
            "     38        \u001b[36m0.0199\u001b[0m  0.0095\n",
            "     39        0.0209  0.0096\n",
            "     40        \u001b[36m0.0199\u001b[0m  0.0089\n",
            "     41        \u001b[36m0.0196\u001b[0m  0.0096\n",
            "     42        \u001b[36m0.0191\u001b[0m  0.0092\n",
            "     43        \u001b[36m0.0186\u001b[0m  0.0110\n",
            "     44        0.0192  0.0096\n",
            "     45        \u001b[36m0.0169\u001b[0m  0.0100\n",
            "     46        0.0181  0.0095\n",
            "     47        0.0171  0.0108\n",
            "     48        \u001b[36m0.0167\u001b[0m  0.0111\n",
            "     49        \u001b[36m0.0165\u001b[0m  0.0091\n",
            "     50        \u001b[36m0.0156\u001b[0m  0.0091\n",
            "     51        0.0158  0.0093\n",
            "     52        0.0169  0.0116\n",
            "     53        \u001b[36m0.0147\u001b[0m  0.0096\n",
            "     54        0.0152  0.0092\n",
            "     55        0.0147  0.0091\n",
            "     56        \u001b[36m0.0146\u001b[0m  0.0091\n",
            "     57        0.0151  0.0111\n",
            "     58        \u001b[36m0.0143\u001b[0m  0.0097\n",
            "     59        \u001b[36m0.0134\u001b[0m  0.0097\n",
            "     60        0.0142  0.0096\n",
            "     61        0.0139  0.0094\n",
            "     62        0.0140  0.0090\n",
            "     63        0.0138  0.0091\n",
            "     64        0.0137  0.0109\n",
            "     65        0.0146  0.0098\n",
            "     66        \u001b[36m0.0131\u001b[0m  0.0098\n",
            "     67        \u001b[36m0.0129\u001b[0m  0.0092\n",
            "     68        \u001b[36m0.0127\u001b[0m  0.0094\n",
            "     69        \u001b[36m0.0119\u001b[0m  0.0093\n",
            "     70        0.0122  0.0115\n",
            "     71        0.0125  0.0096\n",
            "     72        0.0120  0.0109\n",
            "     73        \u001b[36m0.0116\u001b[0m  0.0095\n",
            "     74        0.0119  0.0091\n",
            "     75        0.0123  0.0092\n",
            "     76        0.0118  0.0124\n",
            "     77        0.0117  0.0097\n",
            "     78        \u001b[36m0.0112\u001b[0m  0.0098\n",
            "     79        0.0115  0.0091\n",
            "     80        \u001b[36m0.0110\u001b[0m  0.0096\n",
            "     81        \u001b[36m0.0105\u001b[0m  0.0091\n",
            "     82        0.0116  0.0116\n",
            "     83        0.0114  0.0098\n",
            "     84        0.0109  0.0099\n",
            "     85        0.0108  0.0094\n",
            "     86        0.0112  0.0092\n",
            "     87        \u001b[36m0.0098\u001b[0m  0.0093\n",
            "     88        0.0110  0.0109\n",
            "     89        0.0110  0.0100\n",
            "     90        0.0108  0.0099\n",
            "     91        0.0100  0.0092\n",
            "     92        0.0103  0.0088\n",
            "     93        0.0105  0.0090\n",
            "     94        0.0116  0.0115\n",
            "     95        0.0103  0.0121\n",
            "     96        0.0111  0.0100\n",
            "     97        0.0099  0.0091\n",
            "     98        0.0109  0.0091\n",
            "     99        0.0104  0.0093\n",
            "    100        0.0098  0.0142\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1622\u001b[0m  0.0159\n",
            "      2        \u001b[36m0.1032\u001b[0m  0.0097\n",
            "      3        \u001b[36m0.0874\u001b[0m  0.0100\n",
            "      4        \u001b[36m0.0779\u001b[0m  0.0101\n",
            "      5        \u001b[36m0.0699\u001b[0m  0.0094\n",
            "      6        \u001b[36m0.0640\u001b[0m  0.0096\n",
            "      7        \u001b[36m0.0597\u001b[0m  0.0096\n",
            "      8        \u001b[36m0.0574\u001b[0m  0.0110\n",
            "      9        \u001b[36m0.0534\u001b[0m  0.0114\n",
            "     10        \u001b[36m0.0490\u001b[0m  0.0137\n",
            "     11        \u001b[36m0.0471\u001b[0m  0.0147\n",
            "     12        \u001b[36m0.0437\u001b[0m  0.0111\n",
            "     13        \u001b[36m0.0416\u001b[0m  0.0099\n",
            "     14        \u001b[36m0.0392\u001b[0m  0.0096\n",
            "     15        \u001b[36m0.0368\u001b[0m  0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     16        \u001b[36m0.0347\u001b[0m  0.0111\n",
            "     17        \u001b[36m0.0328\u001b[0m  0.0123\n",
            "     18        \u001b[36m0.0310\u001b[0m  0.0113\n",
            "     19        \u001b[36m0.0291\u001b[0m  0.0100\n",
            "     20        \u001b[36m0.0278\u001b[0m  0.0119\n",
            "     21        \u001b[36m0.0257\u001b[0m  0.0097\n",
            "     22        \u001b[36m0.0248\u001b[0m  0.0101\n",
            "     23        \u001b[36m0.0230\u001b[0m  0.0108\n",
            "     24        \u001b[36m0.0217\u001b[0m  0.0103\n",
            "     25        0.0219  0.0093\n",
            "     26        0.0221  0.0098\n",
            "     27        \u001b[36m0.0200\u001b[0m  0.0091\n",
            "     28        \u001b[36m0.0194\u001b[0m  0.0114\n",
            "     29        \u001b[36m0.0190\u001b[0m  0.0134\n",
            "     30        \u001b[36m0.0185\u001b[0m  0.0136\n",
            "     31        \u001b[36m0.0177\u001b[0m  0.0113\n",
            "     32        \u001b[36m0.0173\u001b[0m  0.0139\n",
            "     33        \u001b[36m0.0170\u001b[0m  0.0127\n",
            "     34        \u001b[36m0.0157\u001b[0m  0.0135\n",
            "     35        \u001b[36m0.0153\u001b[0m  0.0113\n",
            "     36        \u001b[36m0.0152\u001b[0m  0.0093\n",
            "     37        \u001b[36m0.0147\u001b[0m  0.0123\n",
            "     38        \u001b[36m0.0137\u001b[0m  0.0101\n",
            "     39        0.0146  0.0100\n",
            "     40        0.0143  0.0094\n",
            "     41        \u001b[36m0.0134\u001b[0m  0.0109\n",
            "     42        \u001b[36m0.0133\u001b[0m  0.0109\n",
            "     43        \u001b[36m0.0128\u001b[0m  0.0102\n",
            "     44        0.0131  0.0104\n",
            "     45        \u001b[36m0.0126\u001b[0m  0.0099\n",
            "     46        \u001b[36m0.0121\u001b[0m  0.0098\n",
            "     47        0.0121  0.0099\n",
            "     48        \u001b[36m0.0117\u001b[0m  0.0108\n",
            "     49        0.0123  0.0101\n",
            "     50        \u001b[36m0.0114\u001b[0m  0.0105\n",
            "     51        \u001b[36m0.0109\u001b[0m  0.0107\n",
            "     52        \u001b[36m0.0102\u001b[0m  0.0101\n",
            "     53        0.0107  0.0095\n",
            "     54        0.0107  0.0099\n",
            "     55        0.0104  0.0097\n",
            "     56        0.0108  0.0114\n",
            "     57        0.0110  0.0107\n",
            "     58        0.0103  0.0098\n",
            "     59        0.0108  0.0099\n",
            "     60        \u001b[36m0.0102\u001b[0m  0.0100\n",
            "     61        \u001b[36m0.0099\u001b[0m  0.0110\n",
            "     62        0.0099  0.0099\n",
            "     63        \u001b[36m0.0099\u001b[0m  0.0095\n",
            "     64        \u001b[36m0.0094\u001b[0m  0.0109\n",
            "     65        \u001b[36m0.0093\u001b[0m  0.0096\n",
            "     66        \u001b[36m0.0090\u001b[0m  0.0103\n",
            "     67        0.0100  0.0099\n",
            "     68        0.0095  0.0094\n",
            "     69        0.0098  0.0095\n",
            "     70        0.0091  0.0096\n",
            "     71        0.0091  0.0126\n",
            "     72        \u001b[36m0.0085\u001b[0m  0.0105\n",
            "     73        0.0086  0.0097\n",
            "     74        0.0091  0.0095\n",
            "     75        0.0088  0.0096\n",
            "     76        \u001b[36m0.0082\u001b[0m  0.0113\n",
            "     77        0.0086  0.0101\n",
            "     78        0.0086  0.0102\n",
            "     79        0.0088  0.0103\n",
            "     80        \u001b[36m0.0078\u001b[0m  0.0096\n",
            "     81        0.0081  0.0095\n",
            "     82        0.0082  0.0098\n",
            "     83        0.0084  0.0111\n",
            "     84        0.0078  0.0108\n",
            "     85        0.0079  0.0097\n",
            "     86        0.0084  0.0097\n",
            "     87        0.0079  0.0144\n",
            "     88        \u001b[36m0.0078\u001b[0m  0.0108\n",
            "     89        0.0082  0.0134\n",
            "     90        0.0081  0.0101\n",
            "     91        \u001b[36m0.0074\u001b[0m  0.0101\n",
            "     92        0.0074  0.0095\n",
            "     93        0.0078  0.0095\n",
            "     94        0.0075  0.0100\n",
            "     95        0.0079  0.0123\n",
            "     96        \u001b[36m0.0073\u001b[0m  0.0104\n",
            "     97        0.0078  0.0096\n",
            "     98        0.0076  0.0094\n",
            "     99        0.0074  0.0131\n",
            "    100        \u001b[36m0.0072\u001b[0m  0.0161\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1653\u001b[0m  0.0053\n",
            "      2        \u001b[36m0.1382\u001b[0m  0.0056\n",
            "      3        \u001b[36m0.1196\u001b[0m  0.0064\n",
            "      4        \u001b[36m0.1084\u001b[0m  0.0058\n",
            "      5        \u001b[36m0.1011\u001b[0m  0.0049\n",
            "      6        \u001b[36m0.0937\u001b[0m  0.0050\n",
            "      7        \u001b[36m0.0899\u001b[0m  0.0048\n",
            "      8        \u001b[36m0.0857\u001b[0m  0.0053\n",
            "      9        \u001b[36m0.0792\u001b[0m  0.0057\n",
            "     10        \u001b[36m0.0756\u001b[0m  0.0050\n",
            "     11        \u001b[36m0.0754\u001b[0m  0.0076\n",
            "     12        \u001b[36m0.0702\u001b[0m  0.0062\n",
            "     13        0.0702  0.0049\n",
            "     14        \u001b[36m0.0651\u001b[0m  0.0051\n",
            "     15        \u001b[36m0.0644\u001b[0m  0.0050\n",
            "     16        \u001b[36m0.0618\u001b[0m  0.0052\n",
            "     17        \u001b[36m0.0605\u001b[0m  0.0052\n",
            "     18        \u001b[36m0.0572\u001b[0m  0.0049\n",
            "     19        \u001b[36m0.0563\u001b[0m  0.0070\n",
            "     20        \u001b[36m0.0557\u001b[0m  0.0054\n",
            "     21        \u001b[36m0.0545\u001b[0m  0.0049\n",
            "     22        \u001b[36m0.0525\u001b[0m  0.0050\n",
            "     23        \u001b[36m0.0501\u001b[0m  0.0048\n",
            "     24        \u001b[36m0.0493\u001b[0m  0.0050\n",
            "     25        \u001b[36m0.0481\u001b[0m  0.0049\n",
            "     26        \u001b[36m0.0463\u001b[0m  0.0049\n",
            "     27        0.0463  0.0088\n",
            "     28        \u001b[36m0.0454\u001b[0m  0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     29        \u001b[36m0.0428\u001b[0m  0.0063\n",
            "     30        0.0438  0.0073\n",
            "     31        \u001b[36m0.0420\u001b[0m  0.0057\n",
            "     32        \u001b[36m0.0413\u001b[0m  0.0056\n",
            "     33        \u001b[36m0.0386\u001b[0m  0.0061\n",
            "     34        \u001b[36m0.0363\u001b[0m  0.0049\n",
            "     35        0.0377  0.0049\n",
            "     36        0.0380  0.0050\n",
            "     37        \u001b[36m0.0343\u001b[0m  0.0050\n",
            "     38        \u001b[36m0.0335\u001b[0m  0.0064\n",
            "     39        0.0341  0.0050\n",
            "     40        \u001b[36m0.0323\u001b[0m  0.0064\n",
            "     41        \u001b[36m0.0322\u001b[0m  0.0051\n",
            "     42        \u001b[36m0.0317\u001b[0m  0.0051\n",
            "     43        \u001b[36m0.0316\u001b[0m  0.0046\n",
            "     44        \u001b[36m0.0304\u001b[0m  0.0048\n",
            "     45        \u001b[36m0.0292\u001b[0m  0.0047\n",
            "     46        \u001b[36m0.0288\u001b[0m  0.0046\n",
            "     47        \u001b[36m0.0278\u001b[0m  0.0047\n",
            "     48        \u001b[36m0.0277\u001b[0m  0.0047\n",
            "     49        \u001b[36m0.0272\u001b[0m  0.0073\n",
            "     50        \u001b[36m0.0264\u001b[0m  0.0076\n",
            "     51        \u001b[36m0.0251\u001b[0m  0.0066\n",
            "     52        \u001b[36m0.0239\u001b[0m  0.0051\n",
            "     53        \u001b[36m0.0237\u001b[0m  0.0047\n",
            "     54        0.0239  0.0048\n",
            "     55        0.0244  0.0047\n",
            "     56        0.0239  0.0046\n",
            "     57        \u001b[36m0.0230\u001b[0m  0.0048\n",
            "     58        \u001b[36m0.0210\u001b[0m  0.0050\n",
            "     59        0.0217  0.0069\n",
            "     60        0.0214  0.0053\n",
            "     61        \u001b[36m0.0202\u001b[0m  0.0053\n",
            "     62        0.0224  0.0048\n",
            "     63        \u001b[36m0.0198\u001b[0m  0.0050\n",
            "     64        0.0215  0.0050\n",
            "     65        \u001b[36m0.0182\u001b[0m  0.0051\n",
            "     66        \u001b[36m0.0182\u001b[0m  0.0050\n",
            "     67        0.0186  0.0049\n",
            "     68        \u001b[36m0.0180\u001b[0m  0.0069\n",
            "     69        0.0185  0.0061\n",
            "     70        \u001b[36m0.0171\u001b[0m  0.0061\n",
            "     71        \u001b[36m0.0168\u001b[0m  0.0052\n",
            "     72        \u001b[36m0.0164\u001b[0m  0.0050\n",
            "     73        0.0171  0.0047\n",
            "     74        \u001b[36m0.0158\u001b[0m  0.0047\n",
            "     75        \u001b[36m0.0154\u001b[0m  0.0048\n",
            "     76        0.0154  0.0047\n",
            "     77        \u001b[36m0.0150\u001b[0m  0.0049\n",
            "     78        \u001b[36m0.0144\u001b[0m  0.0048\n",
            "     79        0.0148  0.0065\n",
            "     80        \u001b[36m0.0141\u001b[0m  0.0061\n",
            "     81        0.0155  0.0053\n",
            "     82        0.0146  0.0052\n",
            "     83        0.0144  0.0053\n",
            "     84        0.0144  0.0050\n",
            "     85        \u001b[36m0.0130\u001b[0m  0.0049\n",
            "     86        \u001b[36m0.0130\u001b[0m  0.0049\n",
            "     87        0.0135  0.0051\n",
            "     88        0.0131  0.0050\n",
            "     89        0.0130  0.0052\n",
            "     90        0.0134  0.0087\n",
            "     91        \u001b[36m0.0121\u001b[0m  0.0068\n",
            "     92        \u001b[36m0.0119\u001b[0m  0.0061\n",
            "     93        0.0126  0.0056\n",
            "     94        \u001b[36m0.0115\u001b[0m  0.0055\n",
            "     95        0.0132  0.0048\n",
            "     96        0.0119  0.0047\n",
            "     97        0.0119  0.0047\n",
            "     98        0.0120  0.0072\n",
            "     99        0.0121  0.0064\n",
            "    100        \u001b[36m0.0100\u001b[0m  0.0065\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1825\u001b[0m  0.0108\n",
            "      2        \u001b[36m0.1401\u001b[0m  0.0110\n",
            "      3        \u001b[36m0.1157\u001b[0m  0.0108\n",
            "      4        \u001b[36m0.1044\u001b[0m  0.0108\n",
            "      5        \u001b[36m0.0969\u001b[0m  0.0100\n",
            "      6        \u001b[36m0.0900\u001b[0m  0.0102\n",
            "      7        \u001b[36m0.0852\u001b[0m  0.0102\n",
            "      8        \u001b[36m0.0813\u001b[0m  0.0117\n",
            "      9        \u001b[36m0.0783\u001b[0m  0.0106\n",
            "     10        \u001b[36m0.0763\u001b[0m  0.0099\n",
            "     11        \u001b[36m0.0706\u001b[0m  0.0098\n",
            "     12        \u001b[36m0.0683\u001b[0m  0.0109\n",
            "     13        \u001b[36m0.0657\u001b[0m  0.0101\n",
            "     14        \u001b[36m0.0631\u001b[0m  0.0098\n",
            "     15        \u001b[36m0.0609\u001b[0m  0.0089\n",
            "     16        \u001b[36m0.0602\u001b[0m  0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0584\u001b[0m  0.0100\n",
            "     18        \u001b[36m0.0566\u001b[0m  0.0122\n",
            "     19        \u001b[36m0.0548\u001b[0m  0.0100\n",
            "     20        \u001b[36m0.0547\u001b[0m  0.0091\n",
            "     21        \u001b[36m0.0521\u001b[0m  0.0091\n",
            "     22        \u001b[36m0.0499\u001b[0m  0.0089\n",
            "     23        \u001b[36m0.0496\u001b[0m  0.0131\n",
            "     24        \u001b[36m0.0471\u001b[0m  0.0099\n",
            "     25        0.0472  0.0099\n",
            "     26        \u001b[36m0.0439\u001b[0m  0.0089\n",
            "     27        0.0444  0.0091\n",
            "     28        \u001b[36m0.0436\u001b[0m  0.0091\n",
            "     29        \u001b[36m0.0412\u001b[0m  0.0115\n",
            "     30        \u001b[36m0.0396\u001b[0m  0.0099\n",
            "     31        0.0401  0.0153\n",
            "     32        \u001b[36m0.0385\u001b[0m  0.0138\n",
            "     33        \u001b[36m0.0366\u001b[0m  0.0098\n",
            "     34        \u001b[36m0.0362\u001b[0m  0.0109\n",
            "     35        \u001b[36m0.0359\u001b[0m  0.0096\n",
            "     36        \u001b[36m0.0339\u001b[0m  0.0095\n",
            "     37        \u001b[36m0.0338\u001b[0m  0.0091\n",
            "     38        \u001b[36m0.0319\u001b[0m  0.0089\n",
            "     39        0.0326  0.0141\n",
            "     40        \u001b[36m0.0308\u001b[0m  0.0096\n",
            "     41        0.0311  0.0096\n",
            "     42        \u001b[36m0.0298\u001b[0m  0.0096\n",
            "     43        \u001b[36m0.0292\u001b[0m  0.0097\n",
            "     44        \u001b[36m0.0277\u001b[0m  0.0095\n",
            "     45        0.0280  0.0090\n",
            "     46        \u001b[36m0.0273\u001b[0m  0.0101\n",
            "     47        \u001b[36m0.0267\u001b[0m  0.0089\n",
            "     48        \u001b[36m0.0254\u001b[0m  0.0120\n",
            "     49        0.0258  0.0094\n",
            "     50        0.0257  0.0104\n",
            "     51        \u001b[36m0.0240\u001b[0m  0.0100\n",
            "     52        \u001b[36m0.0236\u001b[0m  0.0091\n",
            "     53        0.0237  0.0100\n",
            "     54        0.0238  0.0090\n",
            "     55        0.0248  0.0125\n",
            "     56        \u001b[36m0.0223\u001b[0m  0.0097\n",
            "     57        \u001b[36m0.0223\u001b[0m  0.0090\n",
            "     58        0.0226  0.0089\n",
            "     59        \u001b[36m0.0221\u001b[0m  0.0090\n",
            "     60        \u001b[36m0.0220\u001b[0m  0.0114\n",
            "     61        \u001b[36m0.0209\u001b[0m  0.0097\n",
            "     62        \u001b[36m0.0207\u001b[0m  0.0101\n",
            "     63        0.0209  0.0102\n",
            "     64        \u001b[36m0.0207\u001b[0m  0.0093\n",
            "     65        \u001b[36m0.0195\u001b[0m  0.0091\n",
            "     66        0.0202  0.0113\n",
            "     67        0.0198  0.0099\n",
            "     68        0.0204  0.0100\n",
            "     69        0.0197  0.0093\n",
            "     70        \u001b[36m0.0183\u001b[0m  0.0092\n",
            "     71        \u001b[36m0.0182\u001b[0m  0.0087\n",
            "     72        0.0189  0.0120\n",
            "     73        \u001b[36m0.0171\u001b[0m  0.0101\n",
            "     74        0.0175  0.0112\n",
            "     75        0.0177  0.0098\n",
            "     76        0.0177  0.0102\n",
            "     77        0.0181  0.0093\n",
            "     78        \u001b[36m0.0168\u001b[0m  0.0093\n",
            "     79        \u001b[36m0.0164\u001b[0m  0.0092\n",
            "     80        \u001b[36m0.0159\u001b[0m  0.0118\n",
            "     81        0.0160  0.0100\n",
            "     82        0.0163  0.0092\n",
            "     83        0.0164  0.0093\n",
            "     84        0.0170  0.0092\n",
            "     85        \u001b[36m0.0155\u001b[0m  0.0111\n",
            "     86        0.0158  0.0099\n",
            "     87        \u001b[36m0.0152\u001b[0m  0.0115\n",
            "     88        0.0164  0.0116\n",
            "     89        \u001b[36m0.0152\u001b[0m  0.0102\n",
            "     90        0.0158  0.0097\n",
            "     91        0.0161  0.0098\n",
            "     92        0.0171  0.0108\n",
            "     93        \u001b[36m0.0146\u001b[0m  0.0093\n",
            "     94        0.0150  0.0091\n",
            "     95        \u001b[36m0.0143\u001b[0m  0.0091\n",
            "     96        0.0156  0.0120\n",
            "     97        \u001b[36m0.0137\u001b[0m  0.0099\n",
            "     98        \u001b[36m0.0137\u001b[0m  0.0100\n",
            "     99        0.0143  0.0098\n",
            "    100        0.0146  0.0092\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1707\u001b[0m  0.0120\n",
            "      2        \u001b[36m0.1230\u001b[0m  0.0103\n",
            "      3        \u001b[36m0.1042\u001b[0m  0.0103\n",
            "      4        \u001b[36m0.0921\u001b[0m  0.0106\n",
            "      5        \u001b[36m0.0853\u001b[0m  0.0094\n",
            "      6        \u001b[36m0.0793\u001b[0m  0.0094\n",
            "      7        \u001b[36m0.0746\u001b[0m  0.0096\n",
            "      8        \u001b[36m0.0708\u001b[0m  0.0130\n",
            "      9        \u001b[36m0.0671\u001b[0m  0.0116\n",
            "     10        \u001b[36m0.0657\u001b[0m  0.0097\n",
            "     11        \u001b[36m0.0618\u001b[0m  0.0096\n",
            "     12        \u001b[36m0.0600\u001b[0m  0.0115\n",
            "     13        \u001b[36m0.0571\u001b[0m  0.0104\n",
            "     14        \u001b[36m0.0557\u001b[0m  0.0104\n",
            "     15        \u001b[36m0.0529\u001b[0m  0.0096\n",
            "     16        \u001b[36m0.0507\u001b[0m  0.0097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0487\u001b[0m  0.0113\n",
            "     18        \u001b[36m0.0473\u001b[0m  0.0109\n",
            "     19        \u001b[36m0.0456\u001b[0m  0.0102\n",
            "     20        \u001b[36m0.0447\u001b[0m  0.0098\n",
            "     21        \u001b[36m0.0426\u001b[0m  0.0095\n",
            "     22        \u001b[36m0.0414\u001b[0m  0.0096\n",
            "     23        \u001b[36m0.0400\u001b[0m  0.0133\n",
            "     24        \u001b[36m0.0383\u001b[0m  0.0184\n",
            "     25        \u001b[36m0.0372\u001b[0m  0.0147\n",
            "     26        \u001b[36m0.0362\u001b[0m  0.0108\n",
            "     27        \u001b[36m0.0342\u001b[0m  0.0104\n",
            "     28        \u001b[36m0.0338\u001b[0m  0.0103\n",
            "     29        \u001b[36m0.0332\u001b[0m  0.0094\n",
            "     30        \u001b[36m0.0317\u001b[0m  0.0109\n",
            "     31        \u001b[36m0.0300\u001b[0m  0.0097\n",
            "     32        \u001b[36m0.0299\u001b[0m  0.0109\n",
            "     33        \u001b[36m0.0283\u001b[0m  0.0103\n",
            "     34        \u001b[36m0.0274\u001b[0m  0.0095\n",
            "     35        \u001b[36m0.0272\u001b[0m  0.0108\n",
            "     36        \u001b[36m0.0263\u001b[0m  0.0102\n",
            "     37        \u001b[36m0.0252\u001b[0m  0.0114\n",
            "     38        \u001b[36m0.0251\u001b[0m  0.0109\n",
            "     39        \u001b[36m0.0242\u001b[0m  0.0096\n",
            "     40        0.0243  0.0095\n",
            "     41        \u001b[36m0.0229\u001b[0m  0.0097\n",
            "     42        \u001b[36m0.0225\u001b[0m  0.0138\n",
            "     43        0.0226  0.0101\n",
            "     44        \u001b[36m0.0208\u001b[0m  0.0097\n",
            "     45        \u001b[36m0.0206\u001b[0m  0.0095\n",
            "     46        0.0213  0.0094\n",
            "     47        0.0212  0.0122\n",
            "     48        \u001b[36m0.0200\u001b[0m  0.0103\n",
            "     49        \u001b[36m0.0196\u001b[0m  0.0102\n",
            "     50        \u001b[36m0.0187\u001b[0m  0.0106\n",
            "     51        0.0190  0.0100\n",
            "     52        \u001b[36m0.0180\u001b[0m  0.0099\n",
            "     53        \u001b[36m0.0178\u001b[0m  0.0121\n",
            "     54        \u001b[36m0.0169\u001b[0m  0.0102\n",
            "     55        \u001b[36m0.0167\u001b[0m  0.0106\n",
            "     56        \u001b[36m0.0162\u001b[0m  0.0095\n",
            "     57        \u001b[36m0.0160\u001b[0m  0.0094\n",
            "     58        0.0161  0.0099\n",
            "     59        \u001b[36m0.0157\u001b[0m  0.0131\n",
            "     60        \u001b[36m0.0157\u001b[0m  0.0102\n",
            "     61        \u001b[36m0.0145\u001b[0m  0.0103\n",
            "     62        \u001b[36m0.0145\u001b[0m  0.0096\n",
            "     63        0.0151  0.0096\n",
            "     64        \u001b[36m0.0139\u001b[0m  0.0094\n",
            "     65        0.0148  0.0115\n",
            "     66        0.0148  0.0101\n",
            "     67        0.0145  0.0106\n",
            "     68        0.0140  0.0095\n",
            "     69        0.0146  0.0095\n",
            "     70        \u001b[36m0.0131\u001b[0m  0.0098\n",
            "     71        0.0140  0.0116\n",
            "     72        0.0133  0.0103\n",
            "     73        \u001b[36m0.0129\u001b[0m  0.0104\n",
            "     74        0.0135  0.0094\n",
            "     75        0.0130  0.0095\n",
            "     76        0.0131  0.0135\n",
            "     77        \u001b[36m0.0119\u001b[0m  0.0124\n",
            "     78        0.0127  0.0100\n",
            "     79        0.0125  0.0102\n",
            "     80        0.0128  0.0108\n",
            "     81        0.0122  0.0103\n",
            "     82        \u001b[36m0.0115\u001b[0m  0.0104\n",
            "     83        0.0122  0.0095\n",
            "     84        0.0128  0.0095\n",
            "     85        0.0121  0.0094\n",
            "     86        0.0118  0.0120\n",
            "     87        \u001b[36m0.0115\u001b[0m  0.0101\n",
            "     88        \u001b[36m0.0110\u001b[0m  0.0095\n",
            "     89        0.0116  0.0094\n",
            "     90        0.0121  0.0096\n",
            "     91        0.0110  0.0115\n",
            "     92        0.0119  0.0117\n",
            "     93        \u001b[36m0.0110\u001b[0m  0.0094\n",
            "     94        \u001b[36m0.0108\u001b[0m  0.0094\n",
            "     95        \u001b[36m0.0105\u001b[0m  0.0098\n",
            "     96        0.0107  0.0109\n",
            "     97        \u001b[36m0.0103\u001b[0m  0.0103\n",
            "     98        0.0108  0.0104\n",
            "     99        0.0106  0.0116\n",
            "    100        0.0107  0.0101\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1799\u001b[0m  0.0059\n",
            "      2        \u001b[36m0.1406\u001b[0m  0.0060\n",
            "      3        \u001b[36m0.1197\u001b[0m  0.0077\n",
            "      4        \u001b[36m0.1066\u001b[0m  0.0061\n",
            "      5        \u001b[36m0.0961\u001b[0m  0.0064\n",
            "      6        \u001b[36m0.0933\u001b[0m  0.0058\n",
            "      7        \u001b[36m0.0866\u001b[0m  0.0057\n",
            "      8        \u001b[36m0.0834\u001b[0m  0.0059\n",
            "      9        \u001b[36m0.0798\u001b[0m  0.0058\n",
            "     10        \u001b[36m0.0779\u001b[0m  0.0061\n",
            "     11        \u001b[36m0.0766\u001b[0m  0.0079\n",
            "     12        \u001b[36m0.0714\u001b[0m  0.0072\n",
            "     13        \u001b[36m0.0702\u001b[0m  0.0064\n",
            "     14        \u001b[36m0.0700\u001b[0m  0.0059\n",
            "     15        \u001b[36m0.0671\u001b[0m  0.0061\n",
            "     16        \u001b[36m0.0645\u001b[0m  0.0056\n",
            "     17        \u001b[36m0.0629\u001b[0m  0.0060\n",
            "     18        \u001b[36m0.0609\u001b[0m  0.0060\n",
            "     19        \u001b[36m0.0594\u001b[0m  0.0082\n",
            "     20        \u001b[36m0.0571\u001b[0m  0.0081\n",
            "     21        \u001b[36m0.0542\u001b[0m  0.0084\n",
            "     22        0.0544  0.0090\n",
            "     23        \u001b[36m0.0537\u001b[0m  0.0089\n",
            "     24        \u001b[36m0.0515\u001b[0m  0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     25        \u001b[36m0.0489\u001b[0m  0.0086\n",
            "     26        \u001b[36m0.0476\u001b[0m  0.0063\n",
            "     27        0.0482  0.0062\n",
            "     28        \u001b[36m0.0456\u001b[0m  0.0058\n",
            "     29        \u001b[36m0.0444\u001b[0m  0.0072\n",
            "     30        \u001b[36m0.0432\u001b[0m  0.0059\n",
            "     31        \u001b[36m0.0407\u001b[0m  0.0057\n",
            "     32        \u001b[36m0.0399\u001b[0m  0.0058\n",
            "     33        \u001b[36m0.0387\u001b[0m  0.0099\n",
            "     34        \u001b[36m0.0383\u001b[0m  0.0066\n",
            "     35        \u001b[36m0.0365\u001b[0m  0.0061\n",
            "     36        \u001b[36m0.0365\u001b[0m  0.0056\n",
            "     37        \u001b[36m0.0340\u001b[0m  0.0058\n",
            "     38        \u001b[36m0.0322\u001b[0m  0.0057\n",
            "     39        0.0334  0.0063\n",
            "     40        \u001b[36m0.0318\u001b[0m  0.0097\n",
            "     41        \u001b[36m0.0308\u001b[0m  0.0073\n",
            "     42        \u001b[36m0.0302\u001b[0m  0.0065\n",
            "     43        \u001b[36m0.0286\u001b[0m  0.0060\n",
            "     44        0.0294  0.0065\n",
            "     45        \u001b[36m0.0276\u001b[0m  0.0059\n",
            "     46        \u001b[36m0.0258\u001b[0m  0.0058\n",
            "     47        0.0258  0.0057\n",
            "     48        \u001b[36m0.0242\u001b[0m  0.0092\n",
            "     49        0.0245  0.0063\n",
            "     50        \u001b[36m0.0239\u001b[0m  0.0066\n",
            "     51        \u001b[36m0.0229\u001b[0m  0.0065\n",
            "     52        \u001b[36m0.0227\u001b[0m  0.0063\n",
            "     53        \u001b[36m0.0226\u001b[0m  0.0055\n",
            "     54        \u001b[36m0.0203\u001b[0m  0.0055\n",
            "     55        0.0212  0.0054\n",
            "     56        0.0220  0.0055\n",
            "     57        0.0214  0.0055\n",
            "     58        \u001b[36m0.0200\u001b[0m  0.0069\n",
            "     59        \u001b[36m0.0186\u001b[0m  0.0073\n",
            "     60        0.0188  0.0065\n",
            "     61        0.0193  0.0057\n",
            "     62        \u001b[36m0.0176\u001b[0m  0.0055\n",
            "     63        0.0190  0.0058\n",
            "     64        \u001b[36m0.0165\u001b[0m  0.0073\n",
            "     65        \u001b[36m0.0163\u001b[0m  0.0059\n",
            "     66        0.0164  0.0088\n",
            "     67        \u001b[36m0.0155\u001b[0m  0.0059\n",
            "     68        \u001b[36m0.0149\u001b[0m  0.0066\n",
            "     69        \u001b[36m0.0147\u001b[0m  0.0064\n",
            "     70        0.0155  0.0056\n",
            "     71        \u001b[36m0.0136\u001b[0m  0.0057\n",
            "     72        0.0141  0.0057\n",
            "     73        0.0156  0.0057\n",
            "     74        0.0138  0.0060\n",
            "     75        \u001b[36m0.0125\u001b[0m  0.0092\n",
            "     76        0.0145  0.0073\n",
            "     77        \u001b[36m0.0120\u001b[0m  0.0071\n",
            "     78        0.0128  0.0066\n",
            "     79        \u001b[36m0.0120\u001b[0m  0.0065\n",
            "     80        \u001b[36m0.0111\u001b[0m  0.0067\n",
            "     81        0.0113  0.0065\n",
            "     82        0.0117  0.0057\n",
            "     83        \u001b[36m0.0103\u001b[0m  0.0058\n",
            "     84        0.0107  0.0058\n",
            "     85        \u001b[36m0.0101\u001b[0m  0.0060\n",
            "     86        0.0105  0.0059\n",
            "     87        0.0116  0.0084\n",
            "     88        0.0103  0.0065\n",
            "     89        0.0106  0.0074\n",
            "     90        \u001b[36m0.0087\u001b[0m  0.0059\n",
            "     91        0.0088  0.0060\n",
            "     92        0.0091  0.0061\n",
            "     93        0.0107  0.0060\n",
            "     94        0.0095  0.0058\n",
            "     95        0.0100  0.0078\n",
            "     96        \u001b[36m0.0084\u001b[0m  0.0065\n",
            "     97        0.0087  0.0056\n",
            "     98        \u001b[36m0.0077\u001b[0m  0.0057\n",
            "     99        0.0090  0.0071\n",
            "    100        0.0085  0.0070\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1872\u001b[0m  0.0127\n",
            "      2        \u001b[36m0.1282\u001b[0m  0.0116\n",
            "      3        \u001b[36m0.1112\u001b[0m  0.0116\n",
            "      4        \u001b[36m0.1048\u001b[0m  0.0118\n",
            "      5        \u001b[36m0.0973\u001b[0m  0.0111\n",
            "      6        \u001b[36m0.0937\u001b[0m  0.0110\n",
            "      7        \u001b[36m0.0873\u001b[0m  0.0127\n",
            "      8        \u001b[36m0.0835\u001b[0m  0.0119\n",
            "      9        \u001b[36m0.0828\u001b[0m  0.0122\n",
            "     10        \u001b[36m0.0807\u001b[0m  0.0116\n",
            "     11        \u001b[36m0.0776\u001b[0m  0.0110\n",
            "     12        \u001b[36m0.0760\u001b[0m  0.0140\n",
            "     13        \u001b[36m0.0730\u001b[0m  0.0122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     14        \u001b[36m0.0710\u001b[0m  0.0141\n",
            "     15        \u001b[36m0.0681\u001b[0m  0.0115\n",
            "     16        \u001b[36m0.0678\u001b[0m  0.0110\n",
            "     17        \u001b[36m0.0645\u001b[0m  0.0144\n",
            "     18        \u001b[36m0.0626\u001b[0m  0.0136\n",
            "     19        \u001b[36m0.0600\u001b[0m  0.0122\n",
            "     20        \u001b[36m0.0585\u001b[0m  0.0110\n",
            "     21        \u001b[36m0.0566\u001b[0m  0.0114\n",
            "     22        \u001b[36m0.0546\u001b[0m  0.0137\n",
            "     23        \u001b[36m0.0525\u001b[0m  0.0120\n",
            "     24        0.0532  0.0126\n",
            "     25        \u001b[36m0.0508\u001b[0m  0.0113\n",
            "     26        \u001b[36m0.0497\u001b[0m  0.0110\n",
            "     27        \u001b[36m0.0484\u001b[0m  0.0135\n",
            "     28        \u001b[36m0.0472\u001b[0m  0.0136\n",
            "     29        \u001b[36m0.0462\u001b[0m  0.0119\n",
            "     30        \u001b[36m0.0449\u001b[0m  0.0117\n",
            "     31        \u001b[36m0.0445\u001b[0m  0.0109\n",
            "     32        0.0445  0.0142\n",
            "     33        \u001b[36m0.0429\u001b[0m  0.0172\n",
            "     34        \u001b[36m0.0413\u001b[0m  0.0193\n",
            "     35        \u001b[36m0.0398\u001b[0m  0.0123\n",
            "     36        \u001b[36m0.0391\u001b[0m  0.0123\n",
            "     37        \u001b[36m0.0387\u001b[0m  0.0122\n",
            "     38        \u001b[36m0.0363\u001b[0m  0.0108\n",
            "     39        0.0374  0.0130\n",
            "     40        \u001b[36m0.0356\u001b[0m  0.0124\n",
            "     41        0.0360  0.0118\n",
            "     42        \u001b[36m0.0349\u001b[0m  0.0131\n",
            "     43        \u001b[36m0.0332\u001b[0m  0.0121\n",
            "     44        \u001b[36m0.0328\u001b[0m  0.0124\n",
            "     45        \u001b[36m0.0312\u001b[0m  0.0109\n",
            "     46        \u001b[36m0.0311\u001b[0m  0.0109\n",
            "     47        0.0317  0.0131\n",
            "     48        \u001b[36m0.0299\u001b[0m  0.0121\n",
            "     49        0.0308  0.0117\n",
            "     50        \u001b[36m0.0294\u001b[0m  0.0122\n",
            "     51        0.0297  0.0120\n",
            "     52        \u001b[36m0.0281\u001b[0m  0.0119\n",
            "     53        \u001b[36m0.0270\u001b[0m  0.0119\n",
            "     54        0.0272  0.0118\n",
            "     55        \u001b[36m0.0251\u001b[0m  0.0109\n",
            "     56        0.0258  0.0110\n",
            "     57        0.0271  0.0169\n",
            "     58        0.0264  0.0115\n",
            "     59        0.0251  0.0118\n",
            "     60        \u001b[36m0.0245\u001b[0m  0.0109\n",
            "     61        0.0249  0.0110\n",
            "     62        \u001b[36m0.0244\u001b[0m  0.0136\n",
            "     63        \u001b[36m0.0240\u001b[0m  0.0115\n",
            "     64        \u001b[36m0.0236\u001b[0m  0.0118\n",
            "     65        \u001b[36m0.0228\u001b[0m  0.0108\n",
            "     66        \u001b[36m0.0221\u001b[0m  0.0111\n",
            "     67        0.0236  0.0129\n",
            "     68        0.0227  0.0122\n",
            "     69        0.0243  0.0114\n",
            "     70        \u001b[36m0.0212\u001b[0m  0.0110\n",
            "     71        0.0216  0.0113\n",
            "     72        0.0213  0.0134\n",
            "     73        0.0215  0.0119\n",
            "     74        0.0222  0.0114\n",
            "     75        \u001b[36m0.0202\u001b[0m  0.0108\n",
            "     76        \u001b[36m0.0189\u001b[0m  0.0107\n",
            "     77        0.0203  0.0156\n",
            "     78        0.0197  0.0129\n",
            "     79        \u001b[36m0.0184\u001b[0m  0.0118\n",
            "     80        0.0193  0.0107\n",
            "     81        0.0186  0.0108\n",
            "     82        0.0188  0.0126\n",
            "     83        \u001b[36m0.0179\u001b[0m  0.0115\n",
            "     84        0.0179  0.0118\n",
            "     85        0.0188  0.0119\n",
            "     86        0.0184  0.0117\n",
            "     87        \u001b[36m0.0170\u001b[0m  0.0107\n",
            "     88        0.0177  0.0107\n",
            "     89        0.0180  0.0136\n",
            "     90        \u001b[36m0.0164\u001b[0m  0.0122\n",
            "     91        0.0185  0.0116\n",
            "     92        0.0166  0.0119\n",
            "     93        0.0171  0.0118\n",
            "     94        0.0178  0.0108\n",
            "     95        0.0180  0.0108\n",
            "     96        0.0173  0.0130\n",
            "     97        0.0177  0.0132\n",
            "     98        0.0171  0.0116\n",
            "     99        0.0166  0.0109\n",
            "    100        \u001b[36m0.0161\u001b[0m  0.0108\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1708\u001b[0m  0.0132\n",
            "      2        \u001b[36m0.1214\u001b[0m  0.0128\n",
            "      3        \u001b[36m0.1024\u001b[0m  0.0125\n",
            "      4        \u001b[36m0.0912\u001b[0m  0.0122\n",
            "      5        \u001b[36m0.0851\u001b[0m  0.0115\n",
            "      6        \u001b[36m0.0818\u001b[0m  0.0122\n",
            "      7        \u001b[36m0.0764\u001b[0m  0.0140\n",
            "      8        \u001b[36m0.0736\u001b[0m  0.0122\n",
            "      9        \u001b[36m0.0706\u001b[0m  0.0124\n",
            "     10        \u001b[36m0.0691\u001b[0m  0.0116\n",
            "     11        \u001b[36m0.0666\u001b[0m  0.0157\n",
            "     12        \u001b[36m0.0634\u001b[0m  0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0612\u001b[0m  0.0143\n",
            "     14        \u001b[36m0.0582\u001b[0m  0.0113\n",
            "     15        \u001b[36m0.0566\u001b[0m  0.0123\n",
            "     16        \u001b[36m0.0537\u001b[0m  0.0160\n",
            "     17        \u001b[36m0.0516\u001b[0m  0.0122\n",
            "     18        \u001b[36m0.0495\u001b[0m  0.0125\n",
            "     19        \u001b[36m0.0492\u001b[0m  0.0132\n",
            "     20        \u001b[36m0.0462\u001b[0m  0.0117\n",
            "     21        \u001b[36m0.0447\u001b[0m  0.0134\n",
            "     22        \u001b[36m0.0425\u001b[0m  0.0122\n",
            "     23        \u001b[36m0.0408\u001b[0m  0.0122\n",
            "     24        \u001b[36m0.0386\u001b[0m  0.0113\n",
            "     25        \u001b[36m0.0370\u001b[0m  0.0112\n",
            "     26        \u001b[36m0.0365\u001b[0m  0.0140\n",
            "     27        \u001b[36m0.0346\u001b[0m  0.0122\n",
            "     28        \u001b[36m0.0341\u001b[0m  0.0141\n",
            "     29        \u001b[36m0.0322\u001b[0m  0.0116\n",
            "     30        \u001b[36m0.0310\u001b[0m  0.0117\n",
            "     31        \u001b[36m0.0303\u001b[0m  0.0137\n",
            "     32        \u001b[36m0.0296\u001b[0m  0.0128\n",
            "     33        \u001b[36m0.0276\u001b[0m  0.0135\n",
            "     34        \u001b[36m0.0275\u001b[0m  0.0114\n",
            "     35        \u001b[36m0.0259\u001b[0m  0.0114\n",
            "     36        \u001b[36m0.0255\u001b[0m  0.0144\n",
            "     37        \u001b[36m0.0250\u001b[0m  0.0125\n",
            "     38        \u001b[36m0.0234\u001b[0m  0.0123\n",
            "     39        0.0238  0.0117\n",
            "     40        \u001b[36m0.0221\u001b[0m  0.0115\n",
            "     41        \u001b[36m0.0218\u001b[0m  0.0139\n",
            "     42        \u001b[36m0.0214\u001b[0m  0.0123\n",
            "     43        \u001b[36m0.0204\u001b[0m  0.0127\n",
            "     44        \u001b[36m0.0199\u001b[0m  0.0116\n",
            "     45        \u001b[36m0.0198\u001b[0m  0.0115\n",
            "     46        \u001b[36m0.0188\u001b[0m  0.0141\n",
            "     47        0.0191  0.0124\n",
            "     48        \u001b[36m0.0186\u001b[0m  0.0123\n",
            "     49        \u001b[36m0.0171\u001b[0m  0.0126\n",
            "     50        0.0181  0.0123\n",
            "     51        0.0179  0.0114\n",
            "     52        0.0174  0.0139\n",
            "     53        0.0172  0.0145\n",
            "     54        0.0173  0.0122\n",
            "     55        \u001b[36m0.0169\u001b[0m  0.0127\n",
            "     56        \u001b[36m0.0158\u001b[0m  0.0113\n",
            "     57        \u001b[36m0.0158\u001b[0m  0.0115\n",
            "     58        0.0167  0.0148\n",
            "     59        0.0159  0.0119\n",
            "     60        \u001b[36m0.0154\u001b[0m  0.0130\n",
            "     61        \u001b[36m0.0142\u001b[0m  0.0116\n",
            "     62        \u001b[36m0.0139\u001b[0m  0.0113\n",
            "     63        0.0142  0.0133\n",
            "     64        0.0142  0.0131\n",
            "     65        0.0144  0.0123\n",
            "     66        0.0144  0.0125\n",
            "     67        \u001b[36m0.0137\u001b[0m  0.0113\n",
            "     68        \u001b[36m0.0136\u001b[0m  0.0115\n",
            "     69        \u001b[36m0.0128\u001b[0m  0.0140\n",
            "     70        0.0130  0.0124\n",
            "     71        \u001b[36m0.0124\u001b[0m  0.0138\n",
            "     72        \u001b[36m0.0122\u001b[0m  0.0136\n",
            "     73        0.0125  0.0124\n",
            "     74        0.0123  0.0114\n",
            "     75        \u001b[36m0.0117\u001b[0m  0.0114\n",
            "     76        0.0126  0.0141\n",
            "     77        0.0122  0.0125\n",
            "     78        0.0122  0.0128\n",
            "     79        \u001b[36m0.0117\u001b[0m  0.0122\n",
            "     80        0.0119  0.0114\n",
            "     81        \u001b[36m0.0116\u001b[0m  0.0142\n",
            "     82        \u001b[36m0.0114\u001b[0m  0.0125\n",
            "     83        \u001b[36m0.0111\u001b[0m  0.0125\n",
            "     84        0.0114  0.0116\n",
            "     85        0.0114  0.0116\n",
            "     86        \u001b[36m0.0108\u001b[0m  0.0142\n",
            "     87        0.0109  0.0177\n",
            "     88        \u001b[36m0.0105\u001b[0m  0.0179\n",
            "     89        0.0111  0.0162\n",
            "     90        0.0113  0.0122\n",
            "     91        0.0110  0.0124\n",
            "     92        0.0112  0.0111\n",
            "     93        \u001b[36m0.0097\u001b[0m  0.0116\n",
            "     94        0.0106  0.0142\n",
            "     95        0.0104  0.0122\n",
            "     96        0.0105  0.0126\n",
            "     97        0.0097  0.0116\n",
            "     98        0.0116  0.0115\n",
            "     99        0.0100  0.0139\n",
            "    100        0.0099  0.0124\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1634\u001b[0m  0.0067\n",
            "      2        \u001b[36m0.1267\u001b[0m  0.0059\n",
            "      3        \u001b[36m0.1101\u001b[0m  0.0061\n",
            "      4        \u001b[36m0.0972\u001b[0m  0.0064\n",
            "      5        \u001b[36m0.0921\u001b[0m  0.0076\n",
            "      6        \u001b[36m0.0876\u001b[0m  0.0068\n",
            "      7        \u001b[36m0.0829\u001b[0m  0.0059\n",
            "      8        \u001b[36m0.0786\u001b[0m  0.0059\n",
            "      9        0.0797  0.0058\n",
            "     10        \u001b[36m0.0764\u001b[0m  0.0059\n",
            "     11        \u001b[36m0.0746\u001b[0m  0.0058\n",
            "     12        \u001b[36m0.0727\u001b[0m  0.0101\n",
            "     13        \u001b[36m0.0687\u001b[0m  0.0085\n",
            "     14        \u001b[36m0.0680\u001b[0m  0.0064\n",
            "     15        \u001b[36m0.0643\u001b[0m  0.0069\n",
            "     16        \u001b[36m0.0637\u001b[0m  0.0059\n",
            "     17        \u001b[36m0.0623\u001b[0m  0.0057\n",
            "     18        \u001b[36m0.0600\u001b[0m  0.0059\n",
            "     19        \u001b[36m0.0572\u001b[0m  0.0057\n",
            "     20        0.0574  0.0060\n",
            "     21        \u001b[36m0.0555\u001b[0m  0.0078\n",
            "     22        \u001b[36m0.0531\u001b[0m  0.0072\n",
            "     23        0.0534  0.0064\n",
            "     24        \u001b[36m0.0496\u001b[0m  0.0071\n",
            "     25        0.0505  0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     26        \u001b[36m0.0468\u001b[0m  0.0080\n",
            "     27        \u001b[36m0.0450\u001b[0m  0.0065\n",
            "     28        0.0451  0.0066\n",
            "     29        \u001b[36m0.0438\u001b[0m  0.0060\n",
            "     30        \u001b[36m0.0420\u001b[0m  0.0060\n",
            "     31        \u001b[36m0.0398\u001b[0m  0.0063\n",
            "     32        0.0406  0.0060\n",
            "     33        \u001b[36m0.0376\u001b[0m  0.0060\n",
            "     34        \u001b[36m0.0371\u001b[0m  0.0084\n",
            "     35        \u001b[36m0.0350\u001b[0m  0.0071\n",
            "     36        \u001b[36m0.0335\u001b[0m  0.0071\n",
            "     37        \u001b[36m0.0334\u001b[0m  0.0063\n",
            "     38        \u001b[36m0.0319\u001b[0m  0.0058\n",
            "     39        0.0325  0.0058\n",
            "     40        \u001b[36m0.0297\u001b[0m  0.0057\n",
            "     41        \u001b[36m0.0283\u001b[0m  0.0061\n",
            "     42        \u001b[36m0.0279\u001b[0m  0.0058\n",
            "     43        0.0289  0.0079\n",
            "     44        \u001b[36m0.0257\u001b[0m  0.0075\n",
            "     45        0.0266  0.0064\n",
            "     46        \u001b[36m0.0229\u001b[0m  0.0068\n",
            "     47        \u001b[36m0.0222\u001b[0m  0.0084\n",
            "     48        \u001b[36m0.0213\u001b[0m  0.0078\n",
            "     49        0.0217  0.0071\n",
            "     50        0.0216  0.0058\n",
            "     51        0.0227  0.0058\n",
            "     52        \u001b[36m0.0197\u001b[0m  0.0060\n",
            "     53        \u001b[36m0.0187\u001b[0m  0.0061\n",
            "     54        \u001b[36m0.0178\u001b[0m  0.0073\n",
            "     55        0.0180  0.0073\n",
            "     56        0.0184  0.0058\n",
            "     57        0.0180  0.0060\n",
            "     58        0.0185  0.0059\n",
            "     59        \u001b[36m0.0163\u001b[0m  0.0060\n",
            "     60        \u001b[36m0.0155\u001b[0m  0.0059\n",
            "     61        \u001b[36m0.0153\u001b[0m  0.0083\n",
            "     62        \u001b[36m0.0152\u001b[0m  0.0065\n",
            "     63        0.0170  0.0059\n",
            "     64        \u001b[36m0.0138\u001b[0m  0.0059\n",
            "     65        \u001b[36m0.0135\u001b[0m  0.0059\n",
            "     66        0.0145  0.0059\n",
            "     67        \u001b[36m0.0132\u001b[0m  0.0060\n",
            "     68        0.0140  0.0096\n",
            "     69        \u001b[36m0.0130\u001b[0m  0.0074\n",
            "     70        0.0132  0.0065\n",
            "     71        0.0144  0.0068\n",
            "     72        \u001b[36m0.0125\u001b[0m  0.0066\n",
            "     73        0.0127  0.0059\n",
            "     74        \u001b[36m0.0122\u001b[0m  0.0058\n",
            "     75        \u001b[36m0.0120\u001b[0m  0.0059\n",
            "     76        0.0126  0.0059\n",
            "     77        \u001b[36m0.0106\u001b[0m  0.0059\n",
            "     78        0.0112  0.0077\n",
            "     79        \u001b[36m0.0103\u001b[0m  0.0071\n",
            "     80        0.0117  0.0065\n",
            "     81        0.0117  0.0077\n",
            "     82        0.0116  0.0066\n",
            "     83        0.0105  0.0059\n",
            "     84        0.0110  0.0072\n",
            "     85        \u001b[36m0.0092\u001b[0m  0.0090\n",
            "     86        0.0094  0.0089\n",
            "     87        0.0109  0.0104\n",
            "     88        0.0096  0.0066\n",
            "     89        \u001b[36m0.0088\u001b[0m  0.0101\n",
            "     90        0.0092  0.0099\n",
            "     91        0.0092  0.0082\n",
            "     92        0.0095  0.0076\n",
            "     93        \u001b[36m0.0083\u001b[0m  0.0075\n",
            "     94        0.0092  0.0079\n",
            "     95        \u001b[36m0.0083\u001b[0m  0.0076\n",
            "     96        0.0090  0.0090\n",
            "     97        0.0088  0.0091\n",
            "     98        \u001b[36m0.0083\u001b[0m  0.0075\n",
            "     99        0.0087  0.0078\n",
            "    100        \u001b[36m0.0082\u001b[0m  0.0076\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.2168\u001b[0m  0.0178\n",
            "      2        \u001b[36m0.1377\u001b[0m  0.0226\n",
            "      3        \u001b[36m0.1090\u001b[0m  0.0165\n",
            "      4        \u001b[36m0.1028\u001b[0m  0.0148\n",
            "      5        \u001b[36m0.0988\u001b[0m  0.0161\n",
            "      6        \u001b[36m0.0938\u001b[0m  0.0186\n",
            "      7        \u001b[36m0.0908\u001b[0m  0.0126\n",
            "      8        \u001b[36m0.0870\u001b[0m  0.0130\n",
            "      9        \u001b[36m0.0845\u001b[0m  0.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.0836\u001b[0m  0.0154\n",
            "     11        \u001b[36m0.0797\u001b[0m  0.0154\n",
            "     12        \u001b[36m0.0785\u001b[0m  0.0132\n",
            "     13        \u001b[36m0.0764\u001b[0m  0.0157\n",
            "     14        \u001b[36m0.0746\u001b[0m  0.0135\n",
            "     15        \u001b[36m0.0724\u001b[0m  0.0129\n",
            "     16        \u001b[36m0.0718\u001b[0m  0.0174\n",
            "     17        \u001b[36m0.0689\u001b[0m  0.0142\n",
            "     18        \u001b[36m0.0683\u001b[0m  0.0143\n",
            "     19        \u001b[36m0.0676\u001b[0m  0.0135\n",
            "     20        \u001b[36m0.0651\u001b[0m  0.0130\n",
            "     21        \u001b[36m0.0638\u001b[0m  0.0136\n",
            "     22        \u001b[36m0.0605\u001b[0m  0.0129\n",
            "     23        0.0609  0.0129\n",
            "     24        \u001b[36m0.0592\u001b[0m  0.0160\n",
            "     25        \u001b[36m0.0572\u001b[0m  0.0179\n",
            "     26        \u001b[36m0.0560\u001b[0m  0.0167\n",
            "     27        \u001b[36m0.0538\u001b[0m  0.0136\n",
            "     28        \u001b[36m0.0538\u001b[0m  0.0134\n",
            "     29        \u001b[36m0.0526\u001b[0m  0.0134\n",
            "     30        \u001b[36m0.0511\u001b[0m  0.0137\n",
            "     31        \u001b[36m0.0500\u001b[0m  0.0144\n",
            "     32        \u001b[36m0.0483\u001b[0m  0.0138\n",
            "     33        \u001b[36m0.0471\u001b[0m  0.0131\n",
            "     34        \u001b[36m0.0463\u001b[0m  0.0143\n",
            "     35        \u001b[36m0.0459\u001b[0m  0.0194\n",
            "     36        \u001b[36m0.0435\u001b[0m  0.0141\n",
            "     37        \u001b[36m0.0434\u001b[0m  0.0138\n",
            "     38        \u001b[36m0.0416\u001b[0m  0.0174\n",
            "     39        \u001b[36m0.0404\u001b[0m  0.0130\n",
            "     40        0.0412  0.0129\n",
            "     41        \u001b[36m0.0397\u001b[0m  0.0132\n",
            "     42        \u001b[36m0.0387\u001b[0m  0.0171\n",
            "     43        \u001b[36m0.0362\u001b[0m  0.0162\n",
            "     44        \u001b[36m0.0350\u001b[0m  0.0131\n",
            "     45        \u001b[36m0.0348\u001b[0m  0.0157\n",
            "     46        \u001b[36m0.0336\u001b[0m  0.0140\n",
            "     47        \u001b[36m0.0332\u001b[0m  0.0130\n",
            "     48        0.0340  0.0141\n",
            "     49        \u001b[36m0.0311\u001b[0m  0.0139\n",
            "     50        0.0333  0.0133\n",
            "     51        0.0313  0.0146\n",
            "     52        0.0319  0.0150\n",
            "     53        \u001b[36m0.0292\u001b[0m  0.0142\n",
            "     54        0.0295  0.0149\n",
            "     55        0.0299  0.0165\n",
            "     56        \u001b[36m0.0274\u001b[0m  0.0149\n",
            "     57        0.0285  0.0126\n",
            "     58        \u001b[36m0.0261\u001b[0m  0.0125\n",
            "     59        \u001b[36m0.0257\u001b[0m  0.0138\n",
            "     60        \u001b[36m0.0252\u001b[0m  0.0136\n",
            "     61        0.0260  0.0134\n",
            "     62        \u001b[36m0.0244\u001b[0m  0.0125\n",
            "     63        0.0249  0.0135\n",
            "     64        \u001b[36m0.0232\u001b[0m  0.0135\n",
            "     65        \u001b[36m0.0220\u001b[0m  0.0132\n",
            "     66        0.0235  0.0135\n",
            "     67        0.0237  0.0125\n",
            "     68        0.0227  0.0156\n",
            "     69        0.0226  0.0136\n",
            "     70        \u001b[36m0.0212\u001b[0m  0.0169\n",
            "     71        0.0225  0.0138\n",
            "     72        0.0225  0.0190\n",
            "     73        0.0214  0.0183\n",
            "     74        \u001b[36m0.0204\u001b[0m  0.0178\n",
            "     75        0.0207  0.0127\n",
            "     76        \u001b[36m0.0199\u001b[0m  0.0161\n",
            "     77        \u001b[36m0.0179\u001b[0m  0.0149\n",
            "     78        0.0195  0.0151\n",
            "     79        0.0199  0.0131\n",
            "     80        0.0204  0.0124\n",
            "     81        0.0200  0.0159\n",
            "     82        0.0185  0.0157\n",
            "     83        0.0186  0.0123\n",
            "     84        0.0191  0.0123\n",
            "     85        0.0190  0.0132\n",
            "     86        0.0183  0.0175\n",
            "     87        \u001b[36m0.0177\u001b[0m  0.0133\n",
            "     88        0.0186  0.0165\n",
            "     89        \u001b[36m0.0170\u001b[0m  0.0151\n",
            "     90        0.0170  0.0135\n",
            "     91        0.0181  0.0158\n",
            "     92        0.0175  0.0151\n",
            "     93        \u001b[36m0.0161\u001b[0m  0.0140\n",
            "     94        \u001b[36m0.0156\u001b[0m  0.0144\n",
            "     95        \u001b[36m0.0151\u001b[0m  0.0165\n",
            "     96        0.0159  0.0159\n",
            "     97        0.0158  0.0159\n",
            "     98        0.0162  0.0196\n",
            "     99        0.0160  0.0173\n",
            "    100        0.0153  0.0159\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1635\u001b[0m  0.0159\n",
            "      2        \u001b[36m0.1129\u001b[0m  0.0178\n",
            "      3        \u001b[36m0.0979\u001b[0m  0.0166\n",
            "      4        \u001b[36m0.0907\u001b[0m  0.0143\n",
            "      5        \u001b[36m0.0854\u001b[0m  0.0144\n",
            "      6        \u001b[36m0.0811\u001b[0m  0.0174\n",
            "      7        \u001b[36m0.0774\u001b[0m  0.0148\n",
            "      8        \u001b[36m0.0731\u001b[0m  0.0176\n",
            "      9        \u001b[36m0.0706\u001b[0m  0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.0673\u001b[0m  0.0196\n",
            "     11        \u001b[36m0.0650\u001b[0m  0.0199\n",
            "     12        \u001b[36m0.0630\u001b[0m  0.0188\n",
            "     13        \u001b[36m0.0601\u001b[0m  0.0181\n",
            "     14        \u001b[36m0.0588\u001b[0m  0.0187\n",
            "     15        \u001b[36m0.0549\u001b[0m  0.0162\n",
            "     16        \u001b[36m0.0538\u001b[0m  0.0145\n",
            "     17        \u001b[36m0.0503\u001b[0m  0.0172\n",
            "     18        \u001b[36m0.0493\u001b[0m  0.0190\n",
            "     19        \u001b[36m0.0478\u001b[0m  0.0160\n",
            "     20        \u001b[36m0.0452\u001b[0m  0.0175\n",
            "     21        \u001b[36m0.0447\u001b[0m  0.0161\n",
            "     22        \u001b[36m0.0432\u001b[0m  0.0189\n",
            "     23        \u001b[36m0.0418\u001b[0m  0.0171\n",
            "     24        \u001b[36m0.0392\u001b[0m  0.0180\n",
            "     25        \u001b[36m0.0377\u001b[0m  0.0184\n",
            "     26        \u001b[36m0.0369\u001b[0m  0.0222\n",
            "     27        \u001b[36m0.0358\u001b[0m  0.0182\n",
            "     28        \u001b[36m0.0337\u001b[0m  0.0178\n",
            "     29        \u001b[36m0.0324\u001b[0m  0.0172\n",
            "     30        \u001b[36m0.0315\u001b[0m  0.0248\n",
            "     31        \u001b[36m0.0307\u001b[0m  0.0184\n",
            "     32        \u001b[36m0.0297\u001b[0m  0.0208\n",
            "     33        \u001b[36m0.0277\u001b[0m  0.0174\n",
            "     34        \u001b[36m0.0273\u001b[0m  0.0208\n",
            "     35        \u001b[36m0.0253\u001b[0m  0.0143\n",
            "     36        \u001b[36m0.0248\u001b[0m  0.0140\n",
            "     37        \u001b[36m0.0246\u001b[0m  0.0138\n",
            "     38        \u001b[36m0.0237\u001b[0m  0.0150\n",
            "     39        \u001b[36m0.0234\u001b[0m  0.0148\n",
            "     40        \u001b[36m0.0228\u001b[0m  0.0150\n",
            "     41        \u001b[36m0.0209\u001b[0m  0.0129\n",
            "     42        0.0217  0.0106\n",
            "     43        \u001b[36m0.0207\u001b[0m  0.0134\n",
            "     44        \u001b[36m0.0201\u001b[0m  0.0122\n",
            "     45        \u001b[36m0.0194\u001b[0m  0.0122\n",
            "     46        \u001b[36m0.0186\u001b[0m  0.0112\n",
            "     47        0.0192  0.0114\n",
            "     48        0.0194  0.0151\n",
            "     49        \u001b[36m0.0176\u001b[0m  0.0123\n",
            "     50        0.0180  0.0126\n",
            "     51        \u001b[36m0.0172\u001b[0m  0.0125\n",
            "     52        \u001b[36m0.0161\u001b[0m  0.0125\n",
            "     53        0.0171  0.0126\n",
            "     54        0.0162  0.0115\n",
            "     55        \u001b[36m0.0153\u001b[0m  0.0113\n",
            "     56        0.0166  0.0143\n",
            "     57        0.0155  0.0147\n",
            "     58        \u001b[36m0.0151\u001b[0m  0.0143\n",
            "     59        0.0157  0.0113\n",
            "     60        \u001b[36m0.0141\u001b[0m  0.0113\n",
            "     61        0.0149  0.0142\n",
            "     62        0.0151  0.0137\n",
            "     63        0.0143  0.0117\n",
            "     64        0.0146  0.0114\n",
            "     65        \u001b[36m0.0130\u001b[0m  0.0140\n",
            "     66        0.0135  0.0122\n",
            "     67        0.0132  0.0127\n",
            "     68        \u001b[36m0.0128\u001b[0m  0.0124\n",
            "     69        0.0138  0.0114\n",
            "     70        0.0131  0.0115\n",
            "     71        \u001b[36m0.0127\u001b[0m  0.0140\n",
            "     72        0.0130  0.0125\n",
            "     73        \u001b[36m0.0125\u001b[0m  0.0125\n",
            "     74        \u001b[36m0.0119\u001b[0m  0.0125\n",
            "     75        0.0122  0.0131\n",
            "     76        0.0125  0.0134\n",
            "     77        0.0120  0.0114\n",
            "     78        \u001b[36m0.0119\u001b[0m  0.0143\n",
            "     79        0.0119  0.0122\n",
            "     80        0.0124  0.0124\n",
            "     81        0.0119  0.0123\n",
            "     82        \u001b[36m0.0115\u001b[0m  0.0131\n",
            "     83        \u001b[36m0.0108\u001b[0m  0.0114\n",
            "     84        \u001b[36m0.0105\u001b[0m  0.0113\n",
            "     85        0.0107  0.0149\n",
            "     86        0.0106  0.0126\n",
            "     87        0.0106  0.0151\n",
            "     88        0.0106  0.0115\n",
            "     89        \u001b[36m0.0104\u001b[0m  0.0113\n",
            "     90        0.0111  0.0135\n",
            "     91        0.0110  0.0121\n",
            "     92        \u001b[36m0.0102\u001b[0m  0.0125\n",
            "     93        0.0104  0.0129\n",
            "     94        0.0103  0.0114\n",
            "     95        0.0113  0.0148\n",
            "     96        \u001b[36m0.0100\u001b[0m  0.0123\n",
            "     97        \u001b[36m0.0097\u001b[0m  0.0123\n",
            "     98        0.0098  0.0125\n",
            "     99        \u001b[36m0.0094\u001b[0m  0.0115\n",
            "    100        \u001b[36m0.0092\u001b[0m  0.0114\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1861\u001b[0m  0.0055\n",
            "      2        \u001b[36m0.1520\u001b[0m  0.0059\n",
            "      3        \u001b[36m0.1324\u001b[0m  0.0096\n",
            "      4        \u001b[36m0.1154\u001b[0m  0.0072\n",
            "      5        \u001b[36m0.1053\u001b[0m  0.0080\n",
            "      6        \u001b[36m0.0974\u001b[0m  0.0063\n",
            "      7        \u001b[36m0.0893\u001b[0m  0.0051\n",
            "      8        \u001b[36m0.0854\u001b[0m  0.0049\n",
            "      9        \u001b[36m0.0808\u001b[0m  0.0053\n",
            "     10        0.0813  0.0063\n",
            "     11        \u001b[36m0.0764\u001b[0m  0.0064\n",
            "     12        \u001b[36m0.0730\u001b[0m  0.0062\n",
            "     13        \u001b[36m0.0689\u001b[0m  0.0062\n",
            "     14        \u001b[36m0.0657\u001b[0m  0.0056\n",
            "     15        \u001b[36m0.0635\u001b[0m  0.0049\n",
            "     16        0.0656  0.0049\n",
            "     17        \u001b[36m0.0620\u001b[0m  0.0050\n",
            "     18        \u001b[36m0.0606\u001b[0m  0.0049\n",
            "     19        \u001b[36m0.0591\u001b[0m  0.0068\n",
            "     20        \u001b[36m0.0582\u001b[0m  0.0060\n",
            "     21        \u001b[36m0.0543\u001b[0m  0.0058\n",
            "     22        \u001b[36m0.0539\u001b[0m  0.0047\n",
            "     23        \u001b[36m0.0518\u001b[0m  0.0058\n",
            "     24        \u001b[36m0.0511\u001b[0m  0.0056\n",
            "     25        \u001b[36m0.0500\u001b[0m  0.0057\n",
            "     26        \u001b[36m0.0489\u001b[0m  0.0059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     27        \u001b[36m0.0478\u001b[0m  0.0087\n",
            "     28        \u001b[36m0.0470\u001b[0m  0.0060\n",
            "     29        \u001b[36m0.0456\u001b[0m  0.0060\n",
            "     30        \u001b[36m0.0442\u001b[0m  0.0049\n",
            "     31        \u001b[36m0.0432\u001b[0m  0.0049\n",
            "     32        \u001b[36m0.0429\u001b[0m  0.0050\n",
            "     33        0.0429  0.0049\n",
            "     34        \u001b[36m0.0412\u001b[0m  0.0050\n",
            "     35        \u001b[36m0.0404\u001b[0m  0.0049\n",
            "     36        \u001b[36m0.0384\u001b[0m  0.0082\n",
            "     37        \u001b[36m0.0371\u001b[0m  0.0055\n",
            "     38        0.0376  0.0058\n",
            "     39        \u001b[36m0.0363\u001b[0m  0.0043\n",
            "     40        \u001b[36m0.0361\u001b[0m  0.0050\n",
            "     41        \u001b[36m0.0355\u001b[0m  0.0050\n",
            "     42        \u001b[36m0.0337\u001b[0m  0.0050\n",
            "     43        0.0339  0.0071\n",
            "     44        \u001b[36m0.0332\u001b[0m  0.0065\n",
            "     45        0.0335  0.0060\n",
            "     46        \u001b[36m0.0327\u001b[0m  0.0056\n",
            "     47        \u001b[36m0.0316\u001b[0m  0.0060\n",
            "     48        \u001b[36m0.0310\u001b[0m  0.0060\n",
            "     49        \u001b[36m0.0288\u001b[0m  0.0048\n",
            "     50        0.0301  0.0048\n",
            "     51        0.0288  0.0050\n",
            "     52        \u001b[36m0.0280\u001b[0m  0.0049\n",
            "     53        \u001b[36m0.0270\u001b[0m  0.0050\n",
            "     54        \u001b[36m0.0263\u001b[0m  0.0048\n",
            "     55        0.0263  0.0081\n",
            "     56        \u001b[36m0.0238\u001b[0m  0.0066\n",
            "     57        0.0243  0.0063\n",
            "     58        0.0238  0.0056\n",
            "     59        0.0248  0.0059\n",
            "     60        \u001b[36m0.0228\u001b[0m  0.0049\n",
            "     61        \u001b[36m0.0226\u001b[0m  0.0055\n",
            "     62        \u001b[36m0.0224\u001b[0m  0.0056\n",
            "     63        \u001b[36m0.0217\u001b[0m  0.0050\n",
            "     64        \u001b[36m0.0213\u001b[0m  0.0049\n",
            "     65        0.0230  0.0048\n",
            "     66        \u001b[36m0.0207\u001b[0m  0.0070\n",
            "     67        0.0212  0.0062\n",
            "     68        \u001b[36m0.0198\u001b[0m  0.0060\n",
            "     69        0.0209  0.0053\n",
            "     70        \u001b[36m0.0182\u001b[0m  0.0058\n",
            "     71        0.0201  0.0054\n",
            "     72        0.0200  0.0057\n",
            "     73        0.0192  0.0057\n",
            "     74        \u001b[36m0.0176\u001b[0m  0.0048\n",
            "     75        \u001b[36m0.0163\u001b[0m  0.0050\n",
            "     76        0.0184  0.0049\n",
            "     77        0.0174  0.0049\n",
            "     78        \u001b[36m0.0157\u001b[0m  0.0051\n",
            "     79        0.0177  0.0050\n",
            "     80        0.0163  0.0066\n",
            "     81        0.0168  0.0063\n",
            "     82        \u001b[36m0.0145\u001b[0m  0.0063\n",
            "     83        0.0164  0.0055\n",
            "     84        0.0159  0.0056\n",
            "     85        0.0156  0.0062\n",
            "     86        0.0147  0.0049\n",
            "     87        \u001b[36m0.0145\u001b[0m  0.0046\n",
            "     88        \u001b[36m0.0137\u001b[0m  0.0048\n",
            "     89        0.0162  0.0046\n",
            "     90        0.0142  0.0045\n",
            "     91        0.0142  0.0046\n",
            "     92        \u001b[36m0.0136\u001b[0m  0.0061\n",
            "     93        \u001b[36m0.0136\u001b[0m  0.0063\n",
            "     94        \u001b[36m0.0132\u001b[0m  0.0062\n",
            "     95        \u001b[36m0.0124\u001b[0m  0.0051\n",
            "     96        0.0134  0.0049\n",
            "     97        0.0130  0.0048\n",
            "     98        0.0133  0.0049\n",
            "     99        0.0134  0.0046\n",
            "    100        0.0137  0.0059\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1939\u001b[0m  0.0136\n",
            "      2        \u001b[36m0.1371\u001b[0m  0.0101\n",
            "      3        \u001b[36m0.1168\u001b[0m  0.0103\n",
            "      4        \u001b[36m0.1055\u001b[0m  0.0100\n",
            "      5        \u001b[36m0.0958\u001b[0m  0.0092\n",
            "      6        \u001b[36m0.0914\u001b[0m  0.0102\n",
            "      7        \u001b[36m0.0856\u001b[0m  0.0092\n",
            "      8        \u001b[36m0.0823\u001b[0m  0.0126\n",
            "      9        \u001b[36m0.0779\u001b[0m  0.0100\n",
            "     10        \u001b[36m0.0764\u001b[0m  0.0092\n",
            "     11        \u001b[36m0.0720\u001b[0m  0.0094\n",
            "     12        \u001b[36m0.0704\u001b[0m  0.0097\n",
            "     13        \u001b[36m0.0682\u001b[0m  0.0116\n",
            "     14        \u001b[36m0.0659\u001b[0m  0.0098\n",
            "     15        \u001b[36m0.0642\u001b[0m  0.0089\n",
            "     16        \u001b[36m0.0614\u001b[0m  0.0090\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0594\u001b[0m  0.0098\n",
            "     18        \u001b[36m0.0574\u001b[0m  0.0152\n",
            "     19        \u001b[36m0.0566\u001b[0m  0.0120\n",
            "     20        \u001b[36m0.0547\u001b[0m  0.0092\n",
            "     21        \u001b[36m0.0540\u001b[0m  0.0092\n",
            "     22        \u001b[36m0.0518\u001b[0m  0.0114\n",
            "     23        \u001b[36m0.0517\u001b[0m  0.0111\n",
            "     24        \u001b[36m0.0488\u001b[0m  0.0100\n",
            "     25        \u001b[36m0.0485\u001b[0m  0.0092\n",
            "     26        \u001b[36m0.0467\u001b[0m  0.0094\n",
            "     27        \u001b[36m0.0452\u001b[0m  0.0091\n",
            "     28        \u001b[36m0.0443\u001b[0m  0.0125\n",
            "     29        \u001b[36m0.0423\u001b[0m  0.0101\n",
            "     30        0.0428  0.0094\n",
            "     31        0.0425  0.0094\n",
            "     32        \u001b[36m0.0405\u001b[0m  0.0091\n",
            "     33        \u001b[36m0.0400\u001b[0m  0.0164\n",
            "     34        \u001b[36m0.0378\u001b[0m  0.0172\n",
            "     35        \u001b[36m0.0372\u001b[0m  0.0103\n",
            "     36        0.0372  0.0090\n",
            "     37        \u001b[36m0.0365\u001b[0m  0.0126\n",
            "     38        \u001b[36m0.0357\u001b[0m  0.0100\n",
            "     39        \u001b[36m0.0336\u001b[0m  0.0100\n",
            "     40        \u001b[36m0.0328\u001b[0m  0.0089\n",
            "     41        \u001b[36m0.0327\u001b[0m  0.0094\n",
            "     42        \u001b[36m0.0320\u001b[0m  0.0091\n",
            "     43        \u001b[36m0.0313\u001b[0m  0.0119\n",
            "     44        \u001b[36m0.0300\u001b[0m  0.0112\n",
            "     45        \u001b[36m0.0286\u001b[0m  0.0124\n",
            "     46        0.0287  0.0090\n",
            "     47        0.0299  0.0091\n",
            "     48        \u001b[36m0.0280\u001b[0m  0.0097\n",
            "     49        \u001b[36m0.0277\u001b[0m  0.0142\n",
            "     50        0.0281  0.0098\n",
            "     51        \u001b[36m0.0266\u001b[0m  0.0098\n",
            "     52        \u001b[36m0.0264\u001b[0m  0.0099\n",
            "     53        \u001b[36m0.0254\u001b[0m  0.0096\n",
            "     54        0.0257  0.0090\n",
            "     55        \u001b[36m0.0243\u001b[0m  0.0090\n",
            "     56        \u001b[36m0.0242\u001b[0m  0.0091\n",
            "     57        \u001b[36m0.0230\u001b[0m  0.0123\n",
            "     58        0.0233  0.0097\n",
            "     59        \u001b[36m0.0227\u001b[0m  0.0113\n",
            "     60        0.0232  0.0098\n",
            "     61        0.0230  0.0102\n",
            "     62        \u001b[36m0.0224\u001b[0m  0.0102\n",
            "     63        \u001b[36m0.0211\u001b[0m  0.0091\n",
            "     64        0.0217  0.0094\n",
            "     65        0.0219  0.0094\n",
            "     66        \u001b[36m0.0199\u001b[0m  0.0140\n",
            "     67        0.0206  0.0110\n",
            "     68        0.0207  0.0101\n",
            "     69        \u001b[36m0.0193\u001b[0m  0.0098\n",
            "     70        0.0198  0.0090\n",
            "     71        0.0194  0.0093\n",
            "     72        0.0197  0.0093\n",
            "     73        \u001b[36m0.0191\u001b[0m  0.0121\n",
            "     74        \u001b[36m0.0190\u001b[0m  0.0099\n",
            "     75        \u001b[36m0.0185\u001b[0m  0.0099\n",
            "     76        \u001b[36m0.0183\u001b[0m  0.0090\n",
            "     77        \u001b[36m0.0176\u001b[0m  0.0091\n",
            "     78        \u001b[36m0.0174\u001b[0m  0.0091\n",
            "     79        \u001b[36m0.0167\u001b[0m  0.0146\n",
            "     80        \u001b[36m0.0167\u001b[0m  0.0100\n",
            "     81        0.0168  0.0093\n",
            "     82        \u001b[36m0.0166\u001b[0m  0.0095\n",
            "     83        \u001b[36m0.0164\u001b[0m  0.0094\n",
            "     84        0.0165  0.0128\n",
            "     85        0.0170  0.0101\n",
            "     86        \u001b[36m0.0153\u001b[0m  0.0101\n",
            "     87        0.0158  0.0102\n",
            "     88        0.0164  0.0092\n",
            "     89        0.0167  0.0092\n",
            "     90        0.0160  0.0137\n",
            "     91        0.0156  0.0108\n",
            "     92        0.0157  0.0092\n",
            "     93        0.0156  0.0093\n",
            "     94        \u001b[36m0.0150\u001b[0m  0.0091\n",
            "     95        \u001b[36m0.0143\u001b[0m  0.0128\n",
            "     96        \u001b[36m0.0141\u001b[0m  0.0099\n",
            "     97        0.0147  0.0090\n",
            "     98        0.0148  0.0089\n",
            "     99        0.0141  0.0099\n",
            "    100        0.0155  0.0122\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1463\u001b[0m  0.0100\n",
            "      2        \u001b[36m0.1162\u001b[0m  0.0120\n",
            "      3        \u001b[36m0.1000\u001b[0m  0.0107\n",
            "      4        \u001b[36m0.0908\u001b[0m  0.0111\n",
            "      5        \u001b[36m0.0828\u001b[0m  0.0099\n",
            "      6        \u001b[36m0.0775\u001b[0m  0.0096\n",
            "      7        \u001b[36m0.0715\u001b[0m  0.0128\n",
            "      8        \u001b[36m0.0692\u001b[0m  0.0108\n",
            "      9        \u001b[36m0.0653\u001b[0m  0.0109\n",
            "     10        \u001b[36m0.0618\u001b[0m  0.0094\n",
            "     11        \u001b[36m0.0591\u001b[0m  0.0094\n",
            "     12        \u001b[36m0.0564\u001b[0m  0.0112\n",
            "     13        \u001b[36m0.0537\u001b[0m  0.0129\n",
            "     14        \u001b[36m0.0518\u001b[0m  0.0103\n",
            "     15        \u001b[36m0.0495\u001b[0m  0.0096\n",
            "     16        \u001b[36m0.0475\u001b[0m  0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0449\u001b[0m  0.0110\n",
            "     18        \u001b[36m0.0440\u001b[0m  0.0122\n",
            "     19        \u001b[36m0.0419\u001b[0m  0.0102\n",
            "     20        \u001b[36m0.0392\u001b[0m  0.0095\n",
            "     21        \u001b[36m0.0386\u001b[0m  0.0096\n",
            "     22        \u001b[36m0.0375\u001b[0m  0.0097\n",
            "     23        \u001b[36m0.0369\u001b[0m  0.0136\n",
            "     24        \u001b[36m0.0349\u001b[0m  0.0171\n",
            "     25        \u001b[36m0.0340\u001b[0m  0.0137\n",
            "     26        \u001b[36m0.0338\u001b[0m  0.0098\n",
            "     27        \u001b[36m0.0317\u001b[0m  0.0125\n",
            "     28        \u001b[36m0.0301\u001b[0m  0.0108\n",
            "     29        \u001b[36m0.0290\u001b[0m  0.0096\n",
            "     30        \u001b[36m0.0281\u001b[0m  0.0096\n",
            "     31        \u001b[36m0.0279\u001b[0m  0.0098\n",
            "     32        \u001b[36m0.0275\u001b[0m  0.0118\n",
            "     33        \u001b[36m0.0260\u001b[0m  0.0120\n",
            "     34        \u001b[36m0.0249\u001b[0m  0.0114\n",
            "     35        \u001b[36m0.0243\u001b[0m  0.0098\n",
            "     36        \u001b[36m0.0242\u001b[0m  0.0123\n",
            "     37        \u001b[36m0.0233\u001b[0m  0.0105\n",
            "     38        \u001b[36m0.0221\u001b[0m  0.0106\n",
            "     39        \u001b[36m0.0218\u001b[0m  0.0094\n",
            "     40        \u001b[36m0.0215\u001b[0m  0.0097\n",
            "     41        \u001b[36m0.0215\u001b[0m  0.0095\n",
            "     42        \u001b[36m0.0199\u001b[0m  0.0122\n",
            "     43        0.0203  0.0102\n",
            "     44        \u001b[36m0.0189\u001b[0m  0.0090\n",
            "     45        \u001b[36m0.0185\u001b[0m  0.0096\n",
            "     46        0.0186  0.0095\n",
            "     47        \u001b[36m0.0184\u001b[0m  0.0145\n",
            "     48        \u001b[36m0.0173\u001b[0m  0.0104\n",
            "     49        0.0176  0.0105\n",
            "     50        \u001b[36m0.0169\u001b[0m  0.0095\n",
            "     51        \u001b[36m0.0165\u001b[0m  0.0095\n",
            "     52        0.0172  0.0098\n",
            "     53        0.0170  0.0121\n",
            "     54        \u001b[36m0.0164\u001b[0m  0.0107\n",
            "     55        \u001b[36m0.0154\u001b[0m  0.0095\n",
            "     56        \u001b[36m0.0149\u001b[0m  0.0110\n",
            "     57        0.0157  0.0123\n",
            "     58        0.0159  0.0110\n",
            "     59        0.0153  0.0107\n",
            "     60        0.0151  0.0095\n",
            "     61        \u001b[36m0.0143\u001b[0m  0.0096\n",
            "     62        0.0144  0.0097\n",
            "     63        \u001b[36m0.0142\u001b[0m  0.0122\n",
            "     64        \u001b[36m0.0137\u001b[0m  0.0102\n",
            "     65        \u001b[36m0.0137\u001b[0m  0.0104\n",
            "     66        \u001b[36m0.0135\u001b[0m  0.0094\n",
            "     67        \u001b[36m0.0129\u001b[0m  0.0096\n",
            "     68        0.0138  0.0095\n",
            "     69        0.0132  0.0138\n",
            "     70        0.0133  0.0103\n",
            "     71        \u001b[36m0.0126\u001b[0m  0.0095\n",
            "     72        0.0128  0.0095\n",
            "     73        0.0130  0.0101\n",
            "     74        \u001b[36m0.0121\u001b[0m  0.0128\n",
            "     75        0.0122  0.0106\n",
            "     76        \u001b[36m0.0118\u001b[0m  0.0106\n",
            "     77        0.0123  0.0108\n",
            "     78        \u001b[36m0.0113\u001b[0m  0.0118\n",
            "     79        0.0119  0.0105\n",
            "     80        0.0114  0.0125\n",
            "     81        0.0116  0.0105\n",
            "     82        0.0118  0.0100\n",
            "     83        0.0117  0.0098\n",
            "     84        0.0115  0.0127\n",
            "     85        0.0118  0.0132\n",
            "     86        \u001b[36m0.0111\u001b[0m  0.0133\n",
            "     87        0.0113  0.0113\n",
            "     88        0.0114  0.0109\n",
            "     89        0.0112  0.0131\n",
            "     90        0.0115  0.0108\n",
            "     91        \u001b[36m0.0103\u001b[0m  0.0108\n",
            "     92        0.0103  0.0092\n",
            "     93        0.0108  0.0108\n",
            "     94        \u001b[36m0.0102\u001b[0m  0.0096\n",
            "     95        0.0104  0.0142\n",
            "     96        \u001b[36m0.0099\u001b[0m  0.0102\n",
            "     97        0.0105  0.0102\n",
            "     98        0.0108  0.0100\n",
            "     99        0.0100  0.0118\n",
            "    100        0.0100  0.0092\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1534\u001b[0m  0.0674\n",
            "      2        \u001b[36m0.1466\u001b[0m  0.0233\n",
            "      3        \u001b[36m0.1362\u001b[0m  0.0344\n",
            "      4        \u001b[36m0.1318\u001b[0m  0.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.1296\u001b[0m  0.0217\n",
            "      6        \u001b[36m0.1199\u001b[0m  0.0222\n",
            "      7        \u001b[36m0.1145\u001b[0m  0.0266\n",
            "      8        0.1157  0.0218\n",
            "      9        \u001b[36m0.1125\u001b[0m  0.0218\n",
            "     10        0.1125  0.0218\n",
            "     11        \u001b[36m0.1088\u001b[0m  0.0215\n",
            "     12        \u001b[36m0.1040\u001b[0m  0.0218\n",
            "     13        0.1071  0.0221\n",
            "     14        \u001b[36m0.0999\u001b[0m  0.0218\n",
            "     15        0.1017  0.0217\n",
            "     16        0.1001  0.0241\n",
            "     17        \u001b[36m0.0983\u001b[0m  0.0220\n",
            "     18        \u001b[36m0.0980\u001b[0m  0.0237\n",
            "     19        \u001b[36m0.0956\u001b[0m  0.0216\n",
            "     20        0.0959  0.0214\n",
            "     21        \u001b[36m0.0953\u001b[0m  0.0218\n",
            "     22        0.0956  0.0222\n",
            "     23        \u001b[36m0.0929\u001b[0m  0.0220\n",
            "     24        \u001b[36m0.0925\u001b[0m  0.0219\n",
            "     25        0.0963  0.0217\n",
            "     26        0.0932  0.0238\n",
            "     27        \u001b[36m0.0922\u001b[0m  0.0217\n",
            "     28        0.0947  0.0215\n",
            "     29        \u001b[36m0.0885\u001b[0m  0.0231\n",
            "     30        0.0894  0.0216\n",
            "     31        0.0896  0.0226\n",
            "     32        0.0891  0.0220\n",
            "     33        \u001b[36m0.0867\u001b[0m  0.0217\n",
            "     34        0.0872  0.0218\n",
            "     35        0.0899  0.0214\n",
            "     36        0.0867  0.0235\n",
            "     37        \u001b[36m0.0840\u001b[0m  0.0226\n",
            "     38        0.0852  0.0239\n",
            "     39        0.0873  0.0214\n",
            "     40        0.0848  0.0230\n",
            "     41        \u001b[36m0.0831\u001b[0m  0.0215\n",
            "     42        0.0843  0.0213\n",
            "     43        \u001b[36m0.0807\u001b[0m  0.0218\n",
            "     44        0.0817  0.0215\n",
            "     45        \u001b[36m0.0794\u001b[0m  0.0224\n",
            "     46        \u001b[36m0.0784\u001b[0m  0.0215\n",
            "     47        0.0807  0.0276\n",
            "     48        \u001b[36m0.0771\u001b[0m  0.0288\n",
            "     49        \u001b[36m0.0736\u001b[0m  0.0216\n",
            "     50        0.0753  0.0218\n",
            "     51        0.0737  0.0305\n",
            "     52        0.0744  0.0216\n",
            "     53        0.0748  0.0210\n",
            "     54        \u001b[36m0.0711\u001b[0m  0.0219\n",
            "     55        \u001b[36m0.0706\u001b[0m  0.0215\n",
            "     56        0.0722  0.0218\n",
            "     57        \u001b[36m0.0694\u001b[0m  0.0216\n",
            "     58        0.0701  0.0217\n",
            "     59        \u001b[36m0.0687\u001b[0m  0.0218\n",
            "     60        \u001b[36m0.0682\u001b[0m  0.0218\n",
            "     61        \u001b[36m0.0660\u001b[0m  0.0217\n",
            "     62        0.0674  0.0232\n",
            "     63        \u001b[36m0.0606\u001b[0m  0.0216\n",
            "     64        0.0636  0.0235\n",
            "     65        0.0639  0.0221\n",
            "     66        \u001b[36m0.0598\u001b[0m  0.0222\n",
            "     67        \u001b[36m0.0591\u001b[0m  0.0217\n",
            "     68        0.0596  0.0219\n",
            "     69        0.0594  0.0228\n",
            "     70        \u001b[36m0.0573\u001b[0m  0.0217\n",
            "     71        0.0609  0.0211\n",
            "     72        0.0574  0.0225\n",
            "     73        \u001b[36m0.0571\u001b[0m  0.0219\n",
            "     74        \u001b[36m0.0540\u001b[0m  0.0225\n",
            "     75        \u001b[36m0.0535\u001b[0m  0.0221\n",
            "     76        \u001b[36m0.0513\u001b[0m  0.0216\n",
            "     77        0.0518  0.0229\n",
            "     78        \u001b[36m0.0509\u001b[0m  0.0215\n",
            "     79        \u001b[36m0.0504\u001b[0m  0.0217\n",
            "     80        \u001b[36m0.0499\u001b[0m  0.0230\n",
            "     81        \u001b[36m0.0480\u001b[0m  0.0214\n",
            "     82        0.0482  0.0214\n",
            "     83        \u001b[36m0.0469\u001b[0m  0.0218\n",
            "     84        0.0471  0.0229\n",
            "     85        \u001b[36m0.0454\u001b[0m  0.0222\n",
            "     86        \u001b[36m0.0444\u001b[0m  0.0217\n",
            "     87        \u001b[36m0.0438\u001b[0m  0.0216\n",
            "     88        \u001b[36m0.0429\u001b[0m  0.0219\n",
            "     89        0.0447  0.0233\n",
            "     90        \u001b[36m0.0426\u001b[0m  0.0215\n",
            "     91        \u001b[36m0.0410\u001b[0m  0.0216\n",
            "     92        0.0434  0.0342\n",
            "     93        \u001b[36m0.0401\u001b[0m  0.0218\n",
            "     94        \u001b[36m0.0399\u001b[0m  0.0218\n",
            "     95        \u001b[36m0.0375\u001b[0m  0.0268\n",
            "     96        0.0390  0.0217\n",
            "     97        0.0379  0.0216\n",
            "     98        0.0391  0.0222\n",
            "     99        \u001b[36m0.0374\u001b[0m  0.0221\n",
            "    100        0.0379  0.0215\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1632\u001b[0m  0.1144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.1458\u001b[0m  0.0463\n",
            "      3        \u001b[36m0.1329\u001b[0m  0.0421\n",
            "      4        0.1338  0.0430\n",
            "      5        \u001b[36m0.1220\u001b[0m  0.0428\n",
            "      6        0.1228  0.0431\n",
            "      7        \u001b[36m0.1167\u001b[0m  0.0414\n",
            "      8        \u001b[36m0.1155\u001b[0m  0.0441\n",
            "      9        \u001b[36m0.1110\u001b[0m  0.0437\n",
            "     10        0.1114  0.0415\n",
            "     11        \u001b[36m0.1068\u001b[0m  0.0415\n",
            "     12        0.1078  0.0412\n",
            "     13        \u001b[36m0.1063\u001b[0m  0.0415\n",
            "     14        \u001b[36m0.1052\u001b[0m  0.0427\n",
            "     15        \u001b[36m0.1044\u001b[0m  0.0424\n",
            "     16        \u001b[36m0.1023\u001b[0m  0.0511\n",
            "     17        0.1038  0.0467\n",
            "     18        0.1036  0.0417\n",
            "     19        0.1025  0.0507\n",
            "     20        \u001b[36m0.1020\u001b[0m  0.0420\n",
            "     21        \u001b[36m0.1018\u001b[0m  0.0417\n",
            "     22        \u001b[36m0.1001\u001b[0m  0.0415\n",
            "     23        \u001b[36m0.0998\u001b[0m  0.0418\n",
            "     24        \u001b[36m0.0996\u001b[0m  0.0420\n",
            "     25        \u001b[36m0.0990\u001b[0m  0.0421\n",
            "     26        \u001b[36m0.0982\u001b[0m  0.0434\n",
            "     27        \u001b[36m0.0975\u001b[0m  0.0416\n",
            "     28        \u001b[36m0.0966\u001b[0m  0.0431\n",
            "     29        \u001b[36m0.0966\u001b[0m  0.0429\n",
            "     30        \u001b[36m0.0948\u001b[0m  0.0430\n",
            "     31        0.0948  0.0436\n",
            "     32        \u001b[36m0.0937\u001b[0m  0.0462\n",
            "     33        \u001b[36m0.0934\u001b[0m  0.0423\n",
            "     34        \u001b[36m0.0921\u001b[0m  0.0427\n",
            "     35        \u001b[36m0.0915\u001b[0m  0.0419\n",
            "     36        0.0916  0.0424\n",
            "     37        \u001b[36m0.0898\u001b[0m  0.0424\n",
            "     38        \u001b[36m0.0887\u001b[0m  0.0467\n",
            "     39        0.0888  0.0435\n",
            "     40        \u001b[36m0.0878\u001b[0m  0.0533\n",
            "     41        \u001b[36m0.0861\u001b[0m  0.0419\n",
            "     42        \u001b[36m0.0857\u001b[0m  0.0417\n",
            "     43        0.0857  0.0418\n",
            "     44        \u001b[36m0.0844\u001b[0m  0.0453\n",
            "     45        \u001b[36m0.0831\u001b[0m  0.0426\n",
            "     46        0.0837  0.0417\n",
            "     47        \u001b[36m0.0810\u001b[0m  0.0421\n",
            "     48        \u001b[36m0.0807\u001b[0m  0.0417\n",
            "     49        0.0812  0.0428\n",
            "     50        \u001b[36m0.0805\u001b[0m  0.0429\n",
            "     51        \u001b[36m0.0791\u001b[0m  0.0427\n",
            "     52        0.0795  0.0425\n",
            "     53        \u001b[36m0.0751\u001b[0m  0.0418\n",
            "     54        \u001b[36m0.0741\u001b[0m  0.0419\n",
            "     55        0.0748  0.0441\n",
            "     56        0.0741  0.0438\n",
            "     57        0.0747  0.0426\n",
            "     58        \u001b[36m0.0712\u001b[0m  0.0434\n",
            "     59        0.0715  0.0425\n",
            "     60        \u001b[36m0.0696\u001b[0m  0.0429\n",
            "     61        0.0723  0.0455\n",
            "     62        \u001b[36m0.0677\u001b[0m  0.0539\n",
            "     63        0.0690  0.0627\n",
            "     64        \u001b[36m0.0670\u001b[0m  0.0471\n",
            "     65        \u001b[36m0.0668\u001b[0m  0.0473\n",
            "     66        \u001b[36m0.0654\u001b[0m  0.0448\n",
            "     67        \u001b[36m0.0653\u001b[0m  0.0434\n",
            "     68        \u001b[36m0.0639\u001b[0m  0.0420\n",
            "     69        \u001b[36m0.0631\u001b[0m  0.0439\n",
            "     70        0.0642  0.0427\n",
            "     71        \u001b[36m0.0620\u001b[0m  0.0462\n",
            "     72        \u001b[36m0.0619\u001b[0m  0.0434\n",
            "     73        \u001b[36m0.0608\u001b[0m  0.0434\n",
            "     74        \u001b[36m0.0605\u001b[0m  0.0417\n",
            "     75        0.0606  0.0415\n",
            "     76        \u001b[36m0.0599\u001b[0m  0.0421\n",
            "     77        \u001b[36m0.0580\u001b[0m  0.0439\n",
            "     78        \u001b[36m0.0557\u001b[0m  0.0422\n",
            "     79        0.0571  0.0430\n",
            "     80        0.0569  0.0427\n",
            "     81        \u001b[36m0.0545\u001b[0m  0.0417\n",
            "     82        \u001b[36m0.0533\u001b[0m  0.0417\n",
            "     83        0.0555  0.0599\n",
            "     84        0.0557  0.0631\n",
            "     85        \u001b[36m0.0524\u001b[0m  0.0771\n",
            "     86        \u001b[36m0.0504\u001b[0m  0.0597\n",
            "     87        0.0522  0.0580\n",
            "     88        0.0531  0.0582\n",
            "     89        \u001b[36m0.0492\u001b[0m  0.0545\n",
            "     90        0.0495  0.0575\n",
            "     91        \u001b[36m0.0491\u001b[0m  0.0546\n",
            "     92        \u001b[36m0.0489\u001b[0m  0.0557\n",
            "     93        \u001b[36m0.0469\u001b[0m  0.0536\n",
            "     94        \u001b[36m0.0466\u001b[0m  0.0546\n",
            "     95        0.0481  0.0560\n",
            "     96        0.0468  0.0559\n",
            "     97        0.0469  0.0559\n",
            "     98        \u001b[36m0.0458\u001b[0m  0.0584\n",
            "     99        \u001b[36m0.0452\u001b[0m  0.0553\n",
            "    100        \u001b[36m0.0446\u001b[0m  0.0507\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1679\u001b[0m  0.1383\n",
            "      2        \u001b[36m0.1460\u001b[0m  0.0593\n",
            "      3        \u001b[36m0.1323\u001b[0m  0.0530\n",
            "      4        \u001b[36m0.1267\u001b[0m  0.0632\n",
            "      5        \u001b[36m0.1207\u001b[0m  0.0670\n",
            "      6        \u001b[36m0.1147\u001b[0m  0.0651\n",
            "      7        \u001b[36m0.1115\u001b[0m  0.0596\n",
            "      8        \u001b[36m0.1092\u001b[0m  0.0699\n",
            "      9        \u001b[36m0.1072\u001b[0m  0.0821\n",
            "     10        \u001b[36m0.1061\u001b[0m  0.0645\n",
            "     11        \u001b[36m0.1032\u001b[0m  0.0660\n",
            "     12        \u001b[36m0.1027\u001b[0m  0.0711\n",
            "     13        \u001b[36m0.0998\u001b[0m  0.0704\n",
            "     14        0.1005  0.0657\n",
            "     15        0.1003  0.0616\n",
            "     16        \u001b[36m0.0976\u001b[0m  0.0539\n",
            "     17        0.0989  0.0545\n",
            "     18        \u001b[36m0.0966\u001b[0m  0.0434\n",
            "     19        \u001b[36m0.0964\u001b[0m  0.0461\n",
            "     20        \u001b[36m0.0957\u001b[0m  0.0423\n",
            "     21        0.0964  0.0439\n",
            "     22        \u001b[36m0.0931\u001b[0m  0.0439\n",
            "     23        \u001b[36m0.0924\u001b[0m  0.0439\n",
            "     24        \u001b[36m0.0916\u001b[0m  0.0427\n",
            "     25        \u001b[36m0.0904\u001b[0m  0.0434\n",
            "     26        \u001b[36m0.0889\u001b[0m  0.0435\n",
            "     27        0.0901  0.0448\n",
            "     28        \u001b[36m0.0882\u001b[0m  0.0446\n",
            "     29        \u001b[36m0.0859\u001b[0m  0.0430\n",
            "     30        \u001b[36m0.0849\u001b[0m  0.0447\n",
            "     31        0.0861  0.0451\n",
            "     32        \u001b[36m0.0830\u001b[0m  0.0429\n",
            "     33        \u001b[36m0.0806\u001b[0m  0.0425\n",
            "     34        \u001b[36m0.0789\u001b[0m  0.0424\n",
            "     35        \u001b[36m0.0783\u001b[0m  0.0429\n",
            "     36        \u001b[36m0.0769\u001b[0m  0.0427\n",
            "     37        \u001b[36m0.0742\u001b[0m  0.0481\n",
            "     38        \u001b[36m0.0728\u001b[0m  0.0425\n",
            "     39        0.0734  0.0489\n",
            "     40        \u001b[36m0.0722\u001b[0m  0.0532\n",
            "     41        \u001b[36m0.0708\u001b[0m  0.0434\n",
            "     42        \u001b[36m0.0684\u001b[0m  0.0450\n",
            "     43        \u001b[36m0.0678\u001b[0m  0.0500\n",
            "     44        \u001b[36m0.0665\u001b[0m  0.0449\n",
            "     45        \u001b[36m0.0653\u001b[0m  0.0432\n",
            "     46        0.0661  0.0427\n",
            "     47        \u001b[36m0.0640\u001b[0m  0.0425\n",
            "     48        \u001b[36m0.0620\u001b[0m  0.0433\n",
            "     49        \u001b[36m0.0607\u001b[0m  0.0450\n",
            "     50        0.0613  0.0431\n",
            "     51        \u001b[36m0.0591\u001b[0m  0.0428\n",
            "     52        \u001b[36m0.0575\u001b[0m  0.0424\n",
            "     53        \u001b[36m0.0566\u001b[0m  0.0433\n",
            "     54        \u001b[36m0.0552\u001b[0m  0.0426\n",
            "     55        0.0559  0.0488\n",
            "     56        \u001b[36m0.0528\u001b[0m  0.0427\n",
            "     57        0.0546  0.0423\n",
            "     58        \u001b[36m0.0526\u001b[0m  0.0424\n",
            "     59        0.0535  0.0426\n",
            "     60        \u001b[36m0.0526\u001b[0m  0.0431\n",
            "     61        \u001b[36m0.0506\u001b[0m  0.0445\n",
            "     62        \u001b[36m0.0498\u001b[0m  0.0567\n",
            "     63        \u001b[36m0.0490\u001b[0m  0.0431\n",
            "     64        \u001b[36m0.0489\u001b[0m  0.0433\n",
            "     65        \u001b[36m0.0481\u001b[0m  0.0439\n",
            "     66        0.0483  0.0439\n",
            "     67        \u001b[36m0.0476\u001b[0m  0.0479\n",
            "     68        \u001b[36m0.0473\u001b[0m  0.0427\n",
            "     69        \u001b[36m0.0456\u001b[0m  0.0427\n",
            "     70        \u001b[36m0.0436\u001b[0m  0.0426\n",
            "     71        \u001b[36m0.0432\u001b[0m  0.0449\n",
            "     72        \u001b[36m0.0432\u001b[0m  0.0433\n",
            "     73        \u001b[36m0.0409\u001b[0m  0.0447\n",
            "     74        0.0421  0.0428\n",
            "     75        \u001b[36m0.0400\u001b[0m  0.0427\n",
            "     76        0.0405  0.0427\n",
            "     77        \u001b[36m0.0378\u001b[0m  0.0426\n",
            "     78        0.0390  0.0425\n",
            "     79        0.0390  0.0479\n",
            "     80        0.0387  0.0441\n",
            "     81        0.0379  0.0425\n",
            "     82        \u001b[36m0.0372\u001b[0m  0.0428\n",
            "     83        0.0377  0.0429\n",
            "     84        \u001b[36m0.0368\u001b[0m  0.0429\n",
            "     85        0.0371  0.0581\n",
            "     86        \u001b[36m0.0340\u001b[0m  0.0432\n",
            "     87        0.0344  0.0435\n",
            "     88        \u001b[36m0.0331\u001b[0m  0.0444\n",
            "     89        0.0335  0.0429\n",
            "     90        0.0340  0.0428\n",
            "     91        \u001b[36m0.0310\u001b[0m  0.0442\n",
            "     92        \u001b[36m0.0303\u001b[0m  0.0421\n",
            "     93        0.0321  0.0445\n",
            "     94        0.0311  0.0427\n",
            "     95        0.0304  0.0455\n",
            "     96        \u001b[36m0.0292\u001b[0m  0.0430\n",
            "     97        0.0296  0.0444\n",
            "     98        \u001b[36m0.0280\u001b[0m  0.0434\n",
            "     99        0.0293  0.0433\n",
            "    100        \u001b[36m0.0272\u001b[0m  0.0465\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1780\u001b[0m  0.0335\n",
            "      2        \u001b[36m0.1467\u001b[0m  0.0168\n",
            "      3        \u001b[36m0.1374\u001b[0m  0.0156\n",
            "      4        \u001b[36m0.1256\u001b[0m  0.0152\n",
            "      5        \u001b[36m0.1202\u001b[0m  0.0132\n",
            "      6        \u001b[36m0.1108\u001b[0m  0.0145\n",
            "      7        \u001b[36m0.1016\u001b[0m  0.0143\n",
            "      8        \u001b[36m0.0966\u001b[0m  0.0138\n",
            "      9        \u001b[36m0.0952\u001b[0m  0.0130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.0906\u001b[0m  0.0142\n",
            "     11        \u001b[36m0.0870\u001b[0m  0.0169\n",
            "     12        \u001b[36m0.0817\u001b[0m  0.0139\n",
            "     13        0.0824  0.0128\n",
            "     14        \u001b[36m0.0791\u001b[0m  0.0132\n",
            "     15        \u001b[36m0.0774\u001b[0m  0.0162\n",
            "     16        \u001b[36m0.0728\u001b[0m  0.0141\n",
            "     17        \u001b[36m0.0692\u001b[0m  0.0129\n",
            "     18        \u001b[36m0.0685\u001b[0m  0.0234\n",
            "     19        \u001b[36m0.0680\u001b[0m  0.0211\n",
            "     20        \u001b[36m0.0635\u001b[0m  0.0138\n",
            "     21        \u001b[36m0.0619\u001b[0m  0.0128\n",
            "     22        \u001b[36m0.0612\u001b[0m  0.0128\n",
            "     23        \u001b[36m0.0581\u001b[0m  0.0180\n",
            "     24        \u001b[36m0.0563\u001b[0m  0.0140\n",
            "     25        \u001b[36m0.0554\u001b[0m  0.0128\n",
            "     26        \u001b[36m0.0526\u001b[0m  0.0144\n",
            "     27        \u001b[36m0.0504\u001b[0m  0.0143\n",
            "     28        \u001b[36m0.0504\u001b[0m  0.0135\n",
            "     29        \u001b[36m0.0493\u001b[0m  0.0135\n",
            "     30        0.0496  0.0132\n",
            "     31        \u001b[36m0.0464\u001b[0m  0.0157\n",
            "     32        \u001b[36m0.0454\u001b[0m  0.0137\n",
            "     33        \u001b[36m0.0445\u001b[0m  0.0143\n",
            "     34        \u001b[36m0.0442\u001b[0m  0.0128\n",
            "     35        \u001b[36m0.0428\u001b[0m  0.0137\n",
            "     36        \u001b[36m0.0412\u001b[0m  0.0214\n",
            "     37        \u001b[36m0.0398\u001b[0m  0.0144\n",
            "     38        \u001b[36m0.0373\u001b[0m  0.0133\n",
            "     39        \u001b[36m0.0365\u001b[0m  0.0137\n",
            "     40        \u001b[36m0.0359\u001b[0m  0.0167\n",
            "     41        0.0364  0.0142\n",
            "     42        \u001b[36m0.0333\u001b[0m  0.0132\n",
            "     43        0.0342  0.0141\n",
            "     44        \u001b[36m0.0321\u001b[0m  0.0149\n",
            "     45        \u001b[36m0.0303\u001b[0m  0.0140\n",
            "     46        \u001b[36m0.0299\u001b[0m  0.0145\n",
            "     47        \u001b[36m0.0282\u001b[0m  0.0131\n",
            "     48        0.0290  0.0137\n",
            "     49        0.0295  0.0170\n",
            "     50        0.0286  0.0140\n",
            "     51        \u001b[36m0.0254\u001b[0m  0.0130\n",
            "     52        0.0277  0.0131\n",
            "     53        \u001b[36m0.0249\u001b[0m  0.0186\n",
            "     54        \u001b[36m0.0245\u001b[0m  0.0158\n",
            "     55        \u001b[36m0.0244\u001b[0m  0.0140\n",
            "     56        0.0259  0.0127\n",
            "     57        \u001b[36m0.0240\u001b[0m  0.0129\n",
            "     58        \u001b[36m0.0220\u001b[0m  0.0167\n",
            "     59        \u001b[36m0.0207\u001b[0m  0.0137\n",
            "     60        0.0209  0.0126\n",
            "     61        0.0216  0.0128\n",
            "     62        0.0223  0.0157\n",
            "     63        0.0219  0.0142\n",
            "     64        0.0207  0.0128\n",
            "     65        \u001b[36m0.0202\u001b[0m  0.0131\n",
            "     66        0.0215  0.0148\n",
            "     67        \u001b[36m0.0201\u001b[0m  0.0141\n",
            "     68        \u001b[36m0.0200\u001b[0m  0.0140\n",
            "     69        \u001b[36m0.0166\u001b[0m  0.0148\n",
            "     70        0.0185  0.0144\n",
            "     71        0.0174  0.0148\n",
            "     72        \u001b[36m0.0164\u001b[0m  0.0143\n",
            "     73        0.0170  0.0142\n",
            "     74        0.0183  0.0144\n",
            "     75        0.0168  0.0142\n",
            "     76        0.0177  0.0131\n",
            "     77        \u001b[36m0.0153\u001b[0m  0.0136\n",
            "     78        0.0158  0.0158\n",
            "     79        0.0161  0.0136\n",
            "     80        0.0159  0.0141\n",
            "     81        0.0159  0.0130\n",
            "     82        \u001b[36m0.0152\u001b[0m  0.0130\n",
            "     83        0.0163  0.0150\n",
            "     84        \u001b[36m0.0148\u001b[0m  0.0147\n",
            "     85        \u001b[36m0.0137\u001b[0m  0.0144\n",
            "     86        0.0146  0.0229\n",
            "     87        0.0139  0.0176\n",
            "     88        0.0142  0.0156\n",
            "     89        0.0153  0.0155\n",
            "     90        0.0137  0.0141\n",
            "     91        \u001b[36m0.0133\u001b[0m  0.0136\n",
            "     92        0.0134  0.0142\n",
            "     93        \u001b[36m0.0131\u001b[0m  0.0137\n",
            "     94        \u001b[36m0.0122\u001b[0m  0.0148\n",
            "     95        0.0128  0.0136\n",
            "     96        0.0127  0.0129\n",
            "     97        0.0126  0.0129\n",
            "     98        0.0139  0.0157\n",
            "     99        0.0126  0.0137\n",
            "    100        \u001b[36m0.0120\u001b[0m  0.0126\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.2049\u001b[0m  0.0673\n",
            "      2        \u001b[36m0.1726\u001b[0m  0.0278\n",
            "      3        \u001b[36m0.1556\u001b[0m  0.0267\n",
            "      4        \u001b[36m0.1379\u001b[0m  0.0259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.1282\u001b[0m  0.0296\n",
            "      6        \u001b[36m0.1179\u001b[0m  0.0267\n",
            "      7        \u001b[36m0.1131\u001b[0m  0.0269\n",
            "      8        \u001b[36m0.1072\u001b[0m  0.0287\n",
            "      9        \u001b[36m0.1037\u001b[0m  0.0263\n",
            "     10        \u001b[36m0.1006\u001b[0m  0.0264\n",
            "     11        \u001b[36m0.0971\u001b[0m  0.0318\n",
            "     12        \u001b[36m0.0915\u001b[0m  0.0258\n",
            "     13        \u001b[36m0.0898\u001b[0m  0.0265\n",
            "     14        \u001b[36m0.0856\u001b[0m  0.0262\n",
            "     15        \u001b[36m0.0827\u001b[0m  0.0260\n",
            "     16        \u001b[36m0.0796\u001b[0m  0.0265\n",
            "     17        \u001b[36m0.0772\u001b[0m  0.0265\n",
            "     18        \u001b[36m0.0756\u001b[0m  0.0271\n",
            "     19        \u001b[36m0.0717\u001b[0m  0.0262\n",
            "     20        \u001b[36m0.0695\u001b[0m  0.0278\n",
            "     21        \u001b[36m0.0650\u001b[0m  0.0286\n",
            "     22        0.0652  0.0269\n",
            "     23        \u001b[36m0.0630\u001b[0m  0.0264\n",
            "     24        \u001b[36m0.0598\u001b[0m  0.0269\n",
            "     25        \u001b[36m0.0592\u001b[0m  0.0269\n",
            "     26        \u001b[36m0.0562\u001b[0m  0.0296\n",
            "     27        \u001b[36m0.0549\u001b[0m  0.0382\n",
            "     28        \u001b[36m0.0538\u001b[0m  0.0279\n",
            "     29        \u001b[36m0.0524\u001b[0m  0.0262\n",
            "     30        \u001b[36m0.0510\u001b[0m  0.0300\n",
            "     31        \u001b[36m0.0500\u001b[0m  0.0264\n",
            "     32        \u001b[36m0.0489\u001b[0m  0.0261\n",
            "     33        \u001b[36m0.0454\u001b[0m  0.0265\n",
            "     34        \u001b[36m0.0454\u001b[0m  0.0263\n",
            "     35        \u001b[36m0.0440\u001b[0m  0.0266\n",
            "     36        \u001b[36m0.0427\u001b[0m  0.0278\n",
            "     37        \u001b[36m0.0411\u001b[0m  0.0264\n",
            "     38        \u001b[36m0.0409\u001b[0m  0.0266\n",
            "     39        \u001b[36m0.0406\u001b[0m  0.0274\n",
            "     40        \u001b[36m0.0380\u001b[0m  0.0263\n",
            "     41        \u001b[36m0.0377\u001b[0m  0.0261\n",
            "     42        \u001b[36m0.0359\u001b[0m  0.0275\n",
            "     43        \u001b[36m0.0356\u001b[0m  0.0265\n",
            "     44        \u001b[36m0.0354\u001b[0m  0.0260\n",
            "     45        \u001b[36m0.0340\u001b[0m  0.0259\n",
            "     46        \u001b[36m0.0327\u001b[0m  0.0262\n",
            "     47        0.0330  0.0260\n",
            "     48        \u001b[36m0.0313\u001b[0m  0.0261\n",
            "     49        \u001b[36m0.0305\u001b[0m  0.0307\n",
            "     50        \u001b[36m0.0289\u001b[0m  0.0260\n",
            "     51        0.0291  0.0261\n",
            "     52        \u001b[36m0.0288\u001b[0m  0.0261\n",
            "     53        \u001b[36m0.0274\u001b[0m  0.0258\n",
            "     54        0.0276  0.0289\n",
            "     55        \u001b[36m0.0271\u001b[0m  0.0258\n",
            "     56        \u001b[36m0.0258\u001b[0m  0.0260\n",
            "     57        0.0267  0.0260\n",
            "     58        0.0266  0.0261\n",
            "     59        \u001b[36m0.0246\u001b[0m  0.0271\n",
            "     60        0.0254  0.0262\n",
            "     61        0.0250  0.0263\n",
            "     62        \u001b[36m0.0239\u001b[0m  0.0265\n",
            "     63        0.0246  0.0276\n",
            "     64        \u001b[36m0.0238\u001b[0m  0.0412\n",
            "     65        0.0241  0.0266\n",
            "     66        \u001b[36m0.0212\u001b[0m  0.0293\n",
            "     67        0.0216  0.0263\n",
            "     68        \u001b[36m0.0207\u001b[0m  0.0272\n",
            "     69        0.0207  0.0392\n",
            "     70        0.0217  0.0370\n",
            "     71        \u001b[36m0.0205\u001b[0m  0.0278\n",
            "     72        \u001b[36m0.0192\u001b[0m  0.0269\n",
            "     73        0.0192  0.0257\n",
            "     74        0.0197  0.0263\n",
            "     75        \u001b[36m0.0183\u001b[0m  0.0264\n",
            "     76        0.0187  0.0277\n",
            "     77        0.0187  0.0292\n",
            "     78        0.0186  0.0264\n",
            "     79        \u001b[36m0.0173\u001b[0m  0.0256\n",
            "     80        0.0178  0.0261\n",
            "     81        0.0176  0.0264\n",
            "     82        0.0182  0.0261\n",
            "     83        \u001b[36m0.0170\u001b[0m  0.0269\n",
            "     84        \u001b[36m0.0168\u001b[0m  0.0261\n",
            "     85        \u001b[36m0.0166\u001b[0m  0.0261\n",
            "     86        \u001b[36m0.0165\u001b[0m  0.0262\n",
            "     87        \u001b[36m0.0160\u001b[0m  0.0314\n",
            "     88        \u001b[36m0.0149\u001b[0m  0.0272\n",
            "     89        \u001b[36m0.0149\u001b[0m  0.0260\n",
            "     90        0.0161  0.0253\n",
            "     91        0.0153  0.0260\n",
            "     92        0.0153  0.0259\n",
            "     93        0.0151  0.0262\n",
            "     94        0.0154  0.0261\n",
            "     95        \u001b[36m0.0148\u001b[0m  0.0263\n",
            "     96        0.0148  0.0261\n",
            "     97        0.0152  0.0275\n",
            "     98        \u001b[36m0.0140\u001b[0m  0.0274\n",
            "     99        0.0146  0.0263\n",
            "    100        \u001b[36m0.0133\u001b[0m  0.0429\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1603\u001b[0m  0.0460\n",
            "      2        \u001b[36m0.1276\u001b[0m  0.0272\n",
            "      3        \u001b[36m0.1155\u001b[0m  0.0272\n",
            "      4        \u001b[36m0.1070\u001b[0m  0.0289\n",
            "      5        \u001b[36m0.0991\u001b[0m  0.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0929\u001b[0m  0.0295\n",
            "      7        \u001b[36m0.0880\u001b[0m  0.0274\n",
            "      8        \u001b[36m0.0834\u001b[0m  0.0270\n",
            "      9        \u001b[36m0.0794\u001b[0m  0.0283\n",
            "     10        \u001b[36m0.0773\u001b[0m  0.0268\n",
            "     11        \u001b[36m0.0731\u001b[0m  0.0268\n",
            "     12        \u001b[36m0.0707\u001b[0m  0.0269\n",
            "     13        \u001b[36m0.0691\u001b[0m  0.0318\n",
            "     14        \u001b[36m0.0647\u001b[0m  0.0269\n",
            "     15        \u001b[36m0.0613\u001b[0m  0.0269\n",
            "     16        \u001b[36m0.0605\u001b[0m  0.0269\n",
            "     17        \u001b[36m0.0579\u001b[0m  0.0268\n",
            "     18        \u001b[36m0.0569\u001b[0m  0.0268\n",
            "     19        \u001b[36m0.0548\u001b[0m  0.0268\n",
            "     20        \u001b[36m0.0525\u001b[0m  0.0269\n",
            "     21        \u001b[36m0.0516\u001b[0m  0.0280\n",
            "     22        \u001b[36m0.0494\u001b[0m  0.0281\n",
            "     23        \u001b[36m0.0472\u001b[0m  0.0265\n",
            "     24        \u001b[36m0.0462\u001b[0m  0.0270\n",
            "     25        \u001b[36m0.0437\u001b[0m  0.0268\n",
            "     26        \u001b[36m0.0428\u001b[0m  0.0270\n",
            "     27        \u001b[36m0.0400\u001b[0m  0.0265\n",
            "     28        \u001b[36m0.0390\u001b[0m  0.0270\n",
            "     29        \u001b[36m0.0384\u001b[0m  0.0268\n",
            "     30        \u001b[36m0.0353\u001b[0m  0.0267\n",
            "     31        0.0356  0.0269\n",
            "     32        \u001b[36m0.0344\u001b[0m  0.0285\n",
            "     33        \u001b[36m0.0325\u001b[0m  0.0285\n",
            "     34        \u001b[36m0.0310\u001b[0m  0.0401\n",
            "     35        \u001b[36m0.0296\u001b[0m  0.0267\n",
            "     36        \u001b[36m0.0285\u001b[0m  0.0269\n",
            "     37        \u001b[36m0.0282\u001b[0m  0.0267\n",
            "     38        \u001b[36m0.0275\u001b[0m  0.0272\n",
            "     39        \u001b[36m0.0254\u001b[0m  0.0269\n",
            "     40        0.0256  0.0277\n",
            "     41        \u001b[36m0.0248\u001b[0m  0.0280\n",
            "     42        \u001b[36m0.0232\u001b[0m  0.0264\n",
            "     43        \u001b[36m0.0228\u001b[0m  0.0268\n",
            "     44        \u001b[36m0.0223\u001b[0m  0.0273\n",
            "     45        \u001b[36m0.0209\u001b[0m  0.0280\n",
            "     46        \u001b[36m0.0205\u001b[0m  0.0267\n",
            "     47        \u001b[36m0.0198\u001b[0m  0.0270\n",
            "     48        0.0199  0.0269\n",
            "     49        \u001b[36m0.0187\u001b[0m  0.0269\n",
            "     50        \u001b[36m0.0182\u001b[0m  0.0315\n",
            "     51        \u001b[36m0.0178\u001b[0m  0.0268\n",
            "     52        \u001b[36m0.0175\u001b[0m  0.0265\n",
            "     53        \u001b[36m0.0171\u001b[0m  0.0264\n",
            "     54        \u001b[36m0.0163\u001b[0m  0.0268\n",
            "     55        0.0166  0.0267\n",
            "     56        0.0165  0.0266\n",
            "     57        \u001b[36m0.0157\u001b[0m  0.0312\n",
            "     58        \u001b[36m0.0154\u001b[0m  0.0478\n",
            "     59        \u001b[36m0.0148\u001b[0m  0.0408\n",
            "     60        \u001b[36m0.0144\u001b[0m  0.0431\n",
            "     61        \u001b[36m0.0139\u001b[0m  0.0344\n",
            "     62        0.0140  0.0351\n",
            "     63        \u001b[36m0.0138\u001b[0m  0.0338\n",
            "     64        \u001b[36m0.0135\u001b[0m  0.0378\n",
            "     65        0.0136  0.0342\n",
            "     66        0.0136  0.0425\n",
            "     67        \u001b[36m0.0129\u001b[0m  0.0458\n",
            "     68        \u001b[36m0.0125\u001b[0m  0.0387\n",
            "     69        \u001b[36m0.0123\u001b[0m  0.0339\n",
            "     70        \u001b[36m0.0122\u001b[0m  0.0336\n",
            "     71        \u001b[36m0.0116\u001b[0m  0.0349\n",
            "     72        0.0116  0.0335\n",
            "     73        \u001b[36m0.0110\u001b[0m  0.0347\n",
            "     74        0.0116  0.0337\n",
            "     75        0.0119  0.0336\n",
            "     76        0.0114  0.0335\n",
            "     77        0.0116  0.0334\n",
            "     78        0.0111  0.0334\n",
            "     79        \u001b[36m0.0107\u001b[0m  0.0334\n",
            "     80        0.0107  0.0332\n",
            "     81        0.0111  0.0367\n",
            "     82        0.0107  0.0382\n",
            "     83        \u001b[36m0.0104\u001b[0m  0.0347\n",
            "     84        \u001b[36m0.0103\u001b[0m  0.0321\n",
            "     85        \u001b[36m0.0100\u001b[0m  0.0322\n",
            "     86        0.0103  0.0319\n",
            "     87        \u001b[36m0.0096\u001b[0m  0.0322\n",
            "     88        \u001b[36m0.0092\u001b[0m  0.0326\n",
            "     89        0.0095  0.0319\n",
            "     90        0.0093  0.0320\n",
            "     91        0.0094  0.0318\n",
            "     92        0.0095  0.0338\n",
            "     93        0.0095  0.0337\n",
            "     94        \u001b[36m0.0090\u001b[0m  0.0327\n",
            "     95        0.0094  0.0319\n",
            "     96        0.0093  0.0360\n",
            "     97        \u001b[36m0.0086\u001b[0m  0.0378\n",
            "     98        0.0087  0.0338\n",
            "     99        0.0091  0.0392\n",
            "    100        0.0094  0.0369\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1558\u001b[0m  0.0194\n",
            "      2        \u001b[36m0.1340\u001b[0m  0.0265\n",
            "      3        \u001b[36m0.1216\u001b[0m  0.0211\n",
            "      4        \u001b[36m0.1161\u001b[0m  0.0169\n",
            "      5        \u001b[36m0.1125\u001b[0m  0.0205\n",
            "      6        \u001b[36m0.1068\u001b[0m  0.0207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.1008\u001b[0m  0.0194\n",
            "      8        \u001b[36m0.0969\u001b[0m  0.0210\n",
            "      9        \u001b[36m0.0918\u001b[0m  0.0212\n",
            "     10        \u001b[36m0.0916\u001b[0m  0.0186\n",
            "     11        \u001b[36m0.0822\u001b[0m  0.0197\n",
            "     12        \u001b[36m0.0810\u001b[0m  0.0232\n",
            "     13        \u001b[36m0.0798\u001b[0m  0.0241\n",
            "     14        \u001b[36m0.0762\u001b[0m  0.0215\n",
            "     15        \u001b[36m0.0758\u001b[0m  0.0182\n",
            "     16        \u001b[36m0.0723\u001b[0m  0.0173\n",
            "     17        \u001b[36m0.0692\u001b[0m  0.0171\n",
            "     18        0.0695  0.0235\n",
            "     19        \u001b[36m0.0656\u001b[0m  0.0204\n",
            "     20        \u001b[36m0.0620\u001b[0m  0.0209\n",
            "     21        0.0647  0.0203\n",
            "     22        \u001b[36m0.0584\u001b[0m  0.0201\n",
            "     23        0.0585  0.0213\n",
            "     24        \u001b[36m0.0551\u001b[0m  0.0211\n",
            "     25        \u001b[36m0.0528\u001b[0m  0.0251\n",
            "     26        0.0535  0.0271\n",
            "     27        0.0530  0.0221\n",
            "     28        \u001b[36m0.0517\u001b[0m  0.0192\n",
            "     29        \u001b[36m0.0498\u001b[0m  0.0184\n",
            "     30        \u001b[36m0.0469\u001b[0m  0.0181\n",
            "     31        \u001b[36m0.0465\u001b[0m  0.0172\n",
            "     32        \u001b[36m0.0450\u001b[0m  0.0172\n",
            "     33        0.0467  0.0168\n",
            "     34        \u001b[36m0.0441\u001b[0m  0.0174\n",
            "     35        \u001b[36m0.0416\u001b[0m  0.0172\n",
            "     36        \u001b[36m0.0392\u001b[0m  0.0135\n",
            "     37        \u001b[36m0.0380\u001b[0m  0.0129\n",
            "     38        0.0385  0.0142\n",
            "     39        \u001b[36m0.0378\u001b[0m  0.0167\n",
            "     40        \u001b[36m0.0345\u001b[0m  0.0220\n",
            "     41        0.0358  0.0191\n",
            "     42        \u001b[36m0.0342\u001b[0m  0.0135\n",
            "     43        \u001b[36m0.0327\u001b[0m  0.0174\n",
            "     44        0.0332  0.0141\n",
            "     45        0.0335  0.0142\n",
            "     46        \u001b[36m0.0309\u001b[0m  0.0144\n",
            "     47        \u001b[36m0.0304\u001b[0m  0.0130\n",
            "     48        \u001b[36m0.0292\u001b[0m  0.0132\n",
            "     49        0.0300  0.0181\n",
            "     50        \u001b[36m0.0265\u001b[0m  0.0141\n",
            "     51        0.0277  0.0141\n",
            "     52        \u001b[36m0.0264\u001b[0m  0.0145\n",
            "     53        \u001b[36m0.0255\u001b[0m  0.0142\n",
            "     54        \u001b[36m0.0251\u001b[0m  0.0177\n",
            "     55        \u001b[36m0.0249\u001b[0m  0.0137\n",
            "     56        0.0261  0.0156\n",
            "     57        \u001b[36m0.0246\u001b[0m  0.0142\n",
            "     58        \u001b[36m0.0240\u001b[0m  0.0156\n",
            "     59        \u001b[36m0.0225\u001b[0m  0.0144\n",
            "     60        0.0236  0.0129\n",
            "     61        \u001b[36m0.0211\u001b[0m  0.0129\n",
            "     62        0.0217  0.0164\n",
            "     63        \u001b[36m0.0207\u001b[0m  0.0144\n",
            "     64        0.0220  0.0143\n",
            "     65        \u001b[36m0.0196\u001b[0m  0.0141\n",
            "     66        0.0197  0.0148\n",
            "     67        \u001b[36m0.0191\u001b[0m  0.0161\n",
            "     68        \u001b[36m0.0189\u001b[0m  0.0144\n",
            "     69        0.0190  0.0142\n",
            "     70        \u001b[36m0.0181\u001b[0m  0.0128\n",
            "     71        0.0182  0.0165\n",
            "     72        \u001b[36m0.0167\u001b[0m  0.0142\n",
            "     73        0.0170  0.0138\n",
            "     74        \u001b[36m0.0154\u001b[0m  0.0142\n",
            "     75        0.0155  0.0140\n",
            "     76        0.0170  0.0164\n",
            "     77        0.0159  0.0142\n",
            "     78        \u001b[36m0.0148\u001b[0m  0.0124\n",
            "     79        0.0158  0.0125\n",
            "     80        \u001b[36m0.0142\u001b[0m  0.0159\n",
            "     81        0.0148  0.0138\n",
            "     82        0.0151  0.0141\n",
            "     83        0.0147  0.0139\n",
            "     84        0.0159  0.0131\n",
            "     85        0.0149  0.0128\n",
            "     86        \u001b[36m0.0138\u001b[0m  0.0163\n",
            "     87        0.0148  0.0141\n",
            "     88        0.0140  0.0154\n",
            "     89        \u001b[36m0.0135\u001b[0m  0.0139\n",
            "     90        \u001b[36m0.0133\u001b[0m  0.0127\n",
            "     91        \u001b[36m0.0126\u001b[0m  0.0147\n",
            "     92        \u001b[36m0.0124\u001b[0m  0.0167\n",
            "     93        \u001b[36m0.0122\u001b[0m  0.0140\n",
            "     94        \u001b[36m0.0121\u001b[0m  0.0128\n",
            "     95        \u001b[36m0.0117\u001b[0m  0.0141\n",
            "     96        0.0118  0.0151\n",
            "     97        0.0121  0.0140\n",
            "     98        0.0126  0.0141\n",
            "     99        \u001b[36m0.0109\u001b[0m  0.0126\n",
            "    100        0.0117  0.0129\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1918\u001b[0m  0.0291\n",
            "      2        \u001b[36m0.1600\u001b[0m  0.0278\n",
            "      3        \u001b[36m0.1391\u001b[0m  0.0430\n",
            "      4        \u001b[36m0.1316\u001b[0m  0.0265\n",
            "      5        \u001b[36m0.1184\u001b[0m  0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.1102\u001b[0m  0.0289\n",
            "      7        \u001b[36m0.1060\u001b[0m  0.0258\n",
            "      8        \u001b[36m0.1009\u001b[0m  0.0260\n",
            "      9        \u001b[36m0.0985\u001b[0m  0.0269\n",
            "     10        \u001b[36m0.0951\u001b[0m  0.0264\n",
            "     11        \u001b[36m0.0900\u001b[0m  0.0316\n",
            "     12        \u001b[36m0.0863\u001b[0m  0.0261\n",
            "     13        \u001b[36m0.0816\u001b[0m  0.0310\n",
            "     14        \u001b[36m0.0800\u001b[0m  0.0263\n",
            "     15        \u001b[36m0.0770\u001b[0m  0.0265\n",
            "     16        \u001b[36m0.0744\u001b[0m  0.0266\n",
            "     17        \u001b[36m0.0719\u001b[0m  0.0270\n",
            "     18        \u001b[36m0.0701\u001b[0m  0.0272\n",
            "     19        \u001b[36m0.0680\u001b[0m  0.0268\n",
            "     20        \u001b[36m0.0644\u001b[0m  0.0278\n",
            "     21        0.0647  0.0268\n",
            "     22        \u001b[36m0.0625\u001b[0m  0.0265\n",
            "     23        \u001b[36m0.0604\u001b[0m  0.0271\n",
            "     24        \u001b[36m0.0591\u001b[0m  0.0300\n",
            "     25        \u001b[36m0.0574\u001b[0m  0.0269\n",
            "     26        \u001b[36m0.0573\u001b[0m  0.0269\n",
            "     27        \u001b[36m0.0549\u001b[0m  0.0275\n",
            "     28        \u001b[36m0.0536\u001b[0m  0.0265\n",
            "     29        \u001b[36m0.0533\u001b[0m  0.0297\n",
            "     30        \u001b[36m0.0509\u001b[0m  0.0277\n",
            "     31        \u001b[36m0.0497\u001b[0m  0.0272\n",
            "     32        \u001b[36m0.0493\u001b[0m  0.0271\n",
            "     33        \u001b[36m0.0478\u001b[0m  0.0266\n",
            "     34        \u001b[36m0.0466\u001b[0m  0.0262\n",
            "     35        \u001b[36m0.0453\u001b[0m  0.0266\n",
            "     36        \u001b[36m0.0442\u001b[0m  0.0281\n",
            "     37        \u001b[36m0.0432\u001b[0m  0.0268\n",
            "     38        \u001b[36m0.0428\u001b[0m  0.0274\n",
            "     39        \u001b[36m0.0402\u001b[0m  0.0380\n",
            "     40        0.0409  0.0292\n",
            "     41        \u001b[36m0.0398\u001b[0m  0.0259\n",
            "     42        \u001b[36m0.0392\u001b[0m  0.0263\n",
            "     43        \u001b[36m0.0377\u001b[0m  0.0266\n",
            "     44        \u001b[36m0.0360\u001b[0m  0.0272\n",
            "     45        0.0362  0.0264\n",
            "     46        \u001b[36m0.0343\u001b[0m  0.0265\n",
            "     47        \u001b[36m0.0334\u001b[0m  0.0327\n",
            "     48        \u001b[36m0.0333\u001b[0m  0.0265\n",
            "     49        0.0341  0.0261\n",
            "     50        \u001b[36m0.0321\u001b[0m  0.0258\n",
            "     51        \u001b[36m0.0316\u001b[0m  0.0266\n",
            "     52        \u001b[36m0.0304\u001b[0m  0.0264\n",
            "     53        \u001b[36m0.0303\u001b[0m  0.0261\n",
            "     54        \u001b[36m0.0290\u001b[0m  0.0259\n",
            "     55        \u001b[36m0.0288\u001b[0m  0.0259\n",
            "     56        \u001b[36m0.0278\u001b[0m  0.0260\n",
            "     57        0.0284  0.0266\n",
            "     58        \u001b[36m0.0277\u001b[0m  0.0294\n",
            "     59        \u001b[36m0.0261\u001b[0m  0.0262\n",
            "     60        0.0275  0.0263\n",
            "     61        0.0276  0.0265\n",
            "     62        \u001b[36m0.0248\u001b[0m  0.0262\n",
            "     63        0.0269  0.0266\n",
            "     64        \u001b[36m0.0244\u001b[0m  0.0264\n",
            "     65        0.0244  0.0305\n",
            "     66        \u001b[36m0.0230\u001b[0m  0.0268\n",
            "     67        0.0234  0.0266\n",
            "     68        \u001b[36m0.0219\u001b[0m  0.0260\n",
            "     69        0.0231  0.0260\n",
            "     70        0.0229  0.0263\n",
            "     71        0.0226  0.0267\n",
            "     72        \u001b[36m0.0210\u001b[0m  0.0264\n",
            "     73        \u001b[36m0.0205\u001b[0m  0.0263\n",
            "     74        0.0215  0.0265\n",
            "     75        0.0213  0.0281\n",
            "     76        0.0213  0.0427\n",
            "     77        0.0215  0.0269\n",
            "     78        \u001b[36m0.0199\u001b[0m  0.0263\n",
            "     79        0.0202  0.0263\n",
            "     80        0.0209  0.0267\n",
            "     81        \u001b[36m0.0194\u001b[0m  0.0268\n",
            "     82        \u001b[36m0.0189\u001b[0m  0.0264\n",
            "     83        \u001b[36m0.0188\u001b[0m  0.0263\n",
            "     84        \u001b[36m0.0182\u001b[0m  0.0267\n",
            "     85        \u001b[36m0.0178\u001b[0m  0.0314\n",
            "     86        \u001b[36m0.0177\u001b[0m  0.0282\n",
            "     87        \u001b[36m0.0171\u001b[0m  0.0262\n",
            "     88        0.0175  0.0266\n",
            "     89        0.0175  0.0263\n",
            "     90        0.0171  0.0260\n",
            "     91        \u001b[36m0.0154\u001b[0m  0.0262\n",
            "     92        0.0164  0.0263\n",
            "     93        0.0167  0.0260\n",
            "     94        0.0167  0.0268\n",
            "     95        0.0156  0.0261\n",
            "     96        \u001b[36m0.0152\u001b[0m  0.0284\n",
            "     97        0.0161  0.0265\n",
            "     98        0.0154  0.0260\n",
            "     99        0.0155  0.0261\n",
            "    100        \u001b[36m0.0147\u001b[0m  0.0261\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1726\u001b[0m  0.0308\n",
            "      2        \u001b[36m0.1373\u001b[0m  0.0279\n",
            "      3        \u001b[36m0.1162\u001b[0m  0.0273\n",
            "      4        \u001b[36m0.1062\u001b[0m  0.0271\n",
            "      5        \u001b[36m0.1003\u001b[0m  0.0288\n",
            "      6        \u001b[36m0.0938\u001b[0m  0.0271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.0867\u001b[0m  0.0289\n",
            "      8        \u001b[36m0.0837\u001b[0m  0.0273\n",
            "      9        \u001b[36m0.0773\u001b[0m  0.0288\n",
            "     10        \u001b[36m0.0739\u001b[0m  0.0270\n",
            "     11        \u001b[36m0.0716\u001b[0m  0.0397\n",
            "     12        \u001b[36m0.0681\u001b[0m  0.0289\n",
            "     13        \u001b[36m0.0661\u001b[0m  0.0268\n",
            "     14        \u001b[36m0.0632\u001b[0m  0.0271\n",
            "     15        \u001b[36m0.0608\u001b[0m  0.0286\n",
            "     16        \u001b[36m0.0601\u001b[0m  0.0264\n",
            "     17        \u001b[36m0.0561\u001b[0m  0.0269\n",
            "     18        \u001b[36m0.0528\u001b[0m  0.0268\n",
            "     19        0.0528  0.0263\n",
            "     20        \u001b[36m0.0498\u001b[0m  0.0315\n",
            "     21        \u001b[36m0.0488\u001b[0m  0.0269\n",
            "     22        \u001b[36m0.0463\u001b[0m  0.0267\n",
            "     23        \u001b[36m0.0453\u001b[0m  0.0265\n",
            "     24        \u001b[36m0.0438\u001b[0m  0.0280\n",
            "     25        \u001b[36m0.0424\u001b[0m  0.0269\n",
            "     26        \u001b[36m0.0398\u001b[0m  0.0269\n",
            "     27        \u001b[36m0.0387\u001b[0m  0.0272\n",
            "     28        0.0392  0.0269\n",
            "     29        \u001b[36m0.0365\u001b[0m  0.0281\n",
            "     30        \u001b[36m0.0355\u001b[0m  0.0271\n",
            "     31        \u001b[36m0.0352\u001b[0m  0.0268\n",
            "     32        \u001b[36m0.0336\u001b[0m  0.0269\n",
            "     33        \u001b[36m0.0334\u001b[0m  0.0278\n",
            "     34        \u001b[36m0.0312\u001b[0m  0.0279\n",
            "     35        \u001b[36m0.0303\u001b[0m  0.0278\n",
            "     36        \u001b[36m0.0298\u001b[0m  0.0280\n",
            "     37        \u001b[36m0.0287\u001b[0m  0.0269\n",
            "     38        \u001b[36m0.0281\u001b[0m  0.0278\n",
            "     39        \u001b[36m0.0276\u001b[0m  0.0270\n",
            "     40        \u001b[36m0.0261\u001b[0m  0.0268\n",
            "     41        \u001b[36m0.0256\u001b[0m  0.0268\n",
            "     42        \u001b[36m0.0244\u001b[0m  0.0279\n",
            "     43        \u001b[36m0.0240\u001b[0m  0.0275\n",
            "     44        \u001b[36m0.0234\u001b[0m  0.0268\n",
            "     45        \u001b[36m0.0223\u001b[0m  0.0288\n",
            "     46        \u001b[36m0.0222\u001b[0m  0.0266\n",
            "     47        \u001b[36m0.0218\u001b[0m  0.0363\n",
            "     48        \u001b[36m0.0202\u001b[0m  0.0279\n",
            "     49        0.0208  0.0267\n",
            "     50        \u001b[36m0.0198\u001b[0m  0.0267\n",
            "     51        \u001b[36m0.0193\u001b[0m  0.0287\n",
            "     52        \u001b[36m0.0192\u001b[0m  0.0267\n",
            "     53        \u001b[36m0.0185\u001b[0m  0.0270\n",
            "     54        \u001b[36m0.0182\u001b[0m  0.0268\n",
            "     55        \u001b[36m0.0171\u001b[0m  0.0264\n",
            "     56        \u001b[36m0.0171\u001b[0m  0.0311\n",
            "     57        \u001b[36m0.0163\u001b[0m  0.0269\n",
            "     58        0.0166  0.0267\n",
            "     59        \u001b[36m0.0162\u001b[0m  0.0264\n",
            "     60        \u001b[36m0.0154\u001b[0m  0.0272\n",
            "     61        \u001b[36m0.0154\u001b[0m  0.0277\n",
            "     62        \u001b[36m0.0153\u001b[0m  0.0265\n",
            "     63        0.0153  0.0268\n",
            "     64        \u001b[36m0.0143\u001b[0m  0.0271\n",
            "     65        \u001b[36m0.0139\u001b[0m  0.0275\n",
            "     66        0.0146  0.0265\n",
            "     67        \u001b[36m0.0137\u001b[0m  0.0267\n",
            "     68        0.0138  0.0268\n",
            "     69        \u001b[36m0.0134\u001b[0m  0.0269\n",
            "     70        0.0136  0.0290\n",
            "     71        0.0136  0.0285\n",
            "     72        \u001b[36m0.0123\u001b[0m  0.0270\n",
            "     73        0.0124  0.0268\n",
            "     74        \u001b[36m0.0123\u001b[0m  0.0278\n",
            "     75        0.0124  0.0268\n",
            "     76        0.0131  0.0265\n",
            "     77        \u001b[36m0.0118\u001b[0m  0.0270\n",
            "     78        0.0124  0.0274\n",
            "     79        \u001b[36m0.0118\u001b[0m  0.0272\n",
            "     80        \u001b[36m0.0114\u001b[0m  0.0293\n",
            "     81        \u001b[36m0.0111\u001b[0m  0.0268\n",
            "     82        0.0116  0.0300\n",
            "     83        0.0112  0.0354\n",
            "     84        \u001b[36m0.0109\u001b[0m  0.0339\n",
            "     85        0.0117  0.0284\n",
            "     86        \u001b[36m0.0106\u001b[0m  0.0269\n",
            "     87        0.0108  0.0273\n",
            "     88        \u001b[36m0.0102\u001b[0m  0.0276\n",
            "     89        \u001b[36m0.0099\u001b[0m  0.0276\n",
            "     90        0.0104  0.0273\n",
            "     91        0.0105  0.0266\n",
            "     92        \u001b[36m0.0099\u001b[0m  0.0324\n",
            "     93        \u001b[36m0.0097\u001b[0m  0.0278\n",
            "     94        \u001b[36m0.0095\u001b[0m  0.0295\n",
            "     95        0.0099  0.0266\n",
            "     96        0.0095  0.0270\n",
            "     97        0.0096  0.0264\n",
            "     98        \u001b[36m0.0095\u001b[0m  0.0274\n",
            "     99        \u001b[36m0.0093\u001b[0m  0.0269\n",
            "    100        \u001b[36m0.0088\u001b[0m  0.0270\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1773\u001b[0m  0.0203\n",
            "      2        \u001b[36m0.1687\u001b[0m  0.0179\n",
            "      3        \u001b[36m0.1615\u001b[0m  0.0164\n",
            "      4        \u001b[36m0.1451\u001b[0m  0.0173\n",
            "      5        0.1504  0.0160\n",
            "      6        \u001b[36m0.1419\u001b[0m  0.0182\n",
            "      7        \u001b[36m0.1327\u001b[0m  0.0174\n",
            "      8        \u001b[36m0.1254\u001b[0m  0.0172\n",
            "      9        0.1279  0.0157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.1211\u001b[0m  0.0224\n",
            "     11        0.1233  0.0176\n",
            "     12        \u001b[36m0.1205\u001b[0m  0.0176\n",
            "     13        \u001b[36m0.1114\u001b[0m  0.0191\n",
            "     14        0.1115  0.0168\n",
            "     15        \u001b[36m0.1098\u001b[0m  0.0150\n",
            "     16        0.1100  0.0180\n",
            "     17        \u001b[36m0.1040\u001b[0m  0.0180\n",
            "     18        0.1085  0.0166\n",
            "     19        \u001b[36m0.1035\u001b[0m  0.0164\n",
            "     20        0.1067  0.0176\n",
            "     21        0.1049  0.0162\n",
            "     22        \u001b[36m0.0987\u001b[0m  0.0170\n",
            "     23        0.1039  0.0155\n",
            "     24        0.1010  0.0179\n",
            "     25        \u001b[36m0.0981\u001b[0m  0.0174\n",
            "     26        \u001b[36m0.0975\u001b[0m  0.0169\n",
            "     27        \u001b[36m0.0968\u001b[0m  0.0173\n",
            "     28        \u001b[36m0.0954\u001b[0m  0.0319\n",
            "     29        0.0977  0.0167\n",
            "     30        \u001b[36m0.0935\u001b[0m  0.0164\n",
            "     31        0.0948  0.0160\n",
            "     32        \u001b[36m0.0935\u001b[0m  0.0165\n",
            "     33        \u001b[36m0.0901\u001b[0m  0.0170\n",
            "     34        0.0912  0.0166\n",
            "     35        \u001b[36m0.0889\u001b[0m  0.0166\n",
            "     36        0.0910  0.0167\n",
            "     37        \u001b[36m0.0874\u001b[0m  0.0192\n",
            "     38        0.0879  0.0161\n",
            "     39        0.0879  0.0165\n",
            "     40        0.0887  0.0169\n",
            "     41        \u001b[36m0.0865\u001b[0m  0.0148\n",
            "     42        \u001b[36m0.0844\u001b[0m  0.0188\n",
            "     43        \u001b[36m0.0837\u001b[0m  0.0167\n",
            "     44        0.0837  0.0164\n",
            "     45        \u001b[36m0.0814\u001b[0m  0.0150\n",
            "     46        0.0825  0.0182\n",
            "     47        0.0821  0.0178\n",
            "     48        0.0829  0.0165\n",
            "     49        \u001b[36m0.0787\u001b[0m  0.0151\n",
            "     50        0.0795  0.0178\n",
            "     51        \u001b[36m0.0775\u001b[0m  0.0162\n",
            "     52        \u001b[36m0.0770\u001b[0m  0.0167\n",
            "     53        \u001b[36m0.0752\u001b[0m  0.0172\n",
            "     54        0.0757  0.0149\n",
            "     55        \u001b[36m0.0720\u001b[0m  0.0178\n",
            "     56        \u001b[36m0.0717\u001b[0m  0.0165\n",
            "     57        \u001b[36m0.0706\u001b[0m  0.0187\n",
            "     58        \u001b[36m0.0686\u001b[0m  0.0149\n",
            "     59        \u001b[36m0.0684\u001b[0m  0.0178\n",
            "     60        0.0687  0.0184\n",
            "     61        \u001b[36m0.0676\u001b[0m  0.0162\n",
            "     62        \u001b[36m0.0647\u001b[0m  0.0174\n",
            "     63        0.0649  0.0167\n",
            "     64        \u001b[36m0.0619\u001b[0m  0.0152\n",
            "     65        \u001b[36m0.0591\u001b[0m  0.0175\n",
            "     66        0.0601  0.0159\n",
            "     67        \u001b[36m0.0581\u001b[0m  0.0180\n",
            "     68        0.0613  0.0166\n",
            "     69        0.0585  0.0166\n",
            "     70        \u001b[36m0.0576\u001b[0m  0.0166\n",
            "     71        0.0589  0.0154\n",
            "     72        \u001b[36m0.0556\u001b[0m  0.0189\n",
            "     73        0.0568  0.0169\n",
            "     74        \u001b[36m0.0521\u001b[0m  0.0170\n",
            "     75        0.0545  0.0167\n",
            "     76        \u001b[36m0.0520\u001b[0m  0.0173\n",
            "     77        0.0523  0.0178\n",
            "     78        \u001b[36m0.0478\u001b[0m  0.0190\n",
            "     79        0.0499  0.0167\n",
            "     80        \u001b[36m0.0477\u001b[0m  0.0168\n",
            "     81        0.0480  0.0165\n",
            "     82        \u001b[36m0.0476\u001b[0m  0.0164\n",
            "     83        \u001b[36m0.0429\u001b[0m  0.0166\n",
            "     84        0.0462  0.0169\n",
            "     85        0.0435  0.0172\n",
            "     86        0.0463  0.0260\n",
            "     87        0.0438  0.0214\n",
            "     88        0.0430  0.0170\n",
            "     89        \u001b[36m0.0426\u001b[0m  0.0153\n",
            "     90        \u001b[36m0.0414\u001b[0m  0.0197\n",
            "     91        0.0441  0.0165\n",
            "     92        \u001b[36m0.0414\u001b[0m  0.0163\n",
            "     93        \u001b[36m0.0402\u001b[0m  0.0168\n",
            "     94        \u001b[36m0.0398\u001b[0m  0.0167\n",
            "     95        \u001b[36m0.0373\u001b[0m  0.0154\n",
            "     96        0.0395  0.0179\n",
            "     97        0.0390  0.0162\n",
            "     98        \u001b[36m0.0368\u001b[0m  0.0161\n",
            "     99        \u001b[36m0.0344\u001b[0m  0.0157\n",
            "    100        0.0394  0.0208\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1817\u001b[0m  0.0373\n",
            "      2        \u001b[36m0.1670\u001b[0m  0.0312\n",
            "      3        \u001b[36m0.1590\u001b[0m  0.0307\n",
            "      4        \u001b[36m0.1488\u001b[0m  0.0305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        0.1489  0.0312\n",
            "      6        \u001b[36m0.1397\u001b[0m  0.0326\n",
            "      7        0.1434  0.0329\n",
            "      8        \u001b[36m0.1365\u001b[0m  0.0306\n",
            "      9        \u001b[36m0.1315\u001b[0m  0.0325\n",
            "     10        \u001b[36m0.1283\u001b[0m  0.0304\n",
            "     11        0.1297  0.0307\n",
            "     12        \u001b[36m0.1212\u001b[0m  0.0304\n",
            "     13        0.1216  0.0307\n",
            "     14        \u001b[36m0.1211\u001b[0m  0.0301\n",
            "     15        \u001b[36m0.1178\u001b[0m  0.0334\n",
            "     16        \u001b[36m0.1120\u001b[0m  0.0306\n",
            "     17        0.1153  0.0320\n",
            "     18        \u001b[36m0.1113\u001b[0m  0.0311\n",
            "     19        \u001b[36m0.1104\u001b[0m  0.0305\n",
            "     20        \u001b[36m0.1084\u001b[0m  0.0302\n",
            "     21        \u001b[36m0.1079\u001b[0m  0.0303\n",
            "     22        \u001b[36m0.1029\u001b[0m  0.0300\n",
            "     23        0.1038  0.0469\n",
            "     24        \u001b[36m0.1008\u001b[0m  0.0303\n",
            "     25        0.1019  0.0336\n",
            "     26        \u001b[36m0.0967\u001b[0m  0.0302\n",
            "     27        0.0986  0.0302\n",
            "     28        \u001b[36m0.0947\u001b[0m  0.0303\n",
            "     29        0.0972  0.0302\n",
            "     30        0.0967  0.0301\n",
            "     31        \u001b[36m0.0914\u001b[0m  0.0312\n",
            "     32        0.0933  0.0304\n",
            "     33        \u001b[36m0.0885\u001b[0m  0.0302\n",
            "     34        \u001b[36m0.0883\u001b[0m  0.0302\n",
            "     35        0.0889  0.0304\n",
            "     36        \u001b[36m0.0881\u001b[0m  0.0350\n",
            "     37        \u001b[36m0.0839\u001b[0m  0.0304\n",
            "     38        \u001b[36m0.0823\u001b[0m  0.0310\n",
            "     39        0.0851  0.0323\n",
            "     40        0.0828  0.0313\n",
            "     41        \u001b[36m0.0783\u001b[0m  0.0311\n",
            "     42        \u001b[36m0.0778\u001b[0m  0.0357\n",
            "     43        0.0787  0.0454\n",
            "     44        0.0800  0.0448\n",
            "     45        \u001b[36m0.0718\u001b[0m  0.0423\n",
            "     46        0.0749  0.0436\n",
            "     47        0.0729  0.0406\n",
            "     48        0.0719  0.0420\n",
            "     49        \u001b[36m0.0710\u001b[0m  0.0408\n",
            "     50        \u001b[36m0.0697\u001b[0m  0.0384\n",
            "     51        \u001b[36m0.0684\u001b[0m  0.0472\n",
            "     52        \u001b[36m0.0673\u001b[0m  0.0601\n",
            "     53        \u001b[36m0.0668\u001b[0m  0.0377\n",
            "     54        \u001b[36m0.0651\u001b[0m  0.0391\n",
            "     55        0.0666  0.0386\n",
            "     56        \u001b[36m0.0642\u001b[0m  0.0392\n",
            "     57        \u001b[36m0.0622\u001b[0m  0.0388\n",
            "     58        0.0651  0.0402\n",
            "     59        \u001b[36m0.0607\u001b[0m  0.0387\n",
            "     60        \u001b[36m0.0597\u001b[0m  0.0402\n",
            "     61        0.0598  0.0400\n",
            "     62        0.0601  0.0391\n",
            "     63        \u001b[36m0.0578\u001b[0m  0.0445\n",
            "     64        \u001b[36m0.0574\u001b[0m  0.0358\n",
            "     65        \u001b[36m0.0559\u001b[0m  0.0369\n",
            "     66        \u001b[36m0.0547\u001b[0m  0.0367\n",
            "     67        \u001b[36m0.0519\u001b[0m  0.0360\n",
            "     68        0.0531  0.0356\n",
            "     69        0.0546  0.0387\n",
            "     70        0.0526  0.0376\n",
            "     71        0.0544  0.0456\n",
            "     72        0.0519  0.0399\n",
            "     73        0.0525  0.0365\n",
            "     74        0.0527  0.0363\n",
            "     75        \u001b[36m0.0519\u001b[0m  0.0365\n",
            "     76        \u001b[36m0.0489\u001b[0m  0.0438\n",
            "     77        \u001b[36m0.0485\u001b[0m  0.0556\n",
            "     78        0.0501  0.0470\n",
            "     79        0.0494  0.0464\n",
            "     80        0.0494  0.0384\n",
            "     81        \u001b[36m0.0480\u001b[0m  0.0409\n",
            "     82        \u001b[36m0.0476\u001b[0m  0.0387\n",
            "     83        \u001b[36m0.0472\u001b[0m  0.0482\n",
            "     84        \u001b[36m0.0448\u001b[0m  0.0465\n",
            "     85        \u001b[36m0.0443\u001b[0m  0.0472\n",
            "     86        0.0451  0.0405\n",
            "     87        0.0458  0.0446\n",
            "     88        \u001b[36m0.0438\u001b[0m  0.0470\n",
            "     89        \u001b[36m0.0434\u001b[0m  0.0502\n",
            "     90        \u001b[36m0.0431\u001b[0m  0.0526\n",
            "     91        \u001b[36m0.0428\u001b[0m  0.0406\n",
            "     92        0.0433  0.0404\n",
            "     93        \u001b[36m0.0427\u001b[0m  0.0372\n",
            "     94        0.0428  0.0308\n",
            "     95        \u001b[36m0.0410\u001b[0m  0.0303\n",
            "     96        \u001b[36m0.0397\u001b[0m  0.0304\n",
            "     97        0.0399  0.0344\n",
            "     98        \u001b[36m0.0394\u001b[0m  0.0303\n",
            "     99        0.0406  0.0314\n",
            "    100        \u001b[36m0.0389\u001b[0m  0.0310\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1592\u001b[0m  0.0500\n",
            "      2        \u001b[36m0.1449\u001b[0m  0.0318\n",
            "      3        \u001b[36m0.1330\u001b[0m  0.0321\n",
            "      4        \u001b[36m0.1217\u001b[0m  0.0327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.1160\u001b[0m  0.0348\n",
            "      6        \u001b[36m0.1106\u001b[0m  0.0343\n",
            "      7        \u001b[36m0.1067\u001b[0m  0.0317\n",
            "      8        \u001b[36m0.1024\u001b[0m  0.0312\n",
            "      9        \u001b[36m0.1001\u001b[0m  0.0312\n",
            "     10        \u001b[36m0.0950\u001b[0m  0.0311\n",
            "     11        0.0963  0.0334\n",
            "     12        \u001b[36m0.0930\u001b[0m  0.0320\n",
            "     13        \u001b[36m0.0897\u001b[0m  0.0330\n",
            "     14        \u001b[36m0.0880\u001b[0m  0.0306\n",
            "     15        0.0881  0.0314\n",
            "     16        \u001b[36m0.0853\u001b[0m  0.0309\n",
            "     17        \u001b[36m0.0845\u001b[0m  0.0310\n",
            "     18        \u001b[36m0.0810\u001b[0m  0.0317\n",
            "     19        \u001b[36m0.0797\u001b[0m  0.0321\n",
            "     20        \u001b[36m0.0765\u001b[0m  0.0322\n",
            "     21        \u001b[36m0.0748\u001b[0m  0.0337\n",
            "     22        \u001b[36m0.0745\u001b[0m  0.0314\n",
            "     23        \u001b[36m0.0735\u001b[0m  0.0322\n",
            "     24        \u001b[36m0.0718\u001b[0m  0.0310\n",
            "     25        \u001b[36m0.0691\u001b[0m  0.0313\n",
            "     26        \u001b[36m0.0670\u001b[0m  0.0308\n",
            "     27        \u001b[36m0.0663\u001b[0m  0.0308\n",
            "     28        \u001b[36m0.0636\u001b[0m  0.0357\n",
            "     29        0.0641  0.0307\n",
            "     30        \u001b[36m0.0624\u001b[0m  0.0314\n",
            "     31        \u001b[36m0.0620\u001b[0m  0.0313\n",
            "     32        \u001b[36m0.0588\u001b[0m  0.0457\n",
            "     33        \u001b[36m0.0583\u001b[0m  0.0310\n",
            "     34        \u001b[36m0.0578\u001b[0m  0.0350\n",
            "     35        0.0580  0.0316\n",
            "     36        \u001b[36m0.0549\u001b[0m  0.0321\n",
            "     37        0.0561  0.0332\n",
            "     38        \u001b[36m0.0544\u001b[0m  0.0310\n",
            "     39        \u001b[36m0.0518\u001b[0m  0.0310\n",
            "     40        \u001b[36m0.0511\u001b[0m  0.0317\n",
            "     41        \u001b[36m0.0490\u001b[0m  0.0332\n",
            "     42        0.0492  0.0319\n",
            "     43        \u001b[36m0.0478\u001b[0m  0.0325\n",
            "     44        0.0482  0.0324\n",
            "     45        \u001b[36m0.0469\u001b[0m  0.0310\n",
            "     46        0.0477  0.0310\n",
            "     47        \u001b[36m0.0460\u001b[0m  0.0315\n",
            "     48        \u001b[36m0.0449\u001b[0m  0.0317\n",
            "     49        \u001b[36m0.0437\u001b[0m  0.0312\n",
            "     50        0.0438  0.0311\n",
            "     51        \u001b[36m0.0431\u001b[0m  0.0350\n",
            "     52        \u001b[36m0.0412\u001b[0m  0.0324\n",
            "     53        0.0416  0.0306\n",
            "     54        0.0417  0.0311\n",
            "     55        \u001b[36m0.0398\u001b[0m  0.0313\n",
            "     56        \u001b[36m0.0386\u001b[0m  0.0313\n",
            "     57        \u001b[36m0.0382\u001b[0m  0.0305\n",
            "     58        \u001b[36m0.0369\u001b[0m  0.0310\n",
            "     59        \u001b[36m0.0369\u001b[0m  0.0308\n",
            "     60        0.0375  0.0383\n",
            "     61        \u001b[36m0.0363\u001b[0m  0.0313\n",
            "     62        \u001b[36m0.0348\u001b[0m  0.0311\n",
            "     63        0.0348  0.0429\n",
            "     64        0.0358  0.0317\n",
            "     65        \u001b[36m0.0338\u001b[0m  0.0314\n",
            "     66        0.0350  0.0313\n",
            "     67        0.0340  0.0382\n",
            "     68        \u001b[36m0.0325\u001b[0m  0.0312\n",
            "     69        \u001b[36m0.0311\u001b[0m  0.0328\n",
            "     70        0.0319  0.0311\n",
            "     71        \u001b[36m0.0310\u001b[0m  0.0325\n",
            "     72        \u001b[36m0.0306\u001b[0m  0.0330\n",
            "     73        \u001b[36m0.0298\u001b[0m  0.0313\n",
            "     74        \u001b[36m0.0296\u001b[0m  0.0311\n",
            "     75        0.0302  0.0310\n",
            "     76        \u001b[36m0.0291\u001b[0m  0.0323\n",
            "     77        0.0293  0.0312\n",
            "     78        \u001b[36m0.0283\u001b[0m  0.0311\n",
            "     79        0.0290  0.0326\n",
            "     80        \u001b[36m0.0268\u001b[0m  0.0313\n",
            "     81        0.0279  0.0314\n",
            "     82        0.0273  0.0333\n",
            "     83        0.0269  0.0314\n",
            "     84        0.0288  0.0374\n",
            "     85        \u001b[36m0.0263\u001b[0m  0.0311\n",
            "     86        0.0267  0.0316\n",
            "     87        \u001b[36m0.0255\u001b[0m  0.0317\n",
            "     88        \u001b[36m0.0244\u001b[0m  0.0312\n",
            "     89        0.0259  0.0313\n",
            "     90        \u001b[36m0.0241\u001b[0m  0.0325\n",
            "     91        0.0245  0.0311\n",
            "     92        0.0250  0.0322\n",
            "     93        \u001b[36m0.0235\u001b[0m  0.0313\n",
            "     94        0.0248  0.0378\n",
            "     95        \u001b[36m0.0230\u001b[0m  0.0378\n",
            "     96        0.0241  0.0312\n",
            "     97        0.0233  0.0311\n",
            "     98        \u001b[36m0.0227\u001b[0m  0.0315\n",
            "     99        0.0233  0.0306\n",
            "    100        0.0228  0.0333\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1716\u001b[0m  0.0181\n",
            "      2        \u001b[36m0.1540\u001b[0m  0.0146\n",
            "      3        \u001b[36m0.1405\u001b[0m  0.0153\n",
            "      4        \u001b[36m0.1273\u001b[0m  0.0148\n",
            "      5        \u001b[36m0.1156\u001b[0m  0.0128\n",
            "      6        \u001b[36m0.1092\u001b[0m  0.0129\n",
            "      7        \u001b[36m0.1038\u001b[0m  0.0168\n",
            "      8        \u001b[36m0.1003\u001b[0m  0.0149\n",
            "      9        \u001b[36m0.0929\u001b[0m  0.0131\n",
            "     10        \u001b[36m0.0897\u001b[0m  0.0136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0894\u001b[0m  0.0171\n",
            "     12        \u001b[36m0.0851\u001b[0m  0.0137\n",
            "     13        \u001b[36m0.0793\u001b[0m  0.0158\n",
            "     14        \u001b[36m0.0776\u001b[0m  0.0130\n",
            "     15        \u001b[36m0.0755\u001b[0m  0.0145\n",
            "     16        \u001b[36m0.0725\u001b[0m  0.0175\n",
            "     17        0.0737  0.0142\n",
            "     18        \u001b[36m0.0689\u001b[0m  0.0130\n",
            "     19        \u001b[36m0.0679\u001b[0m  0.0129\n",
            "     20        \u001b[36m0.0664\u001b[0m  0.0161\n",
            "     21        \u001b[36m0.0636\u001b[0m  0.0179\n",
            "     22        \u001b[36m0.0633\u001b[0m  0.0152\n",
            "     23        \u001b[36m0.0590\u001b[0m  0.0157\n",
            "     24        \u001b[36m0.0579\u001b[0m  0.0140\n",
            "     25        \u001b[36m0.0556\u001b[0m  0.0144\n",
            "     26        \u001b[36m0.0539\u001b[0m  0.0129\n",
            "     27        0.0552  0.0152\n",
            "     28        \u001b[36m0.0496\u001b[0m  0.0164\n",
            "     29        \u001b[36m0.0485\u001b[0m  0.0166\n",
            "     30        0.0487  0.0164\n",
            "     31        0.0495  0.0131\n",
            "     32        0.0487  0.0138\n",
            "     33        \u001b[36m0.0469\u001b[0m  0.0149\n",
            "     34        \u001b[36m0.0441\u001b[0m  0.0148\n",
            "     35        \u001b[36m0.0435\u001b[0m  0.0146\n",
            "     36        \u001b[36m0.0409\u001b[0m  0.0131\n",
            "     37        0.0423  0.0136\n",
            "     38        \u001b[36m0.0401\u001b[0m  0.0169\n",
            "     39        0.0403  0.0151\n",
            "     40        \u001b[36m0.0391\u001b[0m  0.0140\n",
            "     41        \u001b[36m0.0358\u001b[0m  0.0145\n",
            "     42        \u001b[36m0.0357\u001b[0m  0.0147\n",
            "     43        \u001b[36m0.0349\u001b[0m  0.0131\n",
            "     44        0.0357  0.0136\n",
            "     45        \u001b[36m0.0339\u001b[0m  0.0166\n",
            "     46        \u001b[36m0.0329\u001b[0m  0.0156\n",
            "     47        \u001b[36m0.0310\u001b[0m  0.0147\n",
            "     48        \u001b[36m0.0300\u001b[0m  0.0128\n",
            "     49        0.0305  0.0134\n",
            "     50        \u001b[36m0.0294\u001b[0m  0.0171\n",
            "     51        0.0298  0.0217\n",
            "     52        0.0299  0.0195\n",
            "     53        0.0296  0.0142\n",
            "     54        \u001b[36m0.0265\u001b[0m  0.0127\n",
            "     55        0.0269  0.0127\n",
            "     56        \u001b[36m0.0261\u001b[0m  0.0158\n",
            "     57        0.0266  0.0148\n",
            "     58        \u001b[36m0.0255\u001b[0m  0.0146\n",
            "     59        0.0262  0.0143\n",
            "     60        \u001b[36m0.0232\u001b[0m  0.0158\n",
            "     61        0.0232  0.0142\n",
            "     62        \u001b[36m0.0231\u001b[0m  0.0160\n",
            "     63        \u001b[36m0.0215\u001b[0m  0.0153\n",
            "     64        0.0217  0.0150\n",
            "     65        0.0216  0.0139\n",
            "     66        0.0230  0.0139\n",
            "     67        \u001b[36m0.0205\u001b[0m  0.0169\n",
            "     68        \u001b[36m0.0199\u001b[0m  0.0141\n",
            "     69        0.0205  0.0156\n",
            "     70        0.0199  0.0130\n",
            "     71        \u001b[36m0.0190\u001b[0m  0.0138\n",
            "     72        \u001b[36m0.0180\u001b[0m  0.0151\n",
            "     73        0.0192  0.0148\n",
            "     74        0.0188  0.0130\n",
            "     75        0.0187  0.0140\n",
            "     76        \u001b[36m0.0177\u001b[0m  0.0149\n",
            "     77        \u001b[36m0.0168\u001b[0m  0.0162\n",
            "     78        0.0178  0.0181\n",
            "     79        0.0175  0.0130\n",
            "     80        \u001b[36m0.0167\u001b[0m  0.0163\n",
            "     81        0.0184  0.0140\n",
            "     82        \u001b[36m0.0162\u001b[0m  0.0141\n",
            "     83        0.0183  0.0141\n",
            "     84        0.0165  0.0141\n",
            "     85        \u001b[36m0.0158\u001b[0m  0.0154\n",
            "     86        0.0163  0.0181\n",
            "     87        \u001b[36m0.0156\u001b[0m  0.0142\n",
            "     88        0.0157  0.0146\n",
            "     89        \u001b[36m0.0154\u001b[0m  0.0148\n",
            "     90        \u001b[36m0.0146\u001b[0m  0.0152\n",
            "     91        0.0159  0.0148\n",
            "     92        0.0153  0.0156\n",
            "     93        \u001b[36m0.0132\u001b[0m  0.0161\n",
            "     94        0.0141  0.0181\n",
            "     95        0.0147  0.0175\n",
            "     96        0.0143  0.0145\n",
            "     97        0.0147  0.0130\n",
            "     98        \u001b[36m0.0123\u001b[0m  0.0138\n",
            "     99        0.0126  0.0155\n",
            "    100        0.0130  0.0144\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1719\u001b[0m  0.0309\n",
            "      2        \u001b[36m0.1441\u001b[0m  0.0293\n",
            "      3        \u001b[36m0.1307\u001b[0m  0.0272\n",
            "      4        \u001b[36m0.1261\u001b[0m  0.0280\n",
            "      5        \u001b[36m0.1170\u001b[0m  0.0300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.1101\u001b[0m  0.0295\n",
            "      7        \u001b[36m0.1032\u001b[0m  0.0270\n",
            "      8        \u001b[36m0.1022\u001b[0m  0.0412\n",
            "      9        \u001b[36m0.0969\u001b[0m  0.0268\n",
            "     10        \u001b[36m0.0935\u001b[0m  0.0266\n",
            "     11        \u001b[36m0.0903\u001b[0m  0.0265\n",
            "     12        0.0906  0.0283\n",
            "     13        \u001b[36m0.0868\u001b[0m  0.0280\n",
            "     14        \u001b[36m0.0823\u001b[0m  0.0285\n",
            "     15        \u001b[36m0.0810\u001b[0m  0.0303\n",
            "     16        \u001b[36m0.0778\u001b[0m  0.0263\n",
            "     17        \u001b[36m0.0772\u001b[0m  0.0268\n",
            "     18        \u001b[36m0.0751\u001b[0m  0.0264\n",
            "     19        \u001b[36m0.0730\u001b[0m  0.0267\n",
            "     20        \u001b[36m0.0719\u001b[0m  0.0269\n",
            "     21        \u001b[36m0.0704\u001b[0m  0.0267\n",
            "     22        \u001b[36m0.0686\u001b[0m  0.0273\n",
            "     23        \u001b[36m0.0685\u001b[0m  0.0293\n",
            "     24        \u001b[36m0.0660\u001b[0m  0.0269\n",
            "     25        \u001b[36m0.0647\u001b[0m  0.0269\n",
            "     26        \u001b[36m0.0623\u001b[0m  0.0288\n",
            "     27        \u001b[36m0.0607\u001b[0m  0.0269\n",
            "     28        \u001b[36m0.0601\u001b[0m  0.0265\n",
            "     29        \u001b[36m0.0574\u001b[0m  0.0267\n",
            "     30        \u001b[36m0.0554\u001b[0m  0.0276\n",
            "     31        \u001b[36m0.0538\u001b[0m  0.0272\n",
            "     32        \u001b[36m0.0536\u001b[0m  0.0322\n",
            "     33        \u001b[36m0.0517\u001b[0m  0.0266\n",
            "     34        \u001b[36m0.0505\u001b[0m  0.0267\n",
            "     35        \u001b[36m0.0498\u001b[0m  0.0269\n",
            "     36        \u001b[36m0.0467\u001b[0m  0.0267\n",
            "     37        0.0468  0.0264\n",
            "     38        \u001b[36m0.0439\u001b[0m  0.0265\n",
            "     39        \u001b[36m0.0439\u001b[0m  0.0272\n",
            "     40        \u001b[36m0.0432\u001b[0m  0.0281\n",
            "     41        \u001b[36m0.0404\u001b[0m  0.0275\n",
            "     42        0.0432  0.0270\n",
            "     43        \u001b[36m0.0404\u001b[0m  0.0268\n",
            "     44        \u001b[36m0.0398\u001b[0m  0.0408\n",
            "     45        \u001b[36m0.0385\u001b[0m  0.0264\n",
            "     46        \u001b[36m0.0366\u001b[0m  0.0276\n",
            "     47        0.0366  0.0268\n",
            "     48        \u001b[36m0.0358\u001b[0m  0.0280\n",
            "     49        0.0359  0.0279\n",
            "     50        \u001b[36m0.0339\u001b[0m  0.0284\n",
            "     51        \u001b[36m0.0337\u001b[0m  0.0265\n",
            "     52        \u001b[36m0.0333\u001b[0m  0.0264\n",
            "     53        \u001b[36m0.0318\u001b[0m  0.0263\n",
            "     54        \u001b[36m0.0312\u001b[0m  0.0264\n",
            "     55        \u001b[36m0.0295\u001b[0m  0.0288\n",
            "     56        0.0315  0.0264\n",
            "     57        \u001b[36m0.0292\u001b[0m  0.0265\n",
            "     58        \u001b[36m0.0289\u001b[0m  0.0265\n",
            "     59        \u001b[36m0.0286\u001b[0m  0.0269\n",
            "     60        0.0288  0.0283\n",
            "     61        \u001b[36m0.0285\u001b[0m  0.0283\n",
            "     62        \u001b[36m0.0281\u001b[0m  0.0259\n",
            "     63        \u001b[36m0.0251\u001b[0m  0.0265\n",
            "     64        0.0266  0.0264\n",
            "     65        \u001b[36m0.0249\u001b[0m  0.0280\n",
            "     66        \u001b[36m0.0241\u001b[0m  0.0265\n",
            "     67        0.0254  0.0266\n",
            "     68        0.0243  0.0263\n",
            "     69        0.0242  0.0267\n",
            "     70        0.0242  0.0311\n",
            "     71        \u001b[36m0.0235\u001b[0m  0.0262\n",
            "     72        \u001b[36m0.0234\u001b[0m  0.0266\n",
            "     73        0.0237  0.0276\n",
            "     74        \u001b[36m0.0226\u001b[0m  0.0266\n",
            "     75        \u001b[36m0.0221\u001b[0m  0.0265\n",
            "     76        0.0222  0.0264\n",
            "     77        \u001b[36m0.0210\u001b[0m  0.0266\n",
            "     78        \u001b[36m0.0199\u001b[0m  0.0277\n",
            "     79        0.0203  0.0273\n",
            "     80        0.0219  0.0321\n",
            "     81        \u001b[36m0.0195\u001b[0m  0.0343\n",
            "     82        0.0201  0.0266\n",
            "     83        \u001b[36m0.0194\u001b[0m  0.0266\n",
            "     84        0.0196  0.0276\n",
            "     85        \u001b[36m0.0182\u001b[0m  0.0288\n",
            "     86        0.0186  0.0264\n",
            "     87        \u001b[36m0.0177\u001b[0m  0.0268\n",
            "     88        0.0180  0.0271\n",
            "     89        0.0191  0.0263\n",
            "     90        0.0186  0.0298\n",
            "     91        0.0180  0.0283\n",
            "     92        \u001b[36m0.0166\u001b[0m  0.0269\n",
            "     93        0.0173  0.0291\n",
            "     94        0.0172  0.0279\n",
            "     95        0.0166  0.0276\n",
            "     96        0.0166  0.0351\n",
            "     97        0.0168  0.0265\n",
            "     98        \u001b[36m0.0161\u001b[0m  0.0271\n",
            "     99        \u001b[36m0.0159\u001b[0m  0.0263\n",
            "    100        \u001b[36m0.0152\u001b[0m  0.0275\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1534\u001b[0m  0.0298\n",
            "      2        \u001b[36m0.1298\u001b[0m  0.0281\n",
            "      3        \u001b[36m0.1123\u001b[0m  0.0274\n",
            "      4        \u001b[36m0.1015\u001b[0m  0.0291\n",
            "      5        \u001b[36m0.0956\u001b[0m  0.0329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0903\u001b[0m  0.0306\n",
            "      7        \u001b[36m0.0873\u001b[0m  0.0276\n",
            "      8        \u001b[36m0.0842\u001b[0m  0.0293\n",
            "      9        \u001b[36m0.0813\u001b[0m  0.0281\n",
            "     10        \u001b[36m0.0786\u001b[0m  0.0279\n",
            "     11        \u001b[36m0.0757\u001b[0m  0.0279\n",
            "     12        \u001b[36m0.0722\u001b[0m  0.0276\n",
            "     13        \u001b[36m0.0701\u001b[0m  0.0276\n",
            "     14        \u001b[36m0.0693\u001b[0m  0.0289\n",
            "     15        \u001b[36m0.0637\u001b[0m  0.0380\n",
            "     16        \u001b[36m0.0615\u001b[0m  0.0277\n",
            "     17        \u001b[36m0.0600\u001b[0m  0.0294\n",
            "     18        \u001b[36m0.0578\u001b[0m  0.0293\n",
            "     19        \u001b[36m0.0549\u001b[0m  0.0277\n",
            "     20        \u001b[36m0.0527\u001b[0m  0.0271\n",
            "     21        \u001b[36m0.0504\u001b[0m  0.0271\n",
            "     22        \u001b[36m0.0502\u001b[0m  0.0270\n",
            "     23        \u001b[36m0.0462\u001b[0m  0.0283\n",
            "     24        \u001b[36m0.0458\u001b[0m  0.0269\n",
            "     25        \u001b[36m0.0453\u001b[0m  0.0272\n",
            "     26        \u001b[36m0.0424\u001b[0m  0.0290\n",
            "     27        0.0427  0.0271\n",
            "     28        \u001b[36m0.0402\u001b[0m  0.0287\n",
            "     29        \u001b[36m0.0381\u001b[0m  0.0296\n",
            "     30        \u001b[36m0.0375\u001b[0m  0.0277\n",
            "     31        \u001b[36m0.0361\u001b[0m  0.0272\n",
            "     32        \u001b[36m0.0340\u001b[0m  0.0343\n",
            "     33        \u001b[36m0.0332\u001b[0m  0.0272\n",
            "     34        0.0334  0.0267\n",
            "     35        \u001b[36m0.0323\u001b[0m  0.0281\n",
            "     36        \u001b[36m0.0310\u001b[0m  0.0274\n",
            "     37        \u001b[36m0.0298\u001b[0m  0.0267\n",
            "     38        \u001b[36m0.0286\u001b[0m  0.0269\n",
            "     39        \u001b[36m0.0278\u001b[0m  0.0268\n",
            "     40        \u001b[36m0.0270\u001b[0m  0.0270\n",
            "     41        \u001b[36m0.0268\u001b[0m  0.0281\n",
            "     42        \u001b[36m0.0262\u001b[0m  0.0268\n",
            "     43        \u001b[36m0.0251\u001b[0m  0.0272\n",
            "     44        \u001b[36m0.0248\u001b[0m  0.0295\n",
            "     45        \u001b[36m0.0242\u001b[0m  0.0273\n",
            "     46        \u001b[36m0.0236\u001b[0m  0.0268\n",
            "     47        \u001b[36m0.0222\u001b[0m  0.0269\n",
            "     48        \u001b[36m0.0221\u001b[0m  0.0271\n",
            "     49        \u001b[36m0.0215\u001b[0m  0.0268\n",
            "     50        \u001b[36m0.0204\u001b[0m  0.0341\n",
            "     51        \u001b[36m0.0197\u001b[0m  0.0347\n",
            "     52        0.0204  0.0283\n",
            "     53        \u001b[36m0.0189\u001b[0m  0.0278\n",
            "     54        \u001b[36m0.0184\u001b[0m  0.0272\n",
            "     55        \u001b[36m0.0180\u001b[0m  0.0298\n",
            "     56        \u001b[36m0.0172\u001b[0m  0.0271\n",
            "     57        0.0173  0.0272\n",
            "     58        \u001b[36m0.0161\u001b[0m  0.0270\n",
            "     59        0.0168  0.0279\n",
            "     60        \u001b[36m0.0159\u001b[0m  0.0273\n",
            "     61        \u001b[36m0.0157\u001b[0m  0.0273\n",
            "     62        \u001b[36m0.0155\u001b[0m  0.0273\n",
            "     63        0.0155  0.0278\n",
            "     64        \u001b[36m0.0145\u001b[0m  0.0295\n",
            "     65        \u001b[36m0.0142\u001b[0m  0.0422\n",
            "     66        \u001b[36m0.0141\u001b[0m  0.0397\n",
            "     67        0.0146  0.0467\n",
            "     68        \u001b[36m0.0139\u001b[0m  0.0372\n",
            "     69        \u001b[36m0.0139\u001b[0m  0.0358\n",
            "     70        \u001b[36m0.0132\u001b[0m  0.0319\n",
            "     71        \u001b[36m0.0128\u001b[0m  0.0362\n",
            "     72        \u001b[36m0.0128\u001b[0m  0.0328\n",
            "     73        \u001b[36m0.0125\u001b[0m  0.0351\n",
            "     74        0.0125  0.0450\n",
            "     75        0.0126  0.0347\n",
            "     76        \u001b[36m0.0113\u001b[0m  0.0350\n",
            "     77        0.0118  0.0336\n",
            "     78        0.0114  0.0334\n",
            "     79        \u001b[36m0.0112\u001b[0m  0.0335\n",
            "     80        0.0120  0.0345\n",
            "     81        \u001b[36m0.0109\u001b[0m  0.0408\n",
            "     82        0.0126  0.0376\n",
            "     83        \u001b[36m0.0105\u001b[0m  0.0357\n",
            "     84        0.0115  0.0337\n",
            "     85        0.0108  0.0338\n",
            "     86        0.0110  0.0334\n",
            "     87        \u001b[36m0.0103\u001b[0m  0.0336\n",
            "     88        \u001b[36m0.0103\u001b[0m  0.0340\n",
            "     89        0.0108  0.0333\n",
            "     90        \u001b[36m0.0101\u001b[0m  0.0362\n",
            "     91        0.0106  0.0372\n",
            "     92        \u001b[36m0.0099\u001b[0m  0.0327\n",
            "     93        0.0102  0.0334\n",
            "     94        \u001b[36m0.0097\u001b[0m  0.0319\n",
            "     95        0.0099  0.0320\n",
            "     96        \u001b[36m0.0094\u001b[0m  0.0372\n",
            "     97        \u001b[36m0.0088\u001b[0m  0.0318\n",
            "     98        0.0102  0.0320\n",
            "     99        0.0090  0.0329\n",
            "    100        0.0095  0.0319\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1625\u001b[0m  0.0429\n",
            "      2        \u001b[36m0.1386\u001b[0m  0.0225\n",
            "      3        \u001b[36m0.1219\u001b[0m  0.0226\n",
            "      4        \u001b[36m0.1171\u001b[0m  0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.1064\u001b[0m  0.0334\n",
            "      6        \u001b[36m0.1026\u001b[0m  0.0290\n",
            "      7        \u001b[36m0.0991\u001b[0m  0.0336\n",
            "      8        \u001b[36m0.0981\u001b[0m  0.0266\n",
            "      9        \u001b[36m0.0962\u001b[0m  0.0329\n",
            "     10        \u001b[36m0.0944\u001b[0m  0.0342\n",
            "     11        0.0945  0.0300\n",
            "     12        \u001b[36m0.0900\u001b[0m  0.0343\n",
            "     13        \u001b[36m0.0886\u001b[0m  0.0278\n",
            "     14        \u001b[36m0.0878\u001b[0m  0.0232\n",
            "     15        \u001b[36m0.0868\u001b[0m  0.0234\n",
            "     16        \u001b[36m0.0861\u001b[0m  0.0278\n",
            "     17        \u001b[36m0.0837\u001b[0m  0.0260\n",
            "     18        \u001b[36m0.0823\u001b[0m  0.0307\n",
            "     19        \u001b[36m0.0805\u001b[0m  0.0295\n",
            "     20        \u001b[36m0.0767\u001b[0m  0.0333\n",
            "     21        \u001b[36m0.0746\u001b[0m  0.0310\n",
            "     22        \u001b[36m0.0739\u001b[0m  0.0252\n",
            "     23        \u001b[36m0.0714\u001b[0m  0.0278\n",
            "     24        0.0714  0.0256\n",
            "     25        \u001b[36m0.0698\u001b[0m  0.0285\n",
            "     26        \u001b[36m0.0658\u001b[0m  0.0284\n",
            "     27        0.0666  0.0335\n",
            "     28        \u001b[36m0.0627\u001b[0m  0.0332\n",
            "     29        \u001b[36m0.0611\u001b[0m  0.0306\n",
            "     30        0.0622  0.0283\n",
            "     31        \u001b[36m0.0583\u001b[0m  0.0231\n",
            "     32        \u001b[36m0.0581\u001b[0m  0.0265\n",
            "     33        \u001b[36m0.0566\u001b[0m  0.0231\n",
            "     34        \u001b[36m0.0542\u001b[0m  0.0269\n",
            "     35        \u001b[36m0.0537\u001b[0m  0.0192\n",
            "     36        \u001b[36m0.0510\u001b[0m  0.0191\n",
            "     37        \u001b[36m0.0505\u001b[0m  0.0197\n",
            "     38        \u001b[36m0.0486\u001b[0m  0.0213\n",
            "     39        \u001b[36m0.0459\u001b[0m  0.0199\n",
            "     40        0.0470  0.0200\n",
            "     41        \u001b[36m0.0442\u001b[0m  0.0199\n",
            "     42        \u001b[36m0.0413\u001b[0m  0.0216\n",
            "     43        \u001b[36m0.0409\u001b[0m  0.0213\n",
            "     44        0.0409  0.0194\n",
            "     45        \u001b[36m0.0394\u001b[0m  0.0209\n",
            "     46        \u001b[36m0.0382\u001b[0m  0.0196\n",
            "     47        \u001b[36m0.0371\u001b[0m  0.0196\n",
            "     48        \u001b[36m0.0357\u001b[0m  0.0209\n",
            "     49        \u001b[36m0.0338\u001b[0m  0.0202\n",
            "     50        \u001b[36m0.0335\u001b[0m  0.0212\n",
            "     51        \u001b[36m0.0314\u001b[0m  0.0201\n",
            "     52        \u001b[36m0.0310\u001b[0m  0.0349\n",
            "     53        \u001b[36m0.0296\u001b[0m  0.0198\n",
            "     54        0.0302  0.0275\n",
            "     55        \u001b[36m0.0293\u001b[0m  0.0264\n",
            "     56        \u001b[36m0.0285\u001b[0m  0.0227\n",
            "     57        \u001b[36m0.0265\u001b[0m  0.0237\n",
            "     58        \u001b[36m0.0254\u001b[0m  0.0202\n",
            "     59        \u001b[36m0.0252\u001b[0m  0.0203\n",
            "     60        \u001b[36m0.0244\u001b[0m  0.0224\n",
            "     61        0.0245  0.0197\n",
            "     62        \u001b[36m0.0241\u001b[0m  0.0197\n",
            "     63        \u001b[36m0.0213\u001b[0m  0.0195\n",
            "     64        0.0221  0.0195\n",
            "     65        \u001b[36m0.0212\u001b[0m  0.0197\n",
            "     66        0.0215  0.0210\n",
            "     67        0.0212  0.0199\n",
            "     68        \u001b[36m0.0198\u001b[0m  0.0193\n",
            "     69        \u001b[36m0.0175\u001b[0m  0.0180\n",
            "     70        0.0190  0.0206\n",
            "     71        0.0203  0.0192\n",
            "     72        0.0185  0.0229\n",
            "     73        0.0187  0.0198\n",
            "     74        0.0177  0.0192\n",
            "     75        \u001b[36m0.0171\u001b[0m  0.0194\n",
            "     76        \u001b[36m0.0167\u001b[0m  0.0206\n",
            "     77        \u001b[36m0.0158\u001b[0m  0.0195\n",
            "     78        0.0171  0.0194\n",
            "     79        \u001b[36m0.0154\u001b[0m  0.0196\n",
            "     80        0.0155  0.0197\n",
            "     81        \u001b[36m0.0151\u001b[0m  0.0199\n",
            "     82        \u001b[36m0.0135\u001b[0m  0.0196\n",
            "     83        0.0139  0.0198\n",
            "     84        0.0146  0.0213\n",
            "     85        0.0145  0.0207\n",
            "     86        \u001b[36m0.0132\u001b[0m  0.0178\n",
            "     87        0.0140  0.0218\n",
            "     88        0.0140  0.0198\n",
            "     89        0.0144  0.0204\n",
            "     90        \u001b[36m0.0126\u001b[0m  0.0179\n",
            "     91        \u001b[36m0.0117\u001b[0m  0.0226\n",
            "     92        0.0125  0.0191\n",
            "     93        0.0128  0.0205\n",
            "     94        \u001b[36m0.0116\u001b[0m  0.0202\n",
            "     95        \u001b[36m0.0103\u001b[0m  0.0180\n",
            "     96        0.0138  0.0220\n",
            "     97        0.0117  0.0213\n",
            "     98        0.0108  0.0195\n",
            "     99        0.0124  0.0178\n",
            "    100        0.0117  0.0359\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1608\u001b[0m  0.0584\n",
            "      2        \u001b[36m0.1359\u001b[0m  0.0388\n",
            "      3        \u001b[36m0.1265\u001b[0m  0.0416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.1177\u001b[0m  0.0372\n",
            "      5        \u001b[36m0.1158\u001b[0m  0.0391\n",
            "      6        \u001b[36m0.1112\u001b[0m  0.0366\n",
            "      7        \u001b[36m0.1071\u001b[0m  0.0365\n",
            "      8        \u001b[36m0.1048\u001b[0m  0.0366\n",
            "      9        \u001b[36m0.1034\u001b[0m  0.0397\n",
            "     10        \u001b[36m0.1011\u001b[0m  0.0372\n",
            "     11        \u001b[36m0.1003\u001b[0m  0.0363\n",
            "     12        \u001b[36m0.0977\u001b[0m  0.0362\n",
            "     13        \u001b[36m0.0965\u001b[0m  0.0364\n",
            "     14        \u001b[36m0.0952\u001b[0m  0.0392\n",
            "     15        \u001b[36m0.0934\u001b[0m  0.0364\n",
            "     16        \u001b[36m0.0921\u001b[0m  0.0361\n",
            "     17        \u001b[36m0.0889\u001b[0m  0.0375\n",
            "     18        \u001b[36m0.0866\u001b[0m  0.0375\n",
            "     19        \u001b[36m0.0833\u001b[0m  0.0385\n",
            "     20        \u001b[36m0.0809\u001b[0m  0.0362\n",
            "     21        0.0842  0.0375\n",
            "     22        0.0822  0.0369\n",
            "     23        \u001b[36m0.0756\u001b[0m  0.0395\n",
            "     24        0.0775  0.0385\n",
            "     25        0.0757  0.0458\n",
            "     26        \u001b[36m0.0734\u001b[0m  0.0384\n",
            "     27        \u001b[36m0.0732\u001b[0m  0.0370\n",
            "     28        \u001b[36m0.0711\u001b[0m  0.0386\n",
            "     29        \u001b[36m0.0695\u001b[0m  0.0366\n",
            "     30        \u001b[36m0.0684\u001b[0m  0.0360\n",
            "     31        \u001b[36m0.0678\u001b[0m  0.0414\n",
            "     32        \u001b[36m0.0657\u001b[0m  0.0372\n",
            "     33        \u001b[36m0.0632\u001b[0m  0.0367\n",
            "     34        \u001b[36m0.0627\u001b[0m  0.0365\n",
            "     35        \u001b[36m0.0612\u001b[0m  0.0364\n",
            "     36        \u001b[36m0.0586\u001b[0m  0.0369\n",
            "     37        \u001b[36m0.0567\u001b[0m  0.0362\n",
            "     38        0.0587  0.0398\n",
            "     39        \u001b[36m0.0552\u001b[0m  0.0410\n",
            "     40        \u001b[36m0.0543\u001b[0m  0.0365\n",
            "     41        \u001b[36m0.0539\u001b[0m  0.0377\n",
            "     42        0.0542  0.0368\n",
            "     43        \u001b[36m0.0518\u001b[0m  0.0361\n",
            "     44        0.0523  0.0377\n",
            "     45        \u001b[36m0.0506\u001b[0m  0.0396\n",
            "     46        \u001b[36m0.0498\u001b[0m  0.0364\n",
            "     47        \u001b[36m0.0485\u001b[0m  0.0378\n",
            "     48        \u001b[36m0.0478\u001b[0m  0.0373\n",
            "     49        \u001b[36m0.0465\u001b[0m  0.0373\n",
            "     50        \u001b[36m0.0445\u001b[0m  0.0372\n",
            "     51        0.0446  0.0513\n",
            "     52        \u001b[36m0.0443\u001b[0m  0.0383\n",
            "     53        0.0444  0.0364\n",
            "     54        \u001b[36m0.0441\u001b[0m  0.0386\n",
            "     55        \u001b[36m0.0418\u001b[0m  0.0381\n",
            "     56        \u001b[36m0.0413\u001b[0m  0.0363\n",
            "     57        \u001b[36m0.0390\u001b[0m  0.0365\n",
            "     58        \u001b[36m0.0387\u001b[0m  0.0362\n",
            "     59        \u001b[36m0.0384\u001b[0m  0.0408\n",
            "     60        \u001b[36m0.0372\u001b[0m  0.0365\n",
            "     61        \u001b[36m0.0362\u001b[0m  0.0366\n",
            "     62        0.0370  0.0363\n",
            "     63        \u001b[36m0.0336\u001b[0m  0.0374\n",
            "     64        0.0346  0.0365\n",
            "     65        0.0348  0.0367\n",
            "     66        0.0345  0.0371\n",
            "     67        \u001b[36m0.0320\u001b[0m  0.0365\n",
            "     68        \u001b[36m0.0319\u001b[0m  0.0390\n",
            "     69        \u001b[36m0.0306\u001b[0m  0.0361\n",
            "     70        0.0309  0.0374\n",
            "     71        \u001b[36m0.0301\u001b[0m  0.0383\n",
            "     72        \u001b[36m0.0288\u001b[0m  0.0377\n",
            "     73        \u001b[36m0.0270\u001b[0m  0.0373\n",
            "     74        0.0280  0.0369\n",
            "     75        \u001b[36m0.0269\u001b[0m  0.0369\n",
            "     76        \u001b[36m0.0261\u001b[0m  0.0375\n",
            "     77        0.0268  0.0405\n",
            "     78        \u001b[36m0.0244\u001b[0m  0.0511\n",
            "     79        \u001b[36m0.0244\u001b[0m  0.0367\n",
            "     80        \u001b[36m0.0239\u001b[0m  0.0396\n",
            "     81        0.0240  0.0363\n",
            "     82        \u001b[36m0.0238\u001b[0m  0.0395\n",
            "     83        \u001b[36m0.0232\u001b[0m  0.0367\n",
            "     84        0.0235  0.0365\n",
            "     85        \u001b[36m0.0229\u001b[0m  0.0367\n",
            "     86        \u001b[36m0.0228\u001b[0m  0.0367\n",
            "     87        \u001b[36m0.0222\u001b[0m  0.0412\n",
            "     88        \u001b[36m0.0214\u001b[0m  0.0356\n",
            "     89        \u001b[36m0.0211\u001b[0m  0.0366\n",
            "     90        \u001b[36m0.0207\u001b[0m  0.0362\n",
            "     91        \u001b[36m0.0199\u001b[0m  0.0376\n",
            "     92        0.0204  0.0367\n",
            "     93        \u001b[36m0.0192\u001b[0m  0.0364\n",
            "     94        0.0197  0.0370\n",
            "     95        0.0198  0.0386\n",
            "     96        0.0194  0.0358\n",
            "     97        \u001b[36m0.0181\u001b[0m  0.0377\n",
            "     98        \u001b[36m0.0180\u001b[0m  0.0366\n",
            "     99        0.0185  0.0376\n",
            "    100        0.0182  0.0363\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1520\u001b[0m  0.0531\n",
            "      2        \u001b[36m0.1231\u001b[0m  0.0422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.1099\u001b[0m  0.0451\n",
            "      4        \u001b[36m0.1028\u001b[0m  0.0387\n",
            "      5        \u001b[36m0.1007\u001b[0m  0.0420\n",
            "      6        \u001b[36m0.0991\u001b[0m  0.0373\n",
            "      7        \u001b[36m0.0965\u001b[0m  0.0371\n",
            "      8        \u001b[36m0.0952\u001b[0m  0.0368\n",
            "      9        \u001b[36m0.0921\u001b[0m  0.0374\n",
            "     10        \u001b[36m0.0880\u001b[0m  0.0389\n",
            "     11        0.0881  0.0374\n",
            "     12        \u001b[36m0.0854\u001b[0m  0.0379\n",
            "     13        \u001b[36m0.0831\u001b[0m  0.0368\n",
            "     14        \u001b[36m0.0800\u001b[0m  0.0369\n",
            "     15        \u001b[36m0.0793\u001b[0m  0.0373\n",
            "     16        \u001b[36m0.0783\u001b[0m  0.0377\n",
            "     17        \u001b[36m0.0755\u001b[0m  0.0372\n",
            "     18        \u001b[36m0.0743\u001b[0m  0.0370\n",
            "     19        \u001b[36m0.0718\u001b[0m  0.0383\n",
            "     20        \u001b[36m0.0688\u001b[0m  0.0413\n",
            "     21        \u001b[36m0.0668\u001b[0m  0.0369\n",
            "     22        \u001b[36m0.0646\u001b[0m  0.0367\n",
            "     23        \u001b[36m0.0634\u001b[0m  0.0379\n",
            "     24        \u001b[36m0.0633\u001b[0m  0.0369\n",
            "     25        \u001b[36m0.0597\u001b[0m  0.0375\n",
            "     26        \u001b[36m0.0595\u001b[0m  0.0383\n",
            "     27        \u001b[36m0.0584\u001b[0m  0.0367\n",
            "     28        \u001b[36m0.0566\u001b[0m  0.0375\n",
            "     29        \u001b[36m0.0537\u001b[0m  0.0512\n",
            "     30        \u001b[36m0.0532\u001b[0m  0.0387\n",
            "     31        \u001b[36m0.0528\u001b[0m  0.0375\n",
            "     32        \u001b[36m0.0497\u001b[0m  0.0371\n",
            "     33        \u001b[36m0.0495\u001b[0m  0.0415\n",
            "     34        \u001b[36m0.0475\u001b[0m  0.0369\n",
            "     35        \u001b[36m0.0469\u001b[0m  0.0369\n",
            "     36        \u001b[36m0.0432\u001b[0m  0.0372\n",
            "     37        \u001b[36m0.0431\u001b[0m  0.0375\n",
            "     38        \u001b[36m0.0415\u001b[0m  0.0396\n",
            "     39        \u001b[36m0.0408\u001b[0m  0.0371\n",
            "     40        \u001b[36m0.0374\u001b[0m  0.0383\n",
            "     41        0.0382  0.0376\n",
            "     42        \u001b[36m0.0363\u001b[0m  0.0373\n",
            "     43        0.0370  0.0371\n",
            "     44        \u001b[36m0.0332\u001b[0m  0.0374\n",
            "     45        \u001b[36m0.0325\u001b[0m  0.0403\n",
            "     46        0.0337  0.0391\n",
            "     47        \u001b[36m0.0311\u001b[0m  0.0377\n",
            "     48        \u001b[36m0.0298\u001b[0m  0.0372\n",
            "     49        \u001b[36m0.0291\u001b[0m  0.0387\n",
            "     50        \u001b[36m0.0282\u001b[0m  0.0373\n",
            "     51        \u001b[36m0.0270\u001b[0m  0.0375\n",
            "     52        \u001b[36m0.0267\u001b[0m  0.0380\n",
            "     53        \u001b[36m0.0262\u001b[0m  0.0375\n",
            "     54        \u001b[36m0.0257\u001b[0m  0.0413\n",
            "     55        \u001b[36m0.0242\u001b[0m  0.0532\n",
            "     56        \u001b[36m0.0234\u001b[0m  0.0372\n",
            "     57        \u001b[36m0.0232\u001b[0m  0.0372\n",
            "     58        \u001b[36m0.0210\u001b[0m  0.0373\n",
            "     59        \u001b[36m0.0206\u001b[0m  0.0373\n",
            "     60        \u001b[36m0.0205\u001b[0m  0.0417\n",
            "     61        0.0206  0.0372\n",
            "     62        \u001b[36m0.0205\u001b[0m  0.0372\n",
            "     63        \u001b[36m0.0195\u001b[0m  0.0386\n",
            "     64        \u001b[36m0.0193\u001b[0m  0.0375\n",
            "     65        \u001b[36m0.0182\u001b[0m  0.0371\n",
            "     66        \u001b[36m0.0181\u001b[0m  0.0375\n",
            "     67        \u001b[36m0.0179\u001b[0m  0.0367\n",
            "     68        \u001b[36m0.0168\u001b[0m  0.0407\n",
            "     69        0.0172  0.0372\n",
            "     70        \u001b[36m0.0167\u001b[0m  0.0387\n",
            "     71        \u001b[36m0.0159\u001b[0m  0.0395\n",
            "     72        \u001b[36m0.0150\u001b[0m  0.0369\n",
            "     73        0.0157  0.0372\n",
            "     74        0.0162  0.0381\n",
            "     75        \u001b[36m0.0148\u001b[0m  0.0390\n",
            "     76        \u001b[36m0.0146\u001b[0m  0.0393\n",
            "     77        \u001b[36m0.0145\u001b[0m  0.0374\n",
            "     78        \u001b[36m0.0135\u001b[0m  0.0377\n",
            "     79        0.0137  0.0378\n",
            "     80        0.0139  0.0371\n",
            "     81        \u001b[36m0.0130\u001b[0m  0.0527\n",
            "     82        \u001b[36m0.0129\u001b[0m  0.0415\n",
            "     83        \u001b[36m0.0125\u001b[0m  0.0376\n",
            "     84        \u001b[36m0.0120\u001b[0m  0.0372\n",
            "     85        0.0129  0.0386\n",
            "     86        \u001b[36m0.0116\u001b[0m  0.0373\n",
            "     87        0.0119  0.0372\n",
            "     88        0.0125  0.0365\n",
            "     89        0.0123  0.0379\n",
            "     90        \u001b[36m0.0116\u001b[0m  0.0374\n",
            "     91        \u001b[36m0.0114\u001b[0m  0.0375\n",
            "     92        \u001b[36m0.0112\u001b[0m  0.0363\n",
            "     93        \u001b[36m0.0109\u001b[0m  0.0373\n",
            "     94        0.0111  0.0384\n",
            "     95        \u001b[36m0.0108\u001b[0m  0.0379\n",
            "     96        \u001b[36m0.0103\u001b[0m  0.0380\n",
            "     97        0.0112  0.0387\n",
            "     98        0.0109  0.0434\n",
            "     99        \u001b[36m0.0103\u001b[0m  0.0430\n",
            "    100        0.0104  0.0430\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1740\u001b[0m  0.0174\n",
            "      2        \u001b[36m0.1565\u001b[0m  0.0192\n",
            "      3        \u001b[36m0.1514\u001b[0m  0.0164\n",
            "      4        \u001b[36m0.1407\u001b[0m  0.0170\n",
            "      5        \u001b[36m0.1313\u001b[0m  0.0170\n",
            "      6        0.1327  0.0186\n",
            "      7        \u001b[36m0.1235\u001b[0m  0.0161\n",
            "      8        0.1276  0.0166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.1176\u001b[0m  0.0190\n",
            "     10        0.1183  0.0187\n",
            "     11        \u001b[36m0.1164\u001b[0m  0.0163\n",
            "     12        \u001b[36m0.1088\u001b[0m  0.0279\n",
            "     13        \u001b[36m0.1047\u001b[0m  0.0163\n",
            "     14        \u001b[36m0.1043\u001b[0m  0.0153\n",
            "     15        \u001b[36m0.1010\u001b[0m  0.0184\n",
            "     16        0.1110  0.0192\n",
            "     17        \u001b[36m0.0993\u001b[0m  0.0184\n",
            "     18        \u001b[36m0.0979\u001b[0m  0.0168\n",
            "     19        0.1004  0.0167\n",
            "     20        \u001b[36m0.0945\u001b[0m  0.0149\n",
            "     21        \u001b[36m0.0927\u001b[0m  0.0191\n",
            "     22        \u001b[36m0.0912\u001b[0m  0.0167\n",
            "     23        \u001b[36m0.0908\u001b[0m  0.0163\n",
            "     24        \u001b[36m0.0884\u001b[0m  0.0149\n",
            "     25        0.0887  0.0178\n",
            "     26        \u001b[36m0.0872\u001b[0m  0.0164\n",
            "     27        \u001b[36m0.0870\u001b[0m  0.0171\n",
            "     28        \u001b[36m0.0846\u001b[0m  0.0170\n",
            "     29        \u001b[36m0.0840\u001b[0m  0.0147\n",
            "     30        \u001b[36m0.0807\u001b[0m  0.0177\n",
            "     31        0.0810  0.0259\n",
            "     32        0.0811  0.0255\n",
            "     33        \u001b[36m0.0760\u001b[0m  0.0244\n",
            "     34        0.0781  0.0229\n",
            "     35        0.0767  0.0253\n",
            "     36        0.0764  0.0253\n",
            "     37        \u001b[36m0.0730\u001b[0m  0.0201\n",
            "     38        \u001b[36m0.0717\u001b[0m  0.0263\n",
            "     39        \u001b[36m0.0717\u001b[0m  0.0199\n",
            "     40        0.0718  0.0202\n",
            "     41        0.0731  0.0237\n",
            "     42        \u001b[36m0.0698\u001b[0m  0.0226\n",
            "     43        0.0703  0.0192\n",
            "     44        \u001b[36m0.0693\u001b[0m  0.0199\n",
            "     45        0.0708  0.0195\n",
            "     46        \u001b[36m0.0657\u001b[0m  0.0223\n",
            "     47        \u001b[36m0.0651\u001b[0m  0.0200\n",
            "     48        \u001b[36m0.0604\u001b[0m  0.0192\n",
            "     49        0.0643  0.0190\n",
            "     50        0.0617  0.0194\n",
            "     51        0.0628  0.0187\n",
            "     52        0.0607  0.0226\n",
            "     53        \u001b[36m0.0599\u001b[0m  0.0210\n",
            "     54        \u001b[36m0.0565\u001b[0m  0.0193\n",
            "     55        0.0584  0.0188\n",
            "     56        \u001b[36m0.0558\u001b[0m  0.0196\n",
            "     57        0.0559  0.0196\n",
            "     58        \u001b[36m0.0538\u001b[0m  0.0192\n",
            "     59        0.0547  0.0219\n",
            "     60        \u001b[36m0.0524\u001b[0m  0.0194\n",
            "     61        0.0533  0.0222\n",
            "     62        \u001b[36m0.0521\u001b[0m  0.0258\n",
            "     63        \u001b[36m0.0519\u001b[0m  0.0200\n",
            "     64        \u001b[36m0.0517\u001b[0m  0.0206\n",
            "     65        \u001b[36m0.0488\u001b[0m  0.0229\n",
            "     66        \u001b[36m0.0482\u001b[0m  0.0236\n",
            "     67        \u001b[36m0.0456\u001b[0m  0.0200\n",
            "     68        0.0487  0.0194\n",
            "     69        \u001b[36m0.0444\u001b[0m  0.0196\n",
            "     70        0.0454  0.0187\n",
            "     71        0.0466  0.0192\n",
            "     72        0.0458  0.0201\n",
            "     73        \u001b[36m0.0441\u001b[0m  0.0199\n",
            "     74        \u001b[36m0.0428\u001b[0m  0.0189\n",
            "     75        \u001b[36m0.0427\u001b[0m  0.0201\n",
            "     76        0.0439  0.0198\n",
            "     77        \u001b[36m0.0416\u001b[0m  0.0202\n",
            "     78        0.0418  0.0194\n",
            "     79        \u001b[36m0.0403\u001b[0m  0.0195\n",
            "     80        0.0425  0.0194\n",
            "     81        \u001b[36m0.0397\u001b[0m  0.0230\n",
            "     82        0.0412  0.0202\n",
            "     83        \u001b[36m0.0381\u001b[0m  0.0189\n",
            "     84        \u001b[36m0.0367\u001b[0m  0.0195\n",
            "     85        \u001b[36m0.0352\u001b[0m  0.0192\n",
            "     86        0.0376  0.0190\n",
            "     87        0.0371  0.0198\n",
            "     88        0.0367  0.0207\n",
            "     89        \u001b[36m0.0348\u001b[0m  0.0194\n",
            "     90        0.0351  0.0181\n",
            "     91        0.0363  0.0195\n",
            "     92        \u001b[36m0.0343\u001b[0m  0.0190\n",
            "     93        \u001b[36m0.0335\u001b[0m  0.0192\n",
            "     94        \u001b[36m0.0325\u001b[0m  0.0192\n",
            "     95        0.0361  0.0183\n",
            "     96        0.0328  0.0198\n",
            "     97        0.0342  0.0188\n",
            "     98        0.0348  0.0196\n",
            "     99        \u001b[36m0.0320\u001b[0m  0.0191\n",
            "    100        \u001b[36m0.0297\u001b[0m  0.0184\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1827\u001b[0m  0.0413\n",
            "      2        \u001b[36m0.1645\u001b[0m  0.0375\n",
            "      3        \u001b[36m0.1519\u001b[0m  0.0393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.1429\u001b[0m  0.0393\n",
            "      5        \u001b[36m0.1343\u001b[0m  0.0396\n",
            "      6        \u001b[36m0.1334\u001b[0m  0.0445\n",
            "      7        \u001b[36m0.1295\u001b[0m  0.0562\n",
            "      8        \u001b[36m0.1248\u001b[0m  0.0481\n",
            "      9        \u001b[36m0.1223\u001b[0m  0.0423\n",
            "     10        \u001b[36m0.1179\u001b[0m  0.0467\n",
            "     11        \u001b[36m0.1143\u001b[0m  0.0397\n",
            "     12        0.1156  0.0392\n",
            "     13        0.1165  0.0493\n",
            "     14        \u001b[36m0.1111\u001b[0m  0.0447\n",
            "     15        \u001b[36m0.1111\u001b[0m  0.0475\n",
            "     16        \u001b[36m0.1098\u001b[0m  0.0439\n",
            "     17        \u001b[36m0.1067\u001b[0m  0.0491\n",
            "     18        0.1092  0.0454\n",
            "     19        \u001b[36m0.1047\u001b[0m  0.0550\n",
            "     20        \u001b[36m0.1045\u001b[0m  0.0549\n",
            "     21        0.1058  0.0462\n",
            "     22        \u001b[36m0.1021\u001b[0m  0.0398\n",
            "     23        0.1023  0.0367\n",
            "     24        \u001b[36m0.0991\u001b[0m  0.0328\n",
            "     25        \u001b[36m0.0984\u001b[0m  0.0382\n",
            "     26        0.0988  0.0310\n",
            "     27        \u001b[36m0.0968\u001b[0m  0.0310\n",
            "     28        \u001b[36m0.0947\u001b[0m  0.0308\n",
            "     29        \u001b[36m0.0923\u001b[0m  0.0307\n",
            "     30        0.0947  0.0472\n",
            "     31        \u001b[36m0.0912\u001b[0m  0.0327\n",
            "     32        \u001b[36m0.0908\u001b[0m  0.0332\n",
            "     33        \u001b[36m0.0885\u001b[0m  0.1958\n",
            "     34        0.0903  0.0349\n",
            "     35        0.0904  0.0324\n",
            "     36        \u001b[36m0.0876\u001b[0m  0.0335\n",
            "     37        \u001b[36m0.0863\u001b[0m  0.0316\n",
            "     38        \u001b[36m0.0844\u001b[0m  0.0319\n",
            "     39        \u001b[36m0.0823\u001b[0m  0.0326\n",
            "     40        \u001b[36m0.0810\u001b[0m  0.0323\n",
            "     41        \u001b[36m0.0809\u001b[0m  0.0310\n",
            "     42        \u001b[36m0.0798\u001b[0m  0.0315\n",
            "     43        \u001b[36m0.0789\u001b[0m  0.0321\n",
            "     44        \u001b[36m0.0770\u001b[0m  0.0326\n",
            "     45        \u001b[36m0.0769\u001b[0m  0.0308\n",
            "     46        \u001b[36m0.0767\u001b[0m  0.0303\n",
            "     47        \u001b[36m0.0727\u001b[0m  0.0312\n",
            "     48        \u001b[36m0.0697\u001b[0m  0.0310\n",
            "     49        0.0729  0.0323\n",
            "     50        \u001b[36m0.0692\u001b[0m  0.0302\n",
            "     51        0.0704  0.0306\n",
            "     52        0.0709  0.0359\n",
            "     53        \u001b[36m0.0664\u001b[0m  0.0318\n",
            "     54        0.0673  0.0311\n",
            "     55        0.0665  0.0306\n",
            "     56        \u001b[36m0.0648\u001b[0m  0.0453\n",
            "     57        \u001b[36m0.0644\u001b[0m  0.0311\n",
            "     58        0.0648  0.0309\n",
            "     59        \u001b[36m0.0620\u001b[0m  0.0311\n",
            "     60        \u001b[36m0.0618\u001b[0m  0.0315\n",
            "     61        0.0631  0.0308\n",
            "     62        \u001b[36m0.0613\u001b[0m  0.0337\n",
            "     63        0.0618  0.0306\n",
            "     64        \u001b[36m0.0595\u001b[0m  0.0324\n",
            "     65        \u001b[36m0.0593\u001b[0m  0.0306\n",
            "     66        \u001b[36m0.0588\u001b[0m  0.0317\n",
            "     67        \u001b[36m0.0556\u001b[0m  0.0318\n",
            "     68        0.0570  0.0332\n",
            "     69        0.0561  0.0330\n",
            "     70        \u001b[36m0.0549\u001b[0m  0.0380\n",
            "     71        \u001b[36m0.0538\u001b[0m  0.0378\n",
            "     72        0.0545  0.0355\n",
            "     73        0.0547  0.0339\n",
            "     74        \u001b[36m0.0519\u001b[0m  0.0344\n",
            "     75        0.0536  0.0355\n",
            "     76        0.0524  0.0309\n",
            "     77        \u001b[36m0.0513\u001b[0m  0.0311\n",
            "     78        \u001b[36m0.0500\u001b[0m  0.0310\n",
            "     79        0.0517  0.0316\n",
            "     80        \u001b[36m0.0496\u001b[0m  0.0306\n",
            "     81        \u001b[36m0.0487\u001b[0m  0.0323\n",
            "     82        0.0489  0.0310\n",
            "     83        0.0493  0.0349\n",
            "     84        \u001b[36m0.0484\u001b[0m  0.0312\n",
            "     85        \u001b[36m0.0461\u001b[0m  0.0308\n",
            "     86        \u001b[36m0.0459\u001b[0m  0.0402\n",
            "     87        0.0460  0.0347\n",
            "     88        \u001b[36m0.0434\u001b[0m  0.0311\n",
            "     89        0.0458  0.0309\n",
            "     90        \u001b[36m0.0432\u001b[0m  0.0304\n",
            "     91        0.0459  0.0325\n",
            "     92        \u001b[36m0.0428\u001b[0m  0.0305\n",
            "     93        \u001b[36m0.0423\u001b[0m  0.0313\n",
            "     94        \u001b[36m0.0417\u001b[0m  0.0322\n",
            "     95        0.0428  0.0319\n",
            "     96        \u001b[36m0.0410\u001b[0m  0.0307\n",
            "     97        0.0414  0.0322\n",
            "     98        \u001b[36m0.0399\u001b[0m  0.0330\n",
            "     99        0.0423  0.0315\n",
            "    100        \u001b[36m0.0379\u001b[0m  0.0312\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1665\u001b[0m  0.0351\n",
            "      2        \u001b[36m0.1493\u001b[0m  0.0319\n",
            "      3        \u001b[36m0.1345\u001b[0m  0.0316\n",
            "      4        \u001b[36m0.1228\u001b[0m  0.0315\n",
            "      5        \u001b[36m0.1181\u001b[0m  0.0312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.1137\u001b[0m  0.0384\n",
            "      7        \u001b[36m0.1113\u001b[0m  0.0314\n",
            "      8        \u001b[36m0.1090\u001b[0m  0.0332\n",
            "      9        \u001b[36m0.1043\u001b[0m  0.0360\n",
            "     10        \u001b[36m0.1009\u001b[0m  0.0314\n",
            "     11        0.1012  0.0319\n",
            "     12        \u001b[36m0.0989\u001b[0m  0.0317\n",
            "     13        \u001b[36m0.0964\u001b[0m  0.0315\n",
            "     14        \u001b[36m0.0947\u001b[0m  0.0324\n",
            "     15        \u001b[36m0.0926\u001b[0m  0.0311\n",
            "     16        0.0930  0.0414\n",
            "     17        0.0936  0.0345\n",
            "     18        \u001b[36m0.0915\u001b[0m  0.0325\n",
            "     19        \u001b[36m0.0876\u001b[0m  0.0310\n",
            "     20        \u001b[36m0.0846\u001b[0m  0.0316\n",
            "     21        \u001b[36m0.0838\u001b[0m  0.0315\n",
            "     22        \u001b[36m0.0814\u001b[0m  0.0325\n",
            "     23        \u001b[36m0.0803\u001b[0m  0.0328\n",
            "     24        \u001b[36m0.0788\u001b[0m  0.0329\n",
            "     25        \u001b[36m0.0769\u001b[0m  0.0311\n",
            "     26        \u001b[36m0.0751\u001b[0m  0.0313\n",
            "     27        \u001b[36m0.0732\u001b[0m  0.0322\n",
            "     28        \u001b[36m0.0717\u001b[0m  0.0315\n",
            "     29        \u001b[36m0.0711\u001b[0m  0.0317\n",
            "     30        \u001b[36m0.0683\u001b[0m  0.0325\n",
            "     31        0.0685  0.0315\n",
            "     32        \u001b[36m0.0676\u001b[0m  0.0312\n",
            "     33        \u001b[36m0.0664\u001b[0m  0.0313\n",
            "     34        \u001b[36m0.0635\u001b[0m  0.0343\n",
            "     35        \u001b[36m0.0622\u001b[0m  0.0314\n",
            "     36        \u001b[36m0.0608\u001b[0m  0.0310\n",
            "     37        0.0621  0.0312\n",
            "     38        \u001b[36m0.0600\u001b[0m  0.0369\n",
            "     39        \u001b[36m0.0577\u001b[0m  0.0308\n",
            "     40        \u001b[36m0.0559\u001b[0m  0.0309\n",
            "     41        \u001b[36m0.0554\u001b[0m  0.0313\n",
            "     42        \u001b[36m0.0553\u001b[0m  0.0310\n",
            "     43        0.0560  0.0330\n",
            "     44        \u001b[36m0.0523\u001b[0m  0.0318\n",
            "     45        \u001b[36m0.0513\u001b[0m  0.0314\n",
            "     46        \u001b[36m0.0506\u001b[0m  0.0333\n",
            "     47        \u001b[36m0.0503\u001b[0m  0.0348\n",
            "     48        0.0506  0.0425\n",
            "     49        \u001b[36m0.0489\u001b[0m  0.0320\n",
            "     50        \u001b[36m0.0474\u001b[0m  0.0337\n",
            "     51        0.0479  0.0318\n",
            "     52        \u001b[36m0.0456\u001b[0m  0.0316\n",
            "     53        \u001b[36m0.0442\u001b[0m  0.0330\n",
            "     54        0.0456  0.0333\n",
            "     55        \u001b[36m0.0431\u001b[0m  0.0314\n",
            "     56        \u001b[36m0.0420\u001b[0m  0.0321\n",
            "     57        0.0420  0.0314\n",
            "     58        \u001b[36m0.0406\u001b[0m  0.0317\n",
            "     59        \u001b[36m0.0398\u001b[0m  0.0349\n",
            "     60        0.0402  0.0312\n",
            "     61        \u001b[36m0.0396\u001b[0m  0.0315\n",
            "     62        \u001b[36m0.0393\u001b[0m  0.0321\n",
            "     63        \u001b[36m0.0379\u001b[0m  0.0313\n",
            "     64        0.0382  0.0316\n",
            "     65        \u001b[36m0.0369\u001b[0m  0.0315\n",
            "     66        \u001b[36m0.0352\u001b[0m  0.0318\n",
            "     67        \u001b[36m0.0351\u001b[0m  0.0332\n",
            "     68        \u001b[36m0.0348\u001b[0m  0.0331\n",
            "     69        0.0350  0.0308\n",
            "     70        \u001b[36m0.0334\u001b[0m  0.0372\n",
            "     71        \u001b[36m0.0318\u001b[0m  0.0316\n",
            "     72        0.0326  0.0351\n",
            "     73        \u001b[36m0.0314\u001b[0m  0.0323\n",
            "     74        \u001b[36m0.0312\u001b[0m  0.0318\n",
            "     75        \u001b[36m0.0304\u001b[0m  0.0335\n",
            "     76        0.0311  0.0327\n",
            "     77        0.0306  0.0330\n",
            "     78        \u001b[36m0.0291\u001b[0m  0.0427\n",
            "     79        \u001b[36m0.0291\u001b[0m  0.0387\n",
            "     80        0.0298  0.0320\n",
            "     81        \u001b[36m0.0274\u001b[0m  0.0323\n",
            "     82        0.0276  0.0328\n",
            "     83        \u001b[36m0.0267\u001b[0m  0.0320\n",
            "     84        \u001b[36m0.0264\u001b[0m  0.0326\n",
            "     85        \u001b[36m0.0257\u001b[0m  0.0321\n",
            "     86        0.0265  0.0320\n",
            "     87        0.0265  0.0324\n",
            "     88        0.0269  0.0319\n",
            "     89        \u001b[36m0.0243\u001b[0m  0.0316\n",
            "     90        0.0244  0.0319\n",
            "     91        \u001b[36m0.0240\u001b[0m  0.0315\n",
            "     92        0.0244  0.0317\n",
            "     93        \u001b[36m0.0238\u001b[0m  0.0331\n",
            "     94        \u001b[36m0.0233\u001b[0m  0.0314\n",
            "     95        0.0235  0.0339\n",
            "     96        \u001b[36m0.0227\u001b[0m  0.0312\n",
            "     97        0.0228  0.0310\n",
            "     98        \u001b[36m0.0220\u001b[0m  0.0331\n",
            "     99        \u001b[36m0.0214\u001b[0m  0.0309\n",
            "    100        0.0224  0.0310\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1552\u001b[0m  0.0320\n",
            "      2        \u001b[36m0.1477\u001b[0m  0.0243\n",
            "      3        \u001b[36m0.1396\u001b[0m  0.0250\n",
            "      4        \u001b[36m0.1241\u001b[0m  0.0250\n",
            "      5        \u001b[36m0.1156\u001b[0m  0.0238\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        0.1157  0.0262\n",
            "      7        \u001b[36m0.1122\u001b[0m  0.0239\n",
            "      8        \u001b[36m0.1060\u001b[0m  0.0254\n",
            "      9        \u001b[36m0.0998\u001b[0m  0.0343\n",
            "     10        0.1007  0.0259\n",
            "     11        \u001b[36m0.0996\u001b[0m  0.0237\n",
            "     12        \u001b[36m0.0965\u001b[0m  0.0231\n",
            "     13        \u001b[36m0.0948\u001b[0m  0.0242\n",
            "     14        0.0966  0.0231\n",
            "     15        \u001b[36m0.0928\u001b[0m  0.0246\n",
            "     16        \u001b[36m0.0889\u001b[0m  0.0231\n",
            "     17        0.0937  0.0255\n",
            "     18        \u001b[36m0.0887\u001b[0m  0.0237\n",
            "     19        0.0889  0.0230\n",
            "     20        \u001b[36m0.0868\u001b[0m  0.0232\n",
            "     21        \u001b[36m0.0832\u001b[0m  0.0237\n",
            "     22        0.0833  0.0227\n",
            "     23        0.0839  0.0230\n",
            "     24        \u001b[36m0.0804\u001b[0m  0.0247\n",
            "     25        0.0811  0.0234\n",
            "     26        \u001b[36m0.0802\u001b[0m  0.0230\n",
            "     27        \u001b[36m0.0789\u001b[0m  0.0224\n",
            "     28        \u001b[36m0.0766\u001b[0m  0.0233\n",
            "     29        \u001b[36m0.0740\u001b[0m  0.0233\n",
            "     30        \u001b[36m0.0725\u001b[0m  0.0236\n",
            "     31        0.0728  0.0234\n",
            "     32        \u001b[36m0.0704\u001b[0m  0.0279\n",
            "     33        0.0757  0.0239\n",
            "     34        \u001b[36m0.0700\u001b[0m  0.0248\n",
            "     35        \u001b[36m0.0669\u001b[0m  0.0231\n",
            "     36        0.0683  0.0224\n",
            "     37        \u001b[36m0.0635\u001b[0m  0.0227\n",
            "     38        0.0640  0.0227\n",
            "     39        \u001b[36m0.0603\u001b[0m  0.0229\n",
            "     40        0.0625  0.0238\n",
            "     41        0.0607  0.0238\n",
            "     42        \u001b[36m0.0552\u001b[0m  0.0232\n",
            "     43        0.0587  0.0249\n",
            "     44        \u001b[36m0.0544\u001b[0m  0.0235\n",
            "     45        \u001b[36m0.0544\u001b[0m  0.0232\n",
            "     46        0.0560  0.0232\n",
            "     47        \u001b[36m0.0536\u001b[0m  0.0253\n",
            "     48        0.0543  0.0228\n",
            "     49        \u001b[36m0.0512\u001b[0m  0.0232\n",
            "     50        \u001b[36m0.0486\u001b[0m  0.0227\n",
            "     51        \u001b[36m0.0483\u001b[0m  0.0333\n",
            "     52        \u001b[36m0.0471\u001b[0m  0.0230\n",
            "     53        \u001b[36m0.0460\u001b[0m  0.0238\n",
            "     54        \u001b[36m0.0424\u001b[0m  0.0225\n",
            "     55        \u001b[36m0.0403\u001b[0m  0.0244\n",
            "     56        0.0437  0.0231\n",
            "     57        0.0425  0.0231\n",
            "     58        \u001b[36m0.0393\u001b[0m  0.0242\n",
            "     59        \u001b[36m0.0389\u001b[0m  0.0229\n",
            "     60        \u001b[36m0.0354\u001b[0m  0.0232\n",
            "     61        \u001b[36m0.0354\u001b[0m  0.0233\n",
            "     62        0.0368  0.0232\n",
            "     63        0.0367  0.0231\n",
            "     64        0.0367  0.0252\n",
            "     65        0.0372  0.0233\n",
            "     66        \u001b[36m0.0330\u001b[0m  0.0229\n",
            "     67        0.0340  0.0230\n",
            "     68        \u001b[36m0.0303\u001b[0m  0.0245\n",
            "     69        \u001b[36m0.0298\u001b[0m  0.0234\n",
            "     70        \u001b[36m0.0283\u001b[0m  0.0222\n",
            "     71        \u001b[36m0.0282\u001b[0m  0.0227\n",
            "     72        \u001b[36m0.0275\u001b[0m  0.0228\n",
            "     73        \u001b[36m0.0271\u001b[0m  0.0231\n",
            "     74        0.0294  0.0230\n",
            "     75        \u001b[36m0.0248\u001b[0m  0.0300\n",
            "     76        0.0261  0.0246\n",
            "     77        0.0256  0.0231\n",
            "     78        \u001b[36m0.0245\u001b[0m  0.0231\n",
            "     79        0.0248  0.0237\n",
            "     80        \u001b[36m0.0243\u001b[0m  0.0229\n",
            "     81        \u001b[36m0.0234\u001b[0m  0.0234\n",
            "     82        \u001b[36m0.0230\u001b[0m  0.0225\n",
            "     83        0.0245  0.0231\n",
            "     84        \u001b[36m0.0218\u001b[0m  0.0232\n",
            "     85        \u001b[36m0.0204\u001b[0m  0.0244\n",
            "     86        0.0210  0.0243\n",
            "     87        \u001b[36m0.0194\u001b[0m  0.0235\n",
            "     88        0.0200  0.0233\n",
            "     89        \u001b[36m0.0181\u001b[0m  0.0235\n",
            "     90        0.0190  0.0232\n",
            "     91        0.0185  0.0232\n",
            "     92        0.0197  0.0223\n",
            "     93        0.0188  0.0363\n",
            "     94        0.0186  0.0264\n",
            "     95        \u001b[36m0.0176\u001b[0m  0.0234\n",
            "     96        0.0193  0.0244\n",
            "     97        0.0188  0.0231\n",
            "     98        \u001b[36m0.0175\u001b[0m  0.0238\n",
            "     99        \u001b[36m0.0155\u001b[0m  0.0239\n",
            "    100        0.0170  0.0245\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1709\u001b[0m  0.0555\n",
            "      2        \u001b[36m0.1368\u001b[0m  0.0433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.1284\u001b[0m  0.0474\n",
            "      4        \u001b[36m0.1206\u001b[0m  0.0468\n",
            "      5        \u001b[36m0.1129\u001b[0m  0.0434\n",
            "      6        \u001b[36m0.1119\u001b[0m  0.0431\n",
            "      7        \u001b[36m0.1084\u001b[0m  0.0455\n",
            "      8        \u001b[36m0.1062\u001b[0m  0.0427\n",
            "      9        \u001b[36m0.1040\u001b[0m  0.0482\n",
            "     10        \u001b[36m0.1040\u001b[0m  0.0433\n",
            "     11        \u001b[36m0.1010\u001b[0m  0.0453\n",
            "     12        \u001b[36m0.1009\u001b[0m  0.0435\n",
            "     13        0.1012  0.0430\n",
            "     14        \u001b[36m0.0992\u001b[0m  0.0448\n",
            "     15        \u001b[36m0.0971\u001b[0m  0.0468\n",
            "     16        \u001b[36m0.0967\u001b[0m  0.0436\n",
            "     17        \u001b[36m0.0953\u001b[0m  0.0567\n",
            "     18        \u001b[36m0.0943\u001b[0m  0.0455\n",
            "     19        \u001b[36m0.0922\u001b[0m  0.0447\n",
            "     20        0.0923  0.0444\n",
            "     21        \u001b[36m0.0896\u001b[0m  0.0445\n",
            "     22        \u001b[36m0.0893\u001b[0m  0.0446\n",
            "     23        \u001b[36m0.0868\u001b[0m  0.0435\n",
            "     24        \u001b[36m0.0856\u001b[0m  0.0423\n",
            "     25        \u001b[36m0.0842\u001b[0m  0.0432\n",
            "     26        \u001b[36m0.0832\u001b[0m  0.0429\n",
            "     27        \u001b[36m0.0801\u001b[0m  0.0564\n",
            "     28        0.0801  0.0690\n",
            "     29        \u001b[36m0.0800\u001b[0m  0.0687\n",
            "     30        \u001b[36m0.0755\u001b[0m  0.0596\n",
            "     31        \u001b[36m0.0740\u001b[0m  0.0639\n",
            "     32        \u001b[36m0.0739\u001b[0m  0.0576\n",
            "     33        \u001b[36m0.0711\u001b[0m  0.0521\n",
            "     34        \u001b[36m0.0705\u001b[0m  0.0592\n",
            "     35        \u001b[36m0.0695\u001b[0m  0.0551\n",
            "     36        \u001b[36m0.0668\u001b[0m  0.0648\n",
            "     37        \u001b[36m0.0666\u001b[0m  0.0622\n",
            "     38        \u001b[36m0.0651\u001b[0m  0.0629\n",
            "     39        0.0660  0.0591\n",
            "     40        \u001b[36m0.0621\u001b[0m  0.0562\n",
            "     41        \u001b[36m0.0618\u001b[0m  0.0565\n",
            "     42        \u001b[36m0.0608\u001b[0m  0.0534\n",
            "     43        \u001b[36m0.0596\u001b[0m  0.0534\n",
            "     44        \u001b[36m0.0574\u001b[0m  0.0591\n",
            "     45        0.0583  0.0528\n",
            "     46        0.0594  0.0528\n",
            "     47        \u001b[36m0.0550\u001b[0m  0.0529\n",
            "     48        0.0553  0.0523\n",
            "     49        \u001b[36m0.0528\u001b[0m  0.0564\n",
            "     50        \u001b[36m0.0515\u001b[0m  0.0629\n",
            "     51        0.0516  0.0622\n",
            "     52        \u001b[36m0.0491\u001b[0m  0.0665\n",
            "     53        0.0496  0.0652\n",
            "     54        \u001b[36m0.0485\u001b[0m  0.0668\n",
            "     55        \u001b[36m0.0485\u001b[0m  0.0668\n",
            "     56        0.0487  0.0703\n",
            "     57        \u001b[36m0.0447\u001b[0m  0.0595\n",
            "     58        \u001b[36m0.0442\u001b[0m  0.0671\n",
            "     59        0.0449  0.0682\n",
            "     60        \u001b[36m0.0434\u001b[0m  0.0652\n",
            "     61        0.0435  0.0627\n",
            "     62        \u001b[36m0.0414\u001b[0m  0.0494\n",
            "     63        0.0418  0.0434\n",
            "     64        \u001b[36m0.0413\u001b[0m  0.0468\n",
            "     65        \u001b[36m0.0398\u001b[0m  0.0436\n",
            "     66        \u001b[36m0.0388\u001b[0m  0.0446\n",
            "     67        0.0408  0.0430\n",
            "     68        \u001b[36m0.0380\u001b[0m  0.0427\n",
            "     69        \u001b[36m0.0380\u001b[0m  0.0439\n",
            "     70        \u001b[36m0.0377\u001b[0m  0.0432\n",
            "     71        \u001b[36m0.0366\u001b[0m  0.0460\n",
            "     72        \u001b[36m0.0354\u001b[0m  0.0576\n",
            "     73        0.0365  0.0448\n",
            "     74        \u001b[36m0.0352\u001b[0m  0.0430\n",
            "     75        \u001b[36m0.0341\u001b[0m  0.0433\n",
            "     76        \u001b[36m0.0331\u001b[0m  0.0434\n",
            "     77        0.0345  0.0435\n",
            "     78        0.0333  0.0454\n",
            "     79        \u001b[36m0.0313\u001b[0m  0.0498\n",
            "     80        0.0314  0.0468\n",
            "     81        \u001b[36m0.0313\u001b[0m  0.0531\n",
            "     82        \u001b[36m0.0307\u001b[0m  0.0482\n",
            "     83        0.0311  0.0465\n",
            "     84        \u001b[36m0.0297\u001b[0m  0.0476\n",
            "     85        \u001b[36m0.0278\u001b[0m  0.0452\n",
            "     86        0.0296  0.0435\n",
            "     87        0.0295  0.0432\n",
            "     88        0.0284  0.0432\n",
            "     89        0.0285  0.0434\n",
            "     90        0.0295  0.0446\n",
            "     91        0.0295  0.0447\n",
            "     92        0.0284  0.0445\n",
            "     93        \u001b[36m0.0276\u001b[0m  0.0437\n",
            "     94        \u001b[36m0.0268\u001b[0m  0.0572\n",
            "     95        0.0272  0.0429\n",
            "     96        \u001b[36m0.0268\u001b[0m  0.0464\n",
            "     97        \u001b[36m0.0252\u001b[0m  0.0442\n",
            "     98        \u001b[36m0.0241\u001b[0m  0.0437\n",
            "     99        0.0241  0.0433\n",
            "    100        0.0244  0.0432\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1654\u001b[0m  0.0545\n",
            "      2        \u001b[36m0.1310\u001b[0m  0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.1172\u001b[0m  0.0472\n",
            "      4        \u001b[36m0.1106\u001b[0m  0.0438\n",
            "      5        \u001b[36m0.1079\u001b[0m  0.0432\n",
            "      6        \u001b[36m0.1046\u001b[0m  0.0449\n",
            "      7        \u001b[36m0.1037\u001b[0m  0.0437\n",
            "      8        \u001b[36m0.1024\u001b[0m  0.0444\n",
            "      9        \u001b[36m0.1003\u001b[0m  0.0437\n",
            "     10        0.1024  0.0434\n",
            "     11        \u001b[36m0.0982\u001b[0m  0.0451\n",
            "     12        \u001b[36m0.0976\u001b[0m  0.0447\n",
            "     13        0.0977  0.0470\n",
            "     14        \u001b[36m0.0953\u001b[0m  0.0441\n",
            "     15        0.0955  0.0577\n",
            "     16        \u001b[36m0.0945\u001b[0m  0.0442\n",
            "     17        \u001b[36m0.0936\u001b[0m  0.0437\n",
            "     18        \u001b[36m0.0913\u001b[0m  0.0440\n",
            "     19        \u001b[36m0.0906\u001b[0m  0.0444\n",
            "     20        \u001b[36m0.0881\u001b[0m  0.0486\n",
            "     21        \u001b[36m0.0861\u001b[0m  0.0439\n",
            "     22        \u001b[36m0.0844\u001b[0m  0.0459\n",
            "     23        \u001b[36m0.0842\u001b[0m  0.0450\n",
            "     24        \u001b[36m0.0837\u001b[0m  0.0436\n",
            "     25        \u001b[36m0.0815\u001b[0m  0.0435\n",
            "     26        \u001b[36m0.0799\u001b[0m  0.0444\n",
            "     27        \u001b[36m0.0770\u001b[0m  0.0441\n",
            "     28        \u001b[36m0.0762\u001b[0m  0.0439\n",
            "     29        0.0768  0.0449\n",
            "     30        \u001b[36m0.0747\u001b[0m  0.0441\n",
            "     31        \u001b[36m0.0731\u001b[0m  0.0436\n",
            "     32        \u001b[36m0.0708\u001b[0m  0.0449\n",
            "     33        \u001b[36m0.0683\u001b[0m  0.0453\n",
            "     34        \u001b[36m0.0682\u001b[0m  0.0442\n",
            "     35        \u001b[36m0.0678\u001b[0m  0.0449\n",
            "     36        \u001b[36m0.0653\u001b[0m  0.0437\n",
            "     37        \u001b[36m0.0642\u001b[0m  0.0538\n",
            "     38        \u001b[36m0.0637\u001b[0m  0.0506\n",
            "     39        \u001b[36m0.0613\u001b[0m  0.0455\n",
            "     40        \u001b[36m0.0609\u001b[0m  0.0451\n",
            "     41        \u001b[36m0.0589\u001b[0m  0.0479\n",
            "     42        \u001b[36m0.0582\u001b[0m  0.0442\n",
            "     43        \u001b[36m0.0574\u001b[0m  0.0437\n",
            "     44        \u001b[36m0.0567\u001b[0m  0.0516\n",
            "     45        \u001b[36m0.0543\u001b[0m  0.0448\n",
            "     46        \u001b[36m0.0538\u001b[0m  0.0436\n",
            "     47        \u001b[36m0.0522\u001b[0m  0.0453\n",
            "     48        \u001b[36m0.0498\u001b[0m  0.0445\n",
            "     49        0.0506  0.0437\n",
            "     50        \u001b[36m0.0498\u001b[0m  0.0452\n",
            "     51        \u001b[36m0.0473\u001b[0m  0.0437\n",
            "     52        \u001b[36m0.0467\u001b[0m  0.0442\n",
            "     53        \u001b[36m0.0446\u001b[0m  0.0431\n",
            "     54        \u001b[36m0.0437\u001b[0m  0.0489\n",
            "     55        \u001b[36m0.0415\u001b[0m  0.0447\n",
            "     56        \u001b[36m0.0409\u001b[0m  0.0445\n",
            "     57        \u001b[36m0.0399\u001b[0m  0.0450\n",
            "     58        \u001b[36m0.0382\u001b[0m  0.0434\n",
            "     59        \u001b[36m0.0377\u001b[0m  0.0443\n",
            "     60        \u001b[36m0.0362\u001b[0m  0.0584\n",
            "     61        \u001b[36m0.0362\u001b[0m  0.0454\n",
            "     62        \u001b[36m0.0335\u001b[0m  0.0445\n",
            "     63        \u001b[36m0.0330\u001b[0m  0.0435\n",
            "     64        \u001b[36m0.0316\u001b[0m  0.0436\n",
            "     65        \u001b[36m0.0310\u001b[0m  0.0433\n",
            "     66        \u001b[36m0.0310\u001b[0m  0.0456\n",
            "     67        \u001b[36m0.0297\u001b[0m  0.0480\n",
            "     68        \u001b[36m0.0286\u001b[0m  0.0443\n",
            "     69        \u001b[36m0.0271\u001b[0m  0.0454\n",
            "     70        0.0278  0.0435\n",
            "     71        \u001b[36m0.0258\u001b[0m  0.0437\n",
            "     72        0.0267  0.0454\n",
            "     73        \u001b[36m0.0248\u001b[0m  0.0432\n",
            "     74        \u001b[36m0.0237\u001b[0m  0.0445\n",
            "     75        \u001b[36m0.0234\u001b[0m  0.0438\n",
            "     76        \u001b[36m0.0227\u001b[0m  0.0453\n",
            "     77        0.0232  0.0480\n",
            "     78        \u001b[36m0.0223\u001b[0m  0.0437\n",
            "     79        \u001b[36m0.0207\u001b[0m  0.0454\n",
            "     80        \u001b[36m0.0199\u001b[0m  0.0458\n",
            "     81        0.0203  0.0445\n",
            "     82        \u001b[36m0.0196\u001b[0m  0.0579\n",
            "     83        \u001b[36m0.0195\u001b[0m  0.0551\n",
            "     84        \u001b[36m0.0186\u001b[0m  0.0646\n",
            "     85        0.0187  0.0502\n",
            "     86        \u001b[36m0.0183\u001b[0m  0.0447\n",
            "     87        \u001b[36m0.0174\u001b[0m  0.0457\n",
            "     88        0.0179  0.0438\n",
            "     89        \u001b[36m0.0173\u001b[0m  0.0454\n",
            "     90        \u001b[36m0.0162\u001b[0m  0.0446\n",
            "     91        \u001b[36m0.0158\u001b[0m  0.0449\n",
            "     92        0.0161  0.0438\n",
            "     93        \u001b[36m0.0152\u001b[0m  0.0437\n",
            "     94        0.0156  0.0436\n",
            "     95        0.0154  0.0446\n",
            "     96        \u001b[36m0.0152\u001b[0m  0.0472\n",
            "     97        \u001b[36m0.0145\u001b[0m  0.0447\n",
            "     98        0.0146  0.0447\n",
            "     99        \u001b[36m0.0140\u001b[0m  0.0438\n",
            "    100        0.0141  0.0437\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1760\u001b[0m  0.0420\n",
            "      2        \u001b[36m0.1482\u001b[0m  0.0078\n",
            "      3        \u001b[36m0.1347\u001b[0m  0.0083\n",
            "      4        \u001b[36m0.1257\u001b[0m  0.0071\n",
            "      5        \u001b[36m0.1141\u001b[0m  0.0056\n",
            "      6        \u001b[36m0.1055\u001b[0m  0.0060\n",
            "      7        \u001b[36m0.1000\u001b[0m  0.0058\n",
            "      8        \u001b[36m0.0924\u001b[0m  0.0057\n",
            "      9        \u001b[36m0.0856\u001b[0m  0.0056\n",
            "     10        \u001b[36m0.0834\u001b[0m  0.0084\n",
            "     11        \u001b[36m0.0769\u001b[0m  0.0095\n",
            "     12        \u001b[36m0.0708\u001b[0m  0.0077\n",
            "     13        \u001b[36m0.0695\u001b[0m  0.0075\n",
            "     14        \u001b[36m0.0672\u001b[0m  0.0075\n",
            "     15        \u001b[36m0.0647\u001b[0m  0.0077\n",
            "     16        \u001b[36m0.0620\u001b[0m  0.0079\n",
            "     17        \u001b[36m0.0587\u001b[0m  0.0077\n",
            "     18        \u001b[36m0.0574\u001b[0m  0.0075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     19        \u001b[36m0.0537\u001b[0m  0.0078\n",
            "     20        \u001b[36m0.0512\u001b[0m  0.0070\n",
            "     21        \u001b[36m0.0491\u001b[0m  0.0070\n",
            "     22        \u001b[36m0.0485\u001b[0m  0.0072\n",
            "     23        \u001b[36m0.0448\u001b[0m  0.0082\n",
            "     24        \u001b[36m0.0447\u001b[0m  0.0066\n",
            "     25        \u001b[36m0.0425\u001b[0m  0.0071\n",
            "     26        \u001b[36m0.0397\u001b[0m  0.0075\n",
            "     27        0.0399  0.0081\n",
            "     28        \u001b[36m0.0371\u001b[0m  0.0059\n",
            "     29        \u001b[36m0.0357\u001b[0m  0.0072\n",
            "     30        0.0358  0.0079\n",
            "     31        \u001b[36m0.0335\u001b[0m  0.0071\n",
            "     32        \u001b[36m0.0324\u001b[0m  0.0063\n",
            "     33        0.0336  0.0070\n",
            "     34        \u001b[36m0.0323\u001b[0m  0.0080\n",
            "     35        \u001b[36m0.0292\u001b[0m  0.0086\n",
            "     36        0.0295  0.0070\n",
            "     37        \u001b[36m0.0282\u001b[0m  0.0057\n",
            "     38        \u001b[36m0.0275\u001b[0m  0.0074\n",
            "     39        \u001b[36m0.0269\u001b[0m  0.0075\n",
            "     40        \u001b[36m0.0258\u001b[0m  0.0071\n",
            "     41        \u001b[36m0.0253\u001b[0m  0.0073\n",
            "     42        \u001b[36m0.0241\u001b[0m  0.0063\n",
            "     43        \u001b[36m0.0229\u001b[0m  0.0057\n",
            "     44        \u001b[36m0.0226\u001b[0m  0.0075\n",
            "     45        \u001b[36m0.0225\u001b[0m  0.0073\n",
            "     46        \u001b[36m0.0216\u001b[0m  0.0074\n",
            "     47        \u001b[36m0.0208\u001b[0m  0.0075\n",
            "     48        \u001b[36m0.0203\u001b[0m  0.0068\n",
            "     49        0.0211  0.0064\n",
            "     50        \u001b[36m0.0188\u001b[0m  0.0059\n",
            "     51        \u001b[36m0.0183\u001b[0m  0.0083\n",
            "     52        0.0184  0.0075\n",
            "     53        \u001b[36m0.0177\u001b[0m  0.0074\n",
            "     54        0.0183  0.0072\n",
            "     55        \u001b[36m0.0167\u001b[0m  0.0071\n",
            "     56        \u001b[36m0.0166\u001b[0m  0.0072\n",
            "     57        0.0170  0.0077\n",
            "     58        \u001b[36m0.0162\u001b[0m  0.0063\n",
            "     59        \u001b[36m0.0153\u001b[0m  0.0058\n",
            "     60        \u001b[36m0.0149\u001b[0m  0.0056\n",
            "     61        \u001b[36m0.0146\u001b[0m  0.0057\n",
            "     62        \u001b[36m0.0144\u001b[0m  0.0061\n",
            "     63        \u001b[36m0.0139\u001b[0m  0.0079\n",
            "     64        \u001b[36m0.0133\u001b[0m  0.0073\n",
            "     65        \u001b[36m0.0128\u001b[0m  0.0071\n",
            "     66        \u001b[36m0.0126\u001b[0m  0.0087\n",
            "     67        0.0130  0.0056\n",
            "     68        \u001b[36m0.0125\u001b[0m  0.0058\n",
            "     69        \u001b[36m0.0119\u001b[0m  0.0079\n",
            "     70        \u001b[36m0.0115\u001b[0m  0.0073\n",
            "     71        0.0117  0.0078\n",
            "     72        0.0116  0.0069\n",
            "     73        \u001b[36m0.0111\u001b[0m  0.0055\n",
            "     74        \u001b[36m0.0106\u001b[0m  0.0056\n",
            "     75        0.0107  0.0082\n",
            "     76        \u001b[36m0.0102\u001b[0m  0.0071\n",
            "     77        0.0103  0.0062\n",
            "     78        0.0105  0.0072\n",
            "     79        \u001b[36m0.0092\u001b[0m  0.0077\n",
            "     80        0.0094  0.0075\n",
            "     81        \u001b[36m0.0088\u001b[0m  0.0084\n",
            "     82        0.0099  0.0077\n",
            "     83        \u001b[36m0.0086\u001b[0m  0.0075\n",
            "     84        0.0090  0.0078\n",
            "     85        0.0092  0.0069\n",
            "     86        \u001b[36m0.0080\u001b[0m  0.0078\n",
            "     87        \u001b[36m0.0079\u001b[0m  0.0073\n",
            "     88        0.0081  0.0076\n",
            "     89        \u001b[36m0.0078\u001b[0m  0.0056\n",
            "     90        0.0081  0.0058\n",
            "     91        0.0080  0.0057\n",
            "     92        \u001b[36m0.0073\u001b[0m  0.0091\n",
            "     93        0.0073  0.0072\n",
            "     94        0.0080  0.0083\n",
            "     95        0.0077  0.0067\n",
            "     96        \u001b[36m0.0068\u001b[0m  0.0071\n",
            "     97        0.0070  0.0084\n",
            "     98        0.0071  0.0056\n",
            "     99        0.0068  0.0059\n",
            "    100        0.0069  0.0058\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1700\u001b[0m  0.0218\n",
            "      2        \u001b[36m0.1334\u001b[0m  0.0139\n",
            "      3        \u001b[36m0.1107\u001b[0m  0.0132\n",
            "      4        \u001b[36m0.0961\u001b[0m  0.0129\n",
            "      5        \u001b[36m0.0831\u001b[0m  0.0107\n",
            "      6        \u001b[36m0.0757\u001b[0m  0.0106\n",
            "      7        \u001b[36m0.0682\u001b[0m  0.0157\n",
            "      8        \u001b[36m0.0639\u001b[0m  0.0132\n",
            "      9        \u001b[36m0.0590\u001b[0m  0.0122\n",
            "     10        \u001b[36m0.0543\u001b[0m  0.0107\n",
            "     11        \u001b[36m0.0503\u001b[0m  0.0106\n",
            "     12        \u001b[36m0.0473\u001b[0m  0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0451\u001b[0m  0.0151\n",
            "     14        \u001b[36m0.0415\u001b[0m  0.0125\n",
            "     15        \u001b[36m0.0391\u001b[0m  0.0120\n",
            "     16        \u001b[36m0.0373\u001b[0m  0.0122\n",
            "     17        \u001b[36m0.0345\u001b[0m  0.0108\n",
            "     18        \u001b[36m0.0329\u001b[0m  0.0137\n",
            "     19        \u001b[36m0.0316\u001b[0m  0.0129\n",
            "     20        \u001b[36m0.0304\u001b[0m  0.0144\n",
            "     21        \u001b[36m0.0294\u001b[0m  0.0110\n",
            "     22        \u001b[36m0.0275\u001b[0m  0.0134\n",
            "     23        \u001b[36m0.0263\u001b[0m  0.0176\n",
            "     24        \u001b[36m0.0249\u001b[0m  0.0170\n",
            "     25        \u001b[36m0.0240\u001b[0m  0.0129\n",
            "     26        \u001b[36m0.0236\u001b[0m  0.0113\n",
            "     27        \u001b[36m0.0225\u001b[0m  0.0143\n",
            "     28        \u001b[36m0.0219\u001b[0m  0.0132\n",
            "     29        \u001b[36m0.0211\u001b[0m  0.0106\n",
            "     30        \u001b[36m0.0204\u001b[0m  0.0108\n",
            "     31        \u001b[36m0.0195\u001b[0m  0.0147\n",
            "     32        \u001b[36m0.0188\u001b[0m  0.0125\n",
            "     33        0.0200  0.0116\n",
            "     34        \u001b[36m0.0180\u001b[0m  0.0150\n",
            "     35        0.0181  0.0140\n",
            "     36        \u001b[36m0.0170\u001b[0m  0.0151\n",
            "     37        \u001b[36m0.0168\u001b[0m  0.0124\n",
            "     38        \u001b[36m0.0163\u001b[0m  0.0122\n",
            "     39        0.0169  0.0108\n",
            "     40        \u001b[36m0.0155\u001b[0m  0.0107\n",
            "     41        \u001b[36m0.0155\u001b[0m  0.0128\n",
            "     42        \u001b[36m0.0148\u001b[0m  0.0140\n",
            "     43        0.0152  0.0120\n",
            "     44        \u001b[36m0.0141\u001b[0m  0.0108\n",
            "     45        \u001b[36m0.0138\u001b[0m  0.0104\n",
            "     46        0.0140  0.0137\n",
            "     47        \u001b[36m0.0128\u001b[0m  0.0159\n",
            "     48        \u001b[36m0.0127\u001b[0m  0.0122\n",
            "     49        0.0129  0.0121\n",
            "     50        0.0128  0.0107\n",
            "     51        0.0129  0.0110\n",
            "     52        \u001b[36m0.0124\u001b[0m  0.0128\n",
            "     53        0.0126  0.0153\n",
            "     54        \u001b[36m0.0117\u001b[0m  0.0134\n",
            "     55        0.0120  0.0119\n",
            "     56        0.0118  0.0122\n",
            "     57        \u001b[36m0.0117\u001b[0m  0.0133\n",
            "     58        \u001b[36m0.0108\u001b[0m  0.0104\n",
            "     59        0.0112  0.0105\n",
            "     60        0.0111  0.0129\n",
            "     61        \u001b[36m0.0104\u001b[0m  0.0136\n",
            "     62        0.0110  0.0131\n",
            "     63        \u001b[36m0.0103\u001b[0m  0.0121\n",
            "     64        0.0104  0.0122\n",
            "     65        \u001b[36m0.0101\u001b[0m  0.0127\n",
            "     66        0.0102  0.0127\n",
            "     67        \u001b[36m0.0099\u001b[0m  0.0131\n",
            "     68        0.0115  0.0131\n",
            "     69        \u001b[36m0.0097\u001b[0m  0.0127\n",
            "     70        0.0098  0.0129\n",
            "     71        0.0098  0.0133\n",
            "     72        \u001b[36m0.0092\u001b[0m  0.0151\n",
            "     73        \u001b[36m0.0091\u001b[0m  0.0107\n",
            "     74        0.0094  0.0107\n",
            "     75        \u001b[36m0.0087\u001b[0m  0.0140\n",
            "     76        0.0088  0.0118\n",
            "     77        0.0095  0.0133\n",
            "     78        0.0092  0.0121\n",
            "     79        \u001b[36m0.0085\u001b[0m  0.0105\n",
            "     80        \u001b[36m0.0082\u001b[0m  0.0103\n",
            "     81        0.0091  0.0129\n",
            "     82        0.0085  0.0138\n",
            "     83        0.0085  0.0123\n",
            "     84        0.0090  0.0110\n",
            "     85        \u001b[36m0.0077\u001b[0m  0.0108\n",
            "     86        0.0083  0.0134\n",
            "     87        0.0081  0.0131\n",
            "     88        0.0082  0.0122\n",
            "     89        0.0083  0.0108\n",
            "     90        0.0083  0.0108\n",
            "     91        0.0079  0.0147\n",
            "     92        \u001b[36m0.0071\u001b[0m  0.0152\n",
            "     93        0.0078  0.0119\n",
            "     94        \u001b[36m0.0071\u001b[0m  0.0124\n",
            "     95        0.0077  0.0127\n",
            "     96        0.0081  0.0133\n",
            "     97        0.0076  0.0136\n",
            "     98        \u001b[36m0.0071\u001b[0m  0.0122\n",
            "     99        0.0076  0.0131\n",
            "    100        0.0074  0.0230\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1856\u001b[0m  0.0136\n",
            "      2        \u001b[36m0.1546\u001b[0m  0.0110\n",
            "      3        \u001b[36m0.1314\u001b[0m  0.0182\n",
            "      4        \u001b[36m0.1170\u001b[0m  0.0124\n",
            "      5        \u001b[36m0.1051\u001b[0m  0.0112\n",
            "      6        \u001b[36m0.0967\u001b[0m  0.0114\n",
            "      7        \u001b[36m0.0887\u001b[0m  0.0151\n",
            "      8        \u001b[36m0.0817\u001b[0m  0.0151\n",
            "      9        \u001b[36m0.0769\u001b[0m  0.0144\n",
            "     10        \u001b[36m0.0705\u001b[0m  0.0115\n",
            "     11        \u001b[36m0.0661\u001b[0m  0.0114\n",
            "     12        \u001b[36m0.0615\u001b[0m  0.0181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0570\u001b[0m  0.0145\n",
            "     14        \u001b[36m0.0534\u001b[0m  0.0128\n",
            "     15        \u001b[36m0.0508\u001b[0m  0.0133\n",
            "     16        \u001b[36m0.0476\u001b[0m  0.0116\n",
            "     17        \u001b[36m0.0452\u001b[0m  0.0115\n",
            "     18        \u001b[36m0.0425\u001b[0m  0.0145\n",
            "     19        \u001b[36m0.0397\u001b[0m  0.0137\n",
            "     20        \u001b[36m0.0381\u001b[0m  0.0134\n",
            "     21        \u001b[36m0.0357\u001b[0m  0.0113\n",
            "     22        \u001b[36m0.0338\u001b[0m  0.0114\n",
            "     23        \u001b[36m0.0322\u001b[0m  0.0153\n",
            "     24        \u001b[36m0.0306\u001b[0m  0.0123\n",
            "     25        \u001b[36m0.0291\u001b[0m  0.0134\n",
            "     26        \u001b[36m0.0273\u001b[0m  0.0123\n",
            "     27        \u001b[36m0.0264\u001b[0m  0.0109\n",
            "     28        \u001b[36m0.0250\u001b[0m  0.0147\n",
            "     29        \u001b[36m0.0238\u001b[0m  0.0142\n",
            "     30        \u001b[36m0.0228\u001b[0m  0.0124\n",
            "     31        \u001b[36m0.0223\u001b[0m  0.0114\n",
            "     32        \u001b[36m0.0209\u001b[0m  0.0119\n",
            "     33        \u001b[36m0.0199\u001b[0m  0.0146\n",
            "     34        \u001b[36m0.0195\u001b[0m  0.0131\n",
            "     35        \u001b[36m0.0186\u001b[0m  0.0139\n",
            "     36        \u001b[36m0.0173\u001b[0m  0.0125\n",
            "     37        \u001b[36m0.0171\u001b[0m  0.0110\n",
            "     38        \u001b[36m0.0163\u001b[0m  0.0214\n",
            "     39        \u001b[36m0.0159\u001b[0m  0.0125\n",
            "     40        \u001b[36m0.0152\u001b[0m  0.0126\n",
            "     41        \u001b[36m0.0150\u001b[0m  0.0117\n",
            "     42        \u001b[36m0.0142\u001b[0m  0.0112\n",
            "     43        \u001b[36m0.0138\u001b[0m  0.0154\n",
            "     44        \u001b[36m0.0132\u001b[0m  0.0147\n",
            "     45        \u001b[36m0.0127\u001b[0m  0.0132\n",
            "     46        \u001b[36m0.0125\u001b[0m  0.0113\n",
            "     47        \u001b[36m0.0119\u001b[0m  0.0113\n",
            "     48        \u001b[36m0.0116\u001b[0m  0.0172\n",
            "     49        \u001b[36m0.0112\u001b[0m  0.0121\n",
            "     50        \u001b[36m0.0108\u001b[0m  0.0124\n",
            "     51        \u001b[36m0.0107\u001b[0m  0.0113\n",
            "     52        \u001b[36m0.0100\u001b[0m  0.0112\n",
            "     53        0.0101  0.0137\n",
            "     54        0.0106  0.0147\n",
            "     55        \u001b[36m0.0097\u001b[0m  0.0127\n",
            "     56        0.0097  0.0113\n",
            "     57        \u001b[36m0.0090\u001b[0m  0.0112\n",
            "     58        0.0090  0.0150\n",
            "     59        0.0090  0.0124\n",
            "     60        \u001b[36m0.0089\u001b[0m  0.0119\n",
            "     61        \u001b[36m0.0089\u001b[0m  0.0114\n",
            "     62        \u001b[36m0.0083\u001b[0m  0.0118\n",
            "     63        \u001b[36m0.0082\u001b[0m  0.0152\n",
            "     64        \u001b[36m0.0081\u001b[0m  0.0141\n",
            "     65        \u001b[36m0.0078\u001b[0m  0.0131\n",
            "     66        0.0079  0.0113\n",
            "     67        0.0079  0.0112\n",
            "     68        \u001b[36m0.0076\u001b[0m  0.0155\n",
            "     69        \u001b[36m0.0076\u001b[0m  0.0125\n",
            "     70        \u001b[36m0.0072\u001b[0m  0.0132\n",
            "     71        0.0074  0.0171\n",
            "     72        0.0072  0.0180\n",
            "     73        0.0072  0.0171\n",
            "     74        \u001b[36m0.0069\u001b[0m  0.0128\n",
            "     75        0.0069  0.0111\n",
            "     76        \u001b[36m0.0067\u001b[0m  0.0110\n",
            "     77        0.0071  0.0143\n",
            "     78        0.0069  0.0132\n",
            "     79        0.0068  0.0142\n",
            "     80        \u001b[36m0.0066\u001b[0m  0.0131\n",
            "     81        \u001b[36m0.0064\u001b[0m  0.0129\n",
            "     82        0.0067  0.0154\n",
            "     83        \u001b[36m0.0062\u001b[0m  0.0122\n",
            "     84        0.0062  0.0161\n",
            "     85        0.0063  0.0215\n",
            "     86        0.0064  0.0219\n",
            "     87        0.0062  0.0165\n",
            "     88        \u001b[36m0.0060\u001b[0m  0.0160\n",
            "     89        0.0063  0.0169\n",
            "     90        \u001b[36m0.0060\u001b[0m  0.0173\n",
            "     91        0.0063  0.0165\n",
            "     92        \u001b[36m0.0059\u001b[0m  0.0191\n",
            "     93        \u001b[36m0.0058\u001b[0m  0.0177\n",
            "     94        \u001b[36m0.0056\u001b[0m  0.0207\n",
            "     95        0.0057  0.0220\n",
            "     96        0.0058  0.0140\n",
            "     97        0.0058  0.0144\n",
            "     98        \u001b[36m0.0053\u001b[0m  0.0141\n",
            "     99        \u001b[36m0.0052\u001b[0m  0.0140\n",
            "    100        0.0055  0.0155\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1530\u001b[0m  0.0123\n",
            "      2        \u001b[36m0.0986\u001b[0m  0.0086\n",
            "      3        \u001b[36m0.0793\u001b[0m  0.0084\n",
            "      4        \u001b[36m0.0637\u001b[0m  0.0086\n",
            "      5        \u001b[36m0.0529\u001b[0m  0.0086\n",
            "      6        \u001b[36m0.0466\u001b[0m  0.0085\n",
            "      7        \u001b[36m0.0380\u001b[0m  0.0082\n",
            "      8        \u001b[36m0.0351\u001b[0m  0.0087\n",
            "      9        \u001b[36m0.0309\u001b[0m  0.0084\n",
            "     10        \u001b[36m0.0271\u001b[0m  0.0086\n",
            "     11        \u001b[36m0.0246\u001b[0m  0.0091\n",
            "     12        \u001b[36m0.0222\u001b[0m  0.0102\n",
            "     13        \u001b[36m0.0196\u001b[0m  0.0092\n",
            "     14        \u001b[36m0.0178\u001b[0m  0.0117\n",
            "     15        \u001b[36m0.0174\u001b[0m  0.0087\n",
            "     16        \u001b[36m0.0155\u001b[0m  0.0107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     17        \u001b[36m0.0143\u001b[0m  0.0088\n",
            "     18        \u001b[36m0.0134\u001b[0m  0.0084\n",
            "     19        \u001b[36m0.0127\u001b[0m  0.0079\n",
            "     20        \u001b[36m0.0116\u001b[0m  0.0086\n",
            "     21        0.0116  0.0087\n",
            "     22        \u001b[36m0.0102\u001b[0m  0.0080\n",
            "     23        \u001b[36m0.0096\u001b[0m  0.0086\n",
            "     24        \u001b[36m0.0089\u001b[0m  0.0085\n",
            "     25        0.0103  0.0079\n",
            "     26        0.0092  0.0086\n",
            "     27        \u001b[36m0.0080\u001b[0m  0.0083\n",
            "     28        \u001b[36m0.0073\u001b[0m  0.0085\n",
            "     29        0.0077  0.0081\n",
            "     30        \u001b[36m0.0072\u001b[0m  0.0092\n",
            "     31        \u001b[36m0.0069\u001b[0m  0.0093\n",
            "     32        \u001b[36m0.0064\u001b[0m  0.0090\n",
            "     33        0.0067  0.0108\n",
            "     34        \u001b[36m0.0060\u001b[0m  0.0123\n",
            "     35        \u001b[36m0.0058\u001b[0m  0.0119\n",
            "     36        \u001b[36m0.0055\u001b[0m  0.0105\n",
            "     37        0.0057  0.0088\n",
            "     38        \u001b[36m0.0053\u001b[0m  0.0085\n",
            "     39        \u001b[36m0.0053\u001b[0m  0.0098\n",
            "     40        \u001b[36m0.0050\u001b[0m  0.0079\n",
            "     41        \u001b[36m0.0048\u001b[0m  0.0088\n",
            "     42        \u001b[36m0.0043\u001b[0m  0.0100\n",
            "     43        0.0050  0.0084\n",
            "     44        0.0043  0.0131\n",
            "     45        \u001b[36m0.0042\u001b[0m  0.0085\n",
            "     46        0.0044  0.0117\n",
            "     47        0.0045  0.0127\n",
            "     48        \u001b[36m0.0039\u001b[0m  0.0128\n",
            "     49        \u001b[36m0.0034\u001b[0m  0.0136\n",
            "     50        0.0039  0.0115\n",
            "     51        0.0040  0.0086\n",
            "     52        0.0034  0.0085\n",
            "     53        0.0037  0.0125\n",
            "     54        0.0038  0.0114\n",
            "     55        \u001b[36m0.0033\u001b[0m  0.0088\n",
            "     56        \u001b[36m0.0031\u001b[0m  0.0108\n",
            "     57        0.0034  0.0088\n",
            "     58        0.0034  0.0095\n",
            "     59        0.0036  0.0093\n",
            "     60        0.0035  0.0084\n",
            "     61        \u001b[36m0.0030\u001b[0m  0.0086\n",
            "     62        0.0031  0.0078\n",
            "     63        0.0031  0.0082\n",
            "     64        \u001b[36m0.0030\u001b[0m  0.0082\n",
            "     65        \u001b[36m0.0029\u001b[0m  0.0101\n",
            "     66        0.0030  0.0106\n",
            "     67        0.0032  0.0086\n",
            "     68        0.0031  0.0110\n",
            "     69        \u001b[36m0.0026\u001b[0m  0.0088\n",
            "     70        0.0031  0.0085\n",
            "     71        \u001b[36m0.0026\u001b[0m  0.0084\n",
            "     72        0.0029  0.0104\n",
            "     73        0.0029  0.0084\n",
            "     74        0.0027  0.0084\n",
            "     75        \u001b[36m0.0025\u001b[0m  0.0092\n",
            "     76        0.0025  0.0086\n",
            "     77        0.0030  0.0081\n",
            "     78        \u001b[36m0.0024\u001b[0m  0.0085\n",
            "     79        0.0027  0.0082\n",
            "     80        0.0025  0.0081\n",
            "     81        0.0024  0.0124\n",
            "     82        0.0026  0.0096\n",
            "     83        \u001b[36m0.0023\u001b[0m  0.0113\n",
            "     84        0.0025  0.0083\n",
            "     85        0.0025  0.0083\n",
            "     86        0.0026  0.0083\n",
            "     87        0.0025  0.0082\n",
            "     88        0.0025  0.0083\n",
            "     89        0.0026  0.0118\n",
            "     90        0.0024  0.0100\n",
            "     91        \u001b[36m0.0021\u001b[0m  0.0117\n",
            "     92        0.0023  0.0130\n",
            "     93        0.0022  0.0092\n",
            "     94        0.0024  0.0109\n",
            "     95        0.0023  0.0091\n",
            "     96        0.0024  0.0114\n",
            "     97        0.0023  0.0083\n",
            "     98        0.0022  0.0097\n",
            "     99        0.0024  0.0082\n",
            "    100        \u001b[36m0.0021\u001b[0m  0.0092\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1824\u001b[0m  0.0224\n",
            "      2        \u001b[36m0.1242\u001b[0m  0.0168\n",
            "      3        \u001b[36m0.0991\u001b[0m  0.0164\n",
            "      4        \u001b[36m0.0818\u001b[0m  0.0170\n",
            "      5        \u001b[36m0.0694\u001b[0m  0.0204\n",
            "      6        \u001b[36m0.0608\u001b[0m  0.0170\n",
            "      7        \u001b[36m0.0532\u001b[0m  0.0162\n",
            "      8        \u001b[36m0.0457\u001b[0m  0.0163\n",
            "      9        \u001b[36m0.0411\u001b[0m  0.0161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     10        \u001b[36m0.0360\u001b[0m  0.0162\n",
            "     11        \u001b[36m0.0311\u001b[0m  0.0161\n",
            "     12        \u001b[36m0.0298\u001b[0m  0.0159\n",
            "     13        \u001b[36m0.0269\u001b[0m  0.0160\n",
            "     14        \u001b[36m0.0248\u001b[0m  0.0162\n",
            "     15        \u001b[36m0.0229\u001b[0m  0.0161\n",
            "     16        \u001b[36m0.0195\u001b[0m  0.0165\n",
            "     17        \u001b[36m0.0188\u001b[0m  0.0168\n",
            "     18        \u001b[36m0.0165\u001b[0m  0.0173\n",
            "     19        \u001b[36m0.0161\u001b[0m  0.0209\n",
            "     20        \u001b[36m0.0152\u001b[0m  0.0161\n",
            "     21        \u001b[36m0.0143\u001b[0m  0.0209\n",
            "     22        \u001b[36m0.0137\u001b[0m  0.0156\n",
            "     23        \u001b[36m0.0127\u001b[0m  0.0164\n",
            "     24        \u001b[36m0.0125\u001b[0m  0.0179\n",
            "     25        \u001b[36m0.0115\u001b[0m  0.0189\n",
            "     26        \u001b[36m0.0112\u001b[0m  0.0175\n",
            "     27        \u001b[36m0.0112\u001b[0m  0.0181\n",
            "     28        \u001b[36m0.0107\u001b[0m  0.0186\n",
            "     29        \u001b[36m0.0097\u001b[0m  0.0165\n",
            "     30        0.0105  0.0196\n",
            "     31        0.0104  0.0163\n",
            "     32        \u001b[36m0.0090\u001b[0m  0.0171\n",
            "     33        \u001b[36m0.0089\u001b[0m  0.0179\n",
            "     34        \u001b[36m0.0089\u001b[0m  0.0157\n",
            "     35        \u001b[36m0.0083\u001b[0m  0.0160\n",
            "     36        \u001b[36m0.0082\u001b[0m  0.0160\n",
            "     37        \u001b[36m0.0080\u001b[0m  0.0158\n",
            "     38        \u001b[36m0.0079\u001b[0m  0.0175\n",
            "     39        0.0080  0.0166\n",
            "     40        \u001b[36m0.0078\u001b[0m  0.0158\n",
            "     41        \u001b[36m0.0070\u001b[0m  0.0167\n",
            "     42        0.0075  0.0164\n",
            "     43        0.0074  0.0169\n",
            "     44        \u001b[36m0.0068\u001b[0m  0.0169\n",
            "     45        0.0070  0.0173\n",
            "     46        0.0074  0.0160\n",
            "     47        \u001b[36m0.0062\u001b[0m  0.0168\n",
            "     48        0.0066  0.0170\n",
            "     49        0.0069  0.0167\n",
            "     50        0.0065  0.0159\n",
            "     51        0.0066  0.0164\n",
            "     52        0.0063  0.0160\n",
            "     53        0.0066  0.0182\n",
            "     54        \u001b[36m0.0059\u001b[0m  0.0204\n",
            "     55        0.0062  0.0169\n",
            "     56        \u001b[36m0.0058\u001b[0m  0.0194\n",
            "     57        \u001b[36m0.0052\u001b[0m  0.0235\n",
            "     58        0.0056  0.0191\n",
            "     59        0.0054  0.0209\n",
            "     60        0.0055  0.0190\n",
            "     61        0.0053  0.0169\n",
            "     62        0.0059  0.0188\n",
            "     63        0.0053  0.0201\n",
            "     64        0.0053  0.0203\n",
            "     65        0.0056  0.0171\n",
            "     66        0.0054  0.0172\n",
            "     67        \u001b[36m0.0051\u001b[0m  0.0205\n",
            "     68        \u001b[36m0.0049\u001b[0m  0.0168\n",
            "     69        0.0051  0.0212\n",
            "     70        0.0049  0.0166\n",
            "     71        \u001b[36m0.0049\u001b[0m  0.0259\n",
            "     72        0.0049  0.0193\n",
            "     73        0.0050  0.0241\n",
            "     74        \u001b[36m0.0048\u001b[0m  0.0192\n",
            "     75        \u001b[36m0.0045\u001b[0m  0.0202\n",
            "     76        0.0047  0.0196\n",
            "     77        0.0046  0.0195\n",
            "     78        0.0045  0.0233\n",
            "     79        0.0047  0.0194\n",
            "     80        \u001b[36m0.0044\u001b[0m  0.0190\n",
            "     81        0.0045  0.0188\n",
            "     82        \u001b[36m0.0044\u001b[0m  0.0238\n",
            "     83        0.0045  0.0190\n",
            "     84        0.0047  0.0201\n",
            "     85        0.0047  0.0180\n",
            "     86        0.0045  0.0179\n",
            "     87        0.0050  0.0185\n",
            "     88        0.0050  0.0176\n",
            "     89        \u001b[36m0.0041\u001b[0m  0.0183\n",
            "     90        0.0045  0.0184\n",
            "     91        0.0045  0.0184\n",
            "     92        0.0046  0.0256\n",
            "     93        0.0045  0.0187\n",
            "     94        0.0045  0.0226\n",
            "     95        0.0047  0.0210\n",
            "     96        0.0041  0.0173\n",
            "     97        0.0041  0.0161\n",
            "     98        \u001b[36m0.0040\u001b[0m  0.0172\n",
            "     99        0.0043  0.0166\n",
            "    100        0.0042  0.0216\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1641\u001b[0m  0.0195\n",
            "      2        \u001b[36m0.1044\u001b[0m  0.0154\n",
            "      3        \u001b[36m0.0775\u001b[0m  0.0153\n",
            "      4        \u001b[36m0.0635\u001b[0m  0.0151\n",
            "      5        \u001b[36m0.0518\u001b[0m  0.0130\n",
            "      6        \u001b[36m0.0431\u001b[0m  0.0138\n",
            "      7        \u001b[36m0.0366\u001b[0m  0.0205\n",
            "      8        \u001b[36m0.0312\u001b[0m  0.0144\n",
            "      9        \u001b[36m0.0280\u001b[0m  0.0146\n",
            "     10        \u001b[36m0.0246\u001b[0m  0.0146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0217\u001b[0m  0.0155\n",
            "     12        \u001b[36m0.0202\u001b[0m  0.0170\n",
            "     13        \u001b[36m0.0184\u001b[0m  0.0153\n",
            "     14        \u001b[36m0.0166\u001b[0m  0.0135\n",
            "     15        \u001b[36m0.0152\u001b[0m  0.0145\n",
            "     16        \u001b[36m0.0141\u001b[0m  0.0168\n",
            "     17        \u001b[36m0.0133\u001b[0m  0.0144\n",
            "     18        \u001b[36m0.0126\u001b[0m  0.0130\n",
            "     19        \u001b[36m0.0118\u001b[0m  0.0143\n",
            "     20        0.0118  0.0167\n",
            "     21        \u001b[36m0.0105\u001b[0m  0.0152\n",
            "     22        \u001b[36m0.0100\u001b[0m  0.0165\n",
            "     23        \u001b[36m0.0097\u001b[0m  0.0152\n",
            "     24        \u001b[36m0.0095\u001b[0m  0.0133\n",
            "     25        0.0095  0.0151\n",
            "     26        \u001b[36m0.0088\u001b[0m  0.0180\n",
            "     27        \u001b[36m0.0085\u001b[0m  0.0163\n",
            "     28        \u001b[36m0.0081\u001b[0m  0.0149\n",
            "     29        0.0082  0.0133\n",
            "     30        \u001b[36m0.0078\u001b[0m  0.0143\n",
            "     31        \u001b[36m0.0073\u001b[0m  0.0166\n",
            "     32        0.0073  0.0146\n",
            "     33        \u001b[36m0.0071\u001b[0m  0.0133\n",
            "     34        \u001b[36m0.0069\u001b[0m  0.0141\n",
            "     35        \u001b[36m0.0066\u001b[0m  0.0171\n",
            "     36        \u001b[36m0.0065\u001b[0m  0.0198\n",
            "     37        0.0067  0.0212\n",
            "     38        0.0066  0.0174\n",
            "     39        \u001b[36m0.0062\u001b[0m  0.0152\n",
            "     40        0.0064  0.0133\n",
            "     41        \u001b[36m0.0059\u001b[0m  0.0144\n",
            "     42        \u001b[36m0.0057\u001b[0m  0.0165\n",
            "     43        \u001b[36m0.0055\u001b[0m  0.0146\n",
            "     44        0.0056  0.0131\n",
            "     45        0.0056  0.0136\n",
            "     46        \u001b[36m0.0052\u001b[0m  0.0187\n",
            "     47        0.0057  0.0146\n",
            "     48        0.0054  0.0153\n",
            "     49        0.0055  0.0154\n",
            "     50        0.0057  0.0136\n",
            "     51        \u001b[36m0.0050\u001b[0m  0.0148\n",
            "     52        0.0050  0.0152\n",
            "     53        0.0052  0.0156\n",
            "     54        \u001b[36m0.0049\u001b[0m  0.0160\n",
            "     55        0.0051  0.0131\n",
            "     56        \u001b[36m0.0048\u001b[0m  0.0167\n",
            "     57        \u001b[36m0.0047\u001b[0m  0.0151\n",
            "     58        \u001b[36m0.0047\u001b[0m  0.0154\n",
            "     59        0.0048  0.0130\n",
            "     60        0.0050  0.0143\n",
            "     61        0.0049  0.0159\n",
            "     62        \u001b[36m0.0044\u001b[0m  0.0169\n",
            "     63        0.0047  0.0140\n",
            "     64        0.0048  0.0150\n",
            "     65        \u001b[36m0.0042\u001b[0m  0.0156\n",
            "     66        \u001b[36m0.0042\u001b[0m  0.0156\n",
            "     67        0.0044  0.0158\n",
            "     68        0.0045  0.0133\n",
            "     69        0.0045  0.0142\n",
            "     70        \u001b[36m0.0038\u001b[0m  0.0158\n",
            "     71        0.0044  0.0151\n",
            "     72        0.0039  0.0159\n",
            "     73        0.0043  0.0150\n",
            "     74        0.0041  0.0148\n",
            "     75        0.0042  0.0154\n",
            "     76        0.0043  0.0156\n",
            "     77        \u001b[36m0.0037\u001b[0m  0.0155\n",
            "     78        0.0037  0.0132\n",
            "     79        \u001b[36m0.0037\u001b[0m  0.0148\n",
            "     80        0.0038  0.0159\n",
            "     81        0.0042  0.0149\n",
            "     82        0.0038  0.0152\n",
            "     83        \u001b[36m0.0036\u001b[0m  0.0131\n",
            "     84        0.0038  0.0139\n",
            "     85        0.0036  0.0175\n",
            "     86        \u001b[36m0.0036\u001b[0m  0.0150\n",
            "     87        0.0036  0.0132\n",
            "     88        \u001b[36m0.0036\u001b[0m  0.0137\n",
            "     89        0.0037  0.0168\n",
            "     90        0.0036  0.0168\n",
            "     91        0.0038  0.0174\n",
            "     92        0.0036  0.0130\n",
            "     93        0.0036  0.0164\n",
            "     94        \u001b[36m0.0034\u001b[0m  0.0162\n",
            "     95        0.0034  0.0150\n",
            "     96        \u001b[36m0.0034\u001b[0m  0.0147\n",
            "     97        0.0037  0.0150\n",
            "     98        0.0037  0.0148\n",
            "     99        \u001b[36m0.0033\u001b[0m  0.0150\n",
            "    100        \u001b[36m0.0033\u001b[0m  0.0181\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1610\u001b[0m  0.0183\n",
            "      2        \u001b[36m0.1348\u001b[0m  0.0075\n",
            "      3        \u001b[36m0.1188\u001b[0m  0.0074\n",
            "      4        \u001b[36m0.1020\u001b[0m  0.0088\n",
            "      5        \u001b[36m0.0890\u001b[0m  0.0069\n",
            "      6        \u001b[36m0.0798\u001b[0m  0.0058\n",
            "      7        \u001b[36m0.0704\u001b[0m  0.0053\n",
            "      8        \u001b[36m0.0696\u001b[0m  0.0054\n",
            "      9        \u001b[36m0.0624\u001b[0m  0.0062\n",
            "     10        \u001b[36m0.0571\u001b[0m  0.0072\n",
            "     11        \u001b[36m0.0552\u001b[0m  0.0071\n",
            "     12        \u001b[36m0.0512\u001b[0m  0.0068\n",
            "     13        \u001b[36m0.0469\u001b[0m  0.0059\n",
            "     14        \u001b[36m0.0456\u001b[0m  0.0057\n",
            "     15        \u001b[36m0.0417\u001b[0m  0.0056\n",
            "     16        \u001b[36m0.0401\u001b[0m  0.0080\n",
            "     17        \u001b[36m0.0389\u001b[0m  0.0068\n",
            "     18        \u001b[36m0.0366\u001b[0m  0.0077\n",
            "     19        \u001b[36m0.0338\u001b[0m  0.0070\n",
            "     20        0.0349  0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     21        \u001b[36m0.0324\u001b[0m  0.0065\n",
            "     22        \u001b[36m0.0320\u001b[0m  0.0057\n",
            "     23        \u001b[36m0.0289\u001b[0m  0.0064\n",
            "     24        \u001b[36m0.0272\u001b[0m  0.0069\n",
            "     25        \u001b[36m0.0261\u001b[0m  0.0069\n",
            "     26        \u001b[36m0.0254\u001b[0m  0.0070\n",
            "     27        \u001b[36m0.0250\u001b[0m  0.0070\n",
            "     28        \u001b[36m0.0235\u001b[0m  0.0070\n",
            "     29        \u001b[36m0.0227\u001b[0m  0.0057\n",
            "     30        \u001b[36m0.0214\u001b[0m  0.0068\n",
            "     31        \u001b[36m0.0203\u001b[0m  0.0079\n",
            "     32        \u001b[36m0.0203\u001b[0m  0.0063\n",
            "     33        \u001b[36m0.0193\u001b[0m  0.0071\n",
            "     34        \u001b[36m0.0183\u001b[0m  0.0070\n",
            "     35        \u001b[36m0.0171\u001b[0m  0.0070\n",
            "     36        0.0180  0.0079\n",
            "     37        0.0182  0.0057\n",
            "     38        0.0176  0.0065\n",
            "     39        \u001b[36m0.0152\u001b[0m  0.0070\n",
            "     40        0.0155  0.0066\n",
            "     41        \u001b[36m0.0146\u001b[0m  0.0069\n",
            "     42        \u001b[36m0.0140\u001b[0m  0.0068\n",
            "     43        0.0144  0.0069\n",
            "     44        0.0146  0.0069\n",
            "     45        \u001b[36m0.0128\u001b[0m  0.0091\n",
            "     46        0.0138  0.0065\n",
            "     47        0.0135  0.0056\n",
            "     48        0.0130  0.0070\n",
            "     49        0.0129  0.0068\n",
            "     50        \u001b[36m0.0112\u001b[0m  0.0070\n",
            "     51        0.0113  0.0071\n",
            "     52        \u001b[36m0.0107\u001b[0m  0.0072\n",
            "     53        0.0117  0.0053\n",
            "     54        0.0108  0.0055\n",
            "     55        0.0108  0.0077\n",
            "     56        \u001b[36m0.0095\u001b[0m  0.0079\n",
            "     57        0.0107  0.0072\n",
            "     58        0.0105  0.0071\n",
            "     59        0.0103  0.0076\n",
            "     60        0.0096  0.0078\n",
            "     61        0.0102  0.0076\n",
            "     62        \u001b[36m0.0095\u001b[0m  0.0062\n",
            "     63        \u001b[36m0.0093\u001b[0m  0.0053\n",
            "     64        \u001b[36m0.0090\u001b[0m  0.0053\n",
            "     65        0.0095  0.0073\n",
            "     66        \u001b[36m0.0087\u001b[0m  0.0063\n",
            "     67        \u001b[36m0.0087\u001b[0m  0.0070\n",
            "     68        \u001b[36m0.0084\u001b[0m  0.0078\n",
            "     69        0.0086  0.0073\n",
            "     70        \u001b[36m0.0082\u001b[0m  0.0074\n",
            "     71        0.0094  0.0073\n",
            "     72        \u001b[36m0.0078\u001b[0m  0.0073\n",
            "     73        0.0084  0.0073\n",
            "     74        \u001b[36m0.0076\u001b[0m  0.0073\n",
            "     75        0.0078  0.0072\n",
            "     76        0.0078  0.0073\n",
            "     77        0.0079  0.0075\n",
            "     78        0.0080  0.0069\n",
            "     79        \u001b[36m0.0075\u001b[0m  0.0062\n",
            "     80        \u001b[36m0.0074\u001b[0m  0.0055\n",
            "     81        \u001b[36m0.0072\u001b[0m  0.0053\n",
            "     82        \u001b[36m0.0071\u001b[0m  0.0056\n",
            "     83        \u001b[36m0.0070\u001b[0m  0.0065\n",
            "     84        \u001b[36m0.0070\u001b[0m  0.0071\n",
            "     85        \u001b[36m0.0069\u001b[0m  0.0071\n",
            "     86        \u001b[36m0.0067\u001b[0m  0.0071\n",
            "     87        \u001b[36m0.0065\u001b[0m  0.0069\n",
            "     88        0.0071  0.0065\n",
            "     89        0.0066  0.0078\n",
            "     90        0.0069  0.0073\n",
            "     91        \u001b[36m0.0062\u001b[0m  0.0079\n",
            "     92        0.0071  0.0068\n",
            "     93        0.0065  0.0070\n",
            "     94        0.0066  0.0070\n",
            "     95        0.0065  0.0070\n",
            "     96        \u001b[36m0.0060\u001b[0m  0.0061\n",
            "     97        \u001b[36m0.0058\u001b[0m  0.0057\n",
            "     98        0.0062  0.0057\n",
            "     99        \u001b[36m0.0057\u001b[0m  0.0062\n",
            "    100        0.0063  0.0089\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1715\u001b[0m  0.0223\n",
            "      2        \u001b[36m0.1308\u001b[0m  0.0149\n",
            "      3        \u001b[36m0.1029\u001b[0m  0.0119\n",
            "      4        \u001b[36m0.0844\u001b[0m  0.0127\n",
            "      5        \u001b[36m0.0726\u001b[0m  0.0104\n",
            "      6        \u001b[36m0.0650\u001b[0m  0.0103\n",
            "      7        \u001b[36m0.0600\u001b[0m  0.0123\n",
            "      8        \u001b[36m0.0543\u001b[0m  0.0139\n",
            "      9        \u001b[36m0.0492\u001b[0m  0.0109\n",
            "     10        \u001b[36m0.0469\u001b[0m  0.0120\n",
            "     11        \u001b[36m0.0431\u001b[0m  0.0138\n",
            "     12        \u001b[36m0.0402\u001b[0m  0.0176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0365\u001b[0m  0.0199\n",
            "     14        \u001b[36m0.0348\u001b[0m  0.0122\n",
            "     15        \u001b[36m0.0340\u001b[0m  0.0126\n",
            "     16        \u001b[36m0.0306\u001b[0m  0.0144\n",
            "     17        \u001b[36m0.0285\u001b[0m  0.0141\n",
            "     18        \u001b[36m0.0273\u001b[0m  0.0108\n",
            "     19        \u001b[36m0.0248\u001b[0m  0.0102\n",
            "     20        \u001b[36m0.0241\u001b[0m  0.0133\n",
            "     21        \u001b[36m0.0230\u001b[0m  0.0133\n",
            "     22        \u001b[36m0.0208\u001b[0m  0.0137\n",
            "     23        \u001b[36m0.0206\u001b[0m  0.0112\n",
            "     24        \u001b[36m0.0194\u001b[0m  0.0103\n",
            "     25        \u001b[36m0.0193\u001b[0m  0.0138\n",
            "     26        \u001b[36m0.0185\u001b[0m  0.0133\n",
            "     27        \u001b[36m0.0175\u001b[0m  0.0123\n",
            "     28        \u001b[36m0.0174\u001b[0m  0.0120\n",
            "     29        \u001b[36m0.0164\u001b[0m  0.0101\n",
            "     30        \u001b[36m0.0163\u001b[0m  0.0108\n",
            "     31        \u001b[36m0.0158\u001b[0m  0.0147\n",
            "     32        \u001b[36m0.0148\u001b[0m  0.0135\n",
            "     33        \u001b[36m0.0147\u001b[0m  0.0116\n",
            "     34        \u001b[36m0.0139\u001b[0m  0.0106\n",
            "     35        \u001b[36m0.0136\u001b[0m  0.0110\n",
            "     36        \u001b[36m0.0131\u001b[0m  0.0131\n",
            "     37        0.0136  0.0134\n",
            "     38        \u001b[36m0.0130\u001b[0m  0.0134\n",
            "     39        \u001b[36m0.0128\u001b[0m  0.0133\n",
            "     40        \u001b[36m0.0125\u001b[0m  0.0124\n",
            "     41        \u001b[36m0.0123\u001b[0m  0.0101\n",
            "     42        \u001b[36m0.0114\u001b[0m  0.0101\n",
            "     43        0.0123  0.0127\n",
            "     44        \u001b[36m0.0111\u001b[0m  0.0136\n",
            "     45        \u001b[36m0.0106\u001b[0m  0.0123\n",
            "     46        0.0110  0.0126\n",
            "     47        0.0108  0.0100\n",
            "     48        \u001b[36m0.0104\u001b[0m  0.0103\n",
            "     49        0.0105  0.0134\n",
            "     50        \u001b[36m0.0101\u001b[0m  0.0132\n",
            "     51        \u001b[36m0.0096\u001b[0m  0.0130\n",
            "     52        0.0100  0.0125\n",
            "     53        \u001b[36m0.0095\u001b[0m  0.0102\n",
            "     54        0.0101  0.0103\n",
            "     55        \u001b[36m0.0089\u001b[0m  0.0132\n",
            "     56        0.0089  0.0139\n",
            "     57        \u001b[36m0.0088\u001b[0m  0.0126\n",
            "     58        \u001b[36m0.0087\u001b[0m  0.0118\n",
            "     59        0.0089  0.0138\n",
            "     60        \u001b[36m0.0084\u001b[0m  0.0101\n",
            "     61        0.0085  0.0101\n",
            "     62        \u001b[36m0.0081\u001b[0m  0.0127\n",
            "     63        0.0083  0.0132\n",
            "     64        \u001b[36m0.0080\u001b[0m  0.0117\n",
            "     65        0.0084  0.0128\n",
            "     66        0.0082  0.0145\n",
            "     67        \u001b[36m0.0076\u001b[0m  0.0129\n",
            "     68        \u001b[36m0.0074\u001b[0m  0.0103\n",
            "     69        0.0077  0.0106\n",
            "     70        \u001b[36m0.0072\u001b[0m  0.0133\n",
            "     71        0.0074  0.0123\n",
            "     72        0.0074  0.0115\n",
            "     73        \u001b[36m0.0072\u001b[0m  0.0134\n",
            "     74        0.0074  0.0102\n",
            "     75        \u001b[36m0.0072\u001b[0m  0.0104\n",
            "     76        \u001b[36m0.0070\u001b[0m  0.0160\n",
            "     77        0.0071  0.0149\n",
            "     78        0.0071  0.0125\n",
            "     79        \u001b[36m0.0069\u001b[0m  0.0120\n",
            "     80        0.0070  0.0104\n",
            "     81        0.0069  0.0101\n",
            "     82        0.0070  0.0119\n",
            "     83        \u001b[36m0.0068\u001b[0m  0.0135\n",
            "     84        \u001b[36m0.0065\u001b[0m  0.0135\n",
            "     85        0.0066  0.0128\n",
            "     86        0.0069  0.0102\n",
            "     87        \u001b[36m0.0062\u001b[0m  0.0101\n",
            "     88        0.0063  0.0130\n",
            "     89        0.0068  0.0136\n",
            "     90        \u001b[36m0.0062\u001b[0m  0.0143\n",
            "     91        \u001b[36m0.0060\u001b[0m  0.0146\n",
            "     92        0.0066  0.0217\n",
            "     93        0.0066  0.0101\n",
            "     94        0.0063  0.0116\n",
            "     95        \u001b[36m0.0060\u001b[0m  0.0143\n",
            "     96        0.0067  0.0131\n",
            "     97        \u001b[36m0.0059\u001b[0m  0.0123\n",
            "     98        0.0063  0.0120\n",
            "     99        \u001b[36m0.0059\u001b[0m  0.0121\n",
            "    100        \u001b[36m0.0058\u001b[0m  0.0122\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1581\u001b[0m  0.0156\n",
            "      2        \u001b[36m0.1205\u001b[0m  0.0127\n",
            "      3        \u001b[36m0.0962\u001b[0m  0.0141\n",
            "      4        \u001b[36m0.0814\u001b[0m  0.0148\n",
            "      5        \u001b[36m0.0710\u001b[0m  0.0110\n",
            "      6        \u001b[36m0.0628\u001b[0m  0.0109\n",
            "      7        \u001b[36m0.0568\u001b[0m  0.0122\n",
            "      8        \u001b[36m0.0510\u001b[0m  0.0141\n",
            "      9        \u001b[36m0.0464\u001b[0m  0.0136\n",
            "     10        \u001b[36m0.0431\u001b[0m  0.0110\n",
            "     11        \u001b[36m0.0394\u001b[0m  0.0126\n",
            "     12        \u001b[36m0.0366\u001b[0m  0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0342\u001b[0m  0.0152\n",
            "     14        \u001b[36m0.0319\u001b[0m  0.0143\n",
            "     15        \u001b[36m0.0289\u001b[0m  0.0122\n",
            "     16        \u001b[36m0.0266\u001b[0m  0.0112\n",
            "     17        \u001b[36m0.0252\u001b[0m  0.0116\n",
            "     18        \u001b[36m0.0246\u001b[0m  0.0156\n",
            "     19        \u001b[36m0.0233\u001b[0m  0.0137\n",
            "     20        \u001b[36m0.0224\u001b[0m  0.0127\n",
            "     21        \u001b[36m0.0209\u001b[0m  0.0110\n",
            "     22        \u001b[36m0.0191\u001b[0m  0.0111\n",
            "     23        \u001b[36m0.0182\u001b[0m  0.0141\n",
            "     24        \u001b[36m0.0177\u001b[0m  0.0142\n",
            "     25        \u001b[36m0.0175\u001b[0m  0.0127\n",
            "     26        \u001b[36m0.0162\u001b[0m  0.0110\n",
            "     27        \u001b[36m0.0156\u001b[0m  0.0110\n",
            "     28        \u001b[36m0.0145\u001b[0m  0.0144\n",
            "     29        \u001b[36m0.0145\u001b[0m  0.0144\n",
            "     30        \u001b[36m0.0140\u001b[0m  0.0127\n",
            "     31        \u001b[36m0.0130\u001b[0m  0.0108\n",
            "     32        \u001b[36m0.0130\u001b[0m  0.0112\n",
            "     33        \u001b[36m0.0120\u001b[0m  0.0150\n",
            "     34        \u001b[36m0.0119\u001b[0m  0.0126\n",
            "     35        \u001b[36m0.0113\u001b[0m  0.0127\n",
            "     36        \u001b[36m0.0109\u001b[0m  0.0111\n",
            "     37        0.0113  0.0108\n",
            "     38        \u001b[36m0.0103\u001b[0m  0.0139\n",
            "     39        \u001b[36m0.0101\u001b[0m  0.0143\n",
            "     40        \u001b[36m0.0097\u001b[0m  0.0126\n",
            "     41        0.0102  0.0108\n",
            "     42        0.0099  0.0115\n",
            "     43        0.0097  0.0148\n",
            "     44        \u001b[36m0.0091\u001b[0m  0.0134\n",
            "     45        0.0093  0.0127\n",
            "     46        \u001b[36m0.0089\u001b[0m  0.0141\n",
            "     47        \u001b[36m0.0088\u001b[0m  0.0123\n",
            "     48        \u001b[36m0.0087\u001b[0m  0.0154\n",
            "     49        \u001b[36m0.0084\u001b[0m  0.0121\n",
            "     50        \u001b[36m0.0081\u001b[0m  0.0110\n",
            "     51        \u001b[36m0.0081\u001b[0m  0.0154\n",
            "     52        \u001b[36m0.0078\u001b[0m  0.0130\n",
            "     53        \u001b[36m0.0077\u001b[0m  0.0110\n",
            "     54        \u001b[36m0.0076\u001b[0m  0.0109\n",
            "     55        0.0078  0.0136\n",
            "     56        \u001b[36m0.0074\u001b[0m  0.0149\n",
            "     57        0.0074  0.0137\n",
            "     58        \u001b[36m0.0070\u001b[0m  0.0126\n",
            "     59        \u001b[36m0.0069\u001b[0m  0.0126\n",
            "     60        0.0071  0.0129\n",
            "     61        \u001b[36m0.0068\u001b[0m  0.0110\n",
            "     62        0.0070  0.0110\n",
            "     63        0.0073  0.0154\n",
            "     64        0.0073  0.0199\n",
            "     65        \u001b[36m0.0066\u001b[0m  0.0217\n",
            "     66        \u001b[36m0.0063\u001b[0m  0.0140\n",
            "     67        0.0068  0.0121\n",
            "     68        0.0067  0.0110\n",
            "     69        \u001b[36m0.0060\u001b[0m  0.0113\n",
            "     70        0.0062  0.0139\n",
            "     71        0.0061  0.0143\n",
            "     72        0.0065  0.0128\n",
            "     73        \u001b[36m0.0056\u001b[0m  0.0111\n",
            "     74        0.0059  0.0110\n",
            "     75        0.0060  0.0148\n",
            "     76        0.0060  0.0138\n",
            "     77        0.0057  0.0119\n",
            "     78        0.0059  0.0109\n",
            "     79        \u001b[36m0.0055\u001b[0m  0.0110\n",
            "     80        \u001b[36m0.0054\u001b[0m  0.0150\n",
            "     81        0.0056  0.0141\n",
            "     82        0.0056  0.0119\n",
            "     83        \u001b[36m0.0054\u001b[0m  0.0130\n",
            "     84        \u001b[36m0.0053\u001b[0m  0.0122\n",
            "     85        0.0054  0.0124\n",
            "     86        \u001b[36m0.0052\u001b[0m  0.0145\n",
            "     87        0.0054  0.0127\n",
            "     88        0.0052  0.0139\n",
            "     89        0.0052  0.0124\n",
            "     90        \u001b[36m0.0050\u001b[0m  0.0110\n",
            "     91        0.0053  0.0109\n",
            "     92        \u001b[36m0.0047\u001b[0m  0.0140\n",
            "     93        0.0051  0.0139\n",
            "     94        0.0052  0.0123\n",
            "     95        0.0053  0.0125\n",
            "     96        0.0049  0.0108\n",
            "     97        0.0049  0.0109\n",
            "     98        0.0047  0.0151\n",
            "     99        0.0053  0.0144\n",
            "    100        0.0048  0.0125\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1607\u001b[0m  0.0118\n",
            "      2        \u001b[36m0.1047\u001b[0m  0.0101\n",
            "      3        \u001b[36m0.0822\u001b[0m  0.0105\n",
            "      4        \u001b[36m0.0699\u001b[0m  0.0086\n",
            "      5        \u001b[36m0.0579\u001b[0m  0.0073\n",
            "      6        \u001b[36m0.0511\u001b[0m  0.0069\n",
            "      7        \u001b[36m0.0434\u001b[0m  0.0069\n",
            "      8        \u001b[36m0.0398\u001b[0m  0.0071\n",
            "      9        \u001b[36m0.0351\u001b[0m  0.0089\n",
            "     10        \u001b[36m0.0327\u001b[0m  0.0085\n",
            "     11        \u001b[36m0.0278\u001b[0m  0.0086\n",
            "     12        \u001b[36m0.0256\u001b[0m  0.0091\n",
            "     13        \u001b[36m0.0240\u001b[0m  0.0070\n",
            "     14        \u001b[36m0.0223\u001b[0m  0.0082\n",
            "     15        \u001b[36m0.0198\u001b[0m  0.0094\n",
            "     16        \u001b[36m0.0185\u001b[0m  0.0083\n",
            "     17        \u001b[36m0.0171\u001b[0m  0.0079\n",
            "     18        \u001b[36m0.0155\u001b[0m  0.0070\n",
            "     19        \u001b[36m0.0139\u001b[0m  0.0067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     20        \u001b[36m0.0136\u001b[0m  0.0108\n",
            "     21        \u001b[36m0.0128\u001b[0m  0.0106\n",
            "     22        \u001b[36m0.0124\u001b[0m  0.0083\n",
            "     23        \u001b[36m0.0113\u001b[0m  0.0081\n",
            "     24        \u001b[36m0.0098\u001b[0m  0.0084\n",
            "     25        0.0099  0.0069\n",
            "     26        \u001b[36m0.0088\u001b[0m  0.0093\n",
            "     27        \u001b[36m0.0088\u001b[0m  0.0088\n",
            "     28        \u001b[36m0.0084\u001b[0m  0.0089\n",
            "     29        0.0085  0.0095\n",
            "     30        \u001b[36m0.0077\u001b[0m  0.0074\n",
            "     31        \u001b[36m0.0071\u001b[0m  0.0069\n",
            "     32        \u001b[36m0.0062\u001b[0m  0.0082\n",
            "     33        0.0069  0.0093\n",
            "     34        0.0067  0.0086\n",
            "     35        \u001b[36m0.0058\u001b[0m  0.0088\n",
            "     36        0.0060  0.0086\n",
            "     37        0.0061  0.0075\n",
            "     38        \u001b[36m0.0055\u001b[0m  0.0070\n",
            "     39        \u001b[36m0.0051\u001b[0m  0.0082\n",
            "     40        0.0051  0.0085\n",
            "     41        0.0053  0.0086\n",
            "     42        \u001b[36m0.0049\u001b[0m  0.0092\n",
            "     43        \u001b[36m0.0048\u001b[0m  0.0093\n",
            "     44        \u001b[36m0.0042\u001b[0m  0.0075\n",
            "     45        \u001b[36m0.0042\u001b[0m  0.0067\n",
            "     46        0.0045  0.0070\n",
            "     47        0.0042  0.0108\n",
            "     48        \u001b[36m0.0039\u001b[0m  0.0090\n",
            "     49        0.0040  0.0085\n",
            "     50        0.0042  0.0084\n",
            "     51        0.0040  0.0086\n",
            "     52        \u001b[36m0.0038\u001b[0m  0.0097\n",
            "     53        \u001b[36m0.0032\u001b[0m  0.0096\n",
            "     54        0.0036  0.0112\n",
            "     55        0.0035  0.0106\n",
            "     56        0.0034  0.0116\n",
            "     57        0.0039  0.0112\n",
            "     58        0.0034  0.0085\n",
            "     59        \u001b[36m0.0031\u001b[0m  0.0083\n",
            "     60        0.0035  0.0084\n",
            "     61        0.0034  0.0085\n",
            "     62        \u001b[36m0.0030\u001b[0m  0.0076\n",
            "     63        0.0033  0.0090\n",
            "     64        0.0032  0.0094\n",
            "     65        0.0033  0.0087\n",
            "     66        \u001b[36m0.0029\u001b[0m  0.0086\n",
            "     67        \u001b[36m0.0028\u001b[0m  0.0073\n",
            "     68        0.0029  0.0069\n",
            "     69        0.0031  0.0083\n",
            "     70        \u001b[36m0.0027\u001b[0m  0.0085\n",
            "     71        0.0030  0.0088\n",
            "     72        0.0030  0.0085\n",
            "     73        0.0030  0.0083\n",
            "     74        \u001b[36m0.0027\u001b[0m  0.0067\n",
            "     75        0.0029  0.0070\n",
            "     76        0.0027  0.0070\n",
            "     77        0.0028  0.0070\n",
            "     78        \u001b[36m0.0024\u001b[0m  0.0107\n",
            "     79        0.0027  0.0100\n",
            "     80        0.0028  0.0092\n",
            "     81        0.0026  0.0102\n",
            "     82        \u001b[36m0.0022\u001b[0m  0.0091\n",
            "     83        0.0026  0.0070\n",
            "     84        0.0025  0.0068\n",
            "     85        0.0025  0.0093\n",
            "     86        0.0027  0.0088\n",
            "     87        0.0027  0.0087\n",
            "     88        0.0026  0.0084\n",
            "     89        0.0025  0.0068\n",
            "     90        \u001b[36m0.0021\u001b[0m  0.0068\n",
            "     91        0.0022  0.0070\n",
            "     92        0.0026  0.0088\n",
            "     93        0.0025  0.0085\n",
            "     94        0.0024  0.0084\n",
            "     95        0.0024  0.0075\n",
            "     96        0.0023  0.0067\n",
            "     97        0.0023  0.0086\n",
            "     98        \u001b[36m0.0021\u001b[0m  0.0096\n",
            "     99        0.0024  0.0083\n",
            "    100        \u001b[36m0.0020\u001b[0m  0.0090\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1755\u001b[0m  0.0214\n",
            "      2        \u001b[36m0.1010\u001b[0m  0.0153\n",
            "      3        \u001b[36m0.0800\u001b[0m  0.0186\n",
            "      4        \u001b[36m0.0661\u001b[0m  0.0153\n",
            "      5        \u001b[36m0.0560\u001b[0m  0.0136\n",
            "      6        \u001b[36m0.0484\u001b[0m  0.0153\n",
            "      7        \u001b[36m0.0420\u001b[0m  0.0166\n",
            "      8        \u001b[36m0.0362\u001b[0m  0.0145\n",
            "      9        \u001b[36m0.0326\u001b[0m  0.0131\n",
            "     10        \u001b[36m0.0299\u001b[0m  0.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0264\u001b[0m  0.0180\n",
            "     12        \u001b[36m0.0241\u001b[0m  0.0147\n",
            "     13        \u001b[36m0.0221\u001b[0m  0.0157\n",
            "     14        \u001b[36m0.0207\u001b[0m  0.0132\n",
            "     15        \u001b[36m0.0186\u001b[0m  0.0155\n",
            "     16        \u001b[36m0.0176\u001b[0m  0.0158\n",
            "     17        \u001b[36m0.0163\u001b[0m  0.0148\n",
            "     18        \u001b[36m0.0152\u001b[0m  0.0133\n",
            "     19        \u001b[36m0.0140\u001b[0m  0.0161\n",
            "     20        \u001b[36m0.0137\u001b[0m  0.0157\n",
            "     21        \u001b[36m0.0132\u001b[0m  0.0173\n",
            "     22        \u001b[36m0.0124\u001b[0m  0.0130\n",
            "     23        \u001b[36m0.0119\u001b[0m  0.0163\n",
            "     24        \u001b[36m0.0113\u001b[0m  0.0149\n",
            "     25        \u001b[36m0.0105\u001b[0m  0.0165\n",
            "     26        \u001b[36m0.0103\u001b[0m  0.0132\n",
            "     27        \u001b[36m0.0098\u001b[0m  0.0159\n",
            "     28        \u001b[36m0.0094\u001b[0m  0.0160\n",
            "     29        \u001b[36m0.0093\u001b[0m  0.0142\n",
            "     30        \u001b[36m0.0089\u001b[0m  0.0132\n",
            "     31        0.0090  0.0139\n",
            "     32        \u001b[36m0.0082\u001b[0m  0.0157\n",
            "     33        \u001b[36m0.0079\u001b[0m  0.0142\n",
            "     34        0.0080  0.0163\n",
            "     35        0.0080  0.0168\n",
            "     36        \u001b[36m0.0073\u001b[0m  0.0266\n",
            "     37        0.0076  0.0145\n",
            "     38        0.0077  0.0147\n",
            "     39        \u001b[36m0.0071\u001b[0m  0.0153\n",
            "     40        0.0072  0.0130\n",
            "     41        \u001b[36m0.0069\u001b[0m  0.0140\n",
            "     42        \u001b[36m0.0067\u001b[0m  0.0163\n",
            "     43        \u001b[36m0.0066\u001b[0m  0.0149\n",
            "     44        0.0067  0.0145\n",
            "     45        \u001b[36m0.0060\u001b[0m  0.0131\n",
            "     46        0.0065  0.0131\n",
            "     47        \u001b[36m0.0059\u001b[0m  0.0187\n",
            "     48        \u001b[36m0.0058\u001b[0m  0.0140\n",
            "     49        0.0063  0.0148\n",
            "     50        0.0061  0.0144\n",
            "     51        \u001b[36m0.0057\u001b[0m  0.0161\n",
            "     52        \u001b[36m0.0054\u001b[0m  0.0178\n",
            "     53        0.0057  0.0147\n",
            "     54        0.0059  0.0130\n",
            "     55        \u001b[36m0.0054\u001b[0m  0.0138\n",
            "     56        0.0056  0.0168\n",
            "     57        0.0054  0.0146\n",
            "     58        0.0061  0.0151\n",
            "     59        \u001b[36m0.0054\u001b[0m  0.0134\n",
            "     60        \u001b[36m0.0053\u001b[0m  0.0136\n",
            "     61        0.0054  0.0176\n",
            "     62        0.0053  0.0142\n",
            "     63        0.0053  0.0147\n",
            "     64        \u001b[36m0.0051\u001b[0m  0.0133\n",
            "     65        \u001b[36m0.0050\u001b[0m  0.0145\n",
            "     66        \u001b[36m0.0050\u001b[0m  0.0200\n",
            "     67        \u001b[36m0.0047\u001b[0m  0.0156\n",
            "     68        0.0049  0.0133\n",
            "     69        0.0048  0.0142\n",
            "     70        0.0051  0.0170\n",
            "     71        \u001b[36m0.0046\u001b[0m  0.0147\n",
            "     72        0.0050  0.0131\n",
            "     73        0.0047  0.0137\n",
            "     74        \u001b[36m0.0044\u001b[0m  0.0187\n",
            "     75        0.0048  0.0145\n",
            "     76        0.0045  0.0149\n",
            "     77        0.0053  0.0148\n",
            "     78        0.0045  0.0131\n",
            "     79        0.0048  0.0140\n",
            "     80        0.0048  0.0171\n",
            "     81        0.0044  0.0166\n",
            "     82        \u001b[36m0.0043\u001b[0m  0.0154\n",
            "     83        0.0044  0.0132\n",
            "     84        0.0045  0.0144\n",
            "     85        0.0047  0.0163\n",
            "     86        \u001b[36m0.0039\u001b[0m  0.0150\n",
            "     87        0.0043  0.0132\n",
            "     88        0.0043  0.0151\n",
            "     89        \u001b[36m0.0038\u001b[0m  0.0163\n",
            "     90        0.0040  0.0145\n",
            "     91        0.0041  0.0154\n",
            "     92        0.0041  0.0159\n",
            "     93        0.0041  0.0132\n",
            "     94        0.0038  0.0145\n",
            "     95        0.0041  0.0154\n",
            "     96        0.0039  0.0144\n",
            "     97        0.0041  0.0132\n",
            "     98        0.0038  0.0132\n",
            "     99        \u001b[36m0.0036\u001b[0m  0.0227\n",
            "    100        0.0037  0.0185\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1532\u001b[0m  0.0180\n",
            "      2        \u001b[36m0.0853\u001b[0m  0.0150\n",
            "      3        \u001b[36m0.0668\u001b[0m  0.0163\n",
            "      4        \u001b[36m0.0516\u001b[0m  0.0152\n",
            "      5        \u001b[36m0.0429\u001b[0m  0.0138\n",
            "      6        \u001b[36m0.0355\u001b[0m  0.0163\n",
            "      7        \u001b[36m0.0290\u001b[0m  0.0167\n",
            "      8        \u001b[36m0.0258\u001b[0m  0.0152\n",
            "      9        \u001b[36m0.0230\u001b[0m  0.0138\n",
            "     10        \u001b[36m0.0198\u001b[0m  0.0152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0167\u001b[0m  0.0179\n",
            "     12        \u001b[36m0.0156\u001b[0m  0.0173\n",
            "     13        \u001b[36m0.0140\u001b[0m  0.0149\n",
            "     14        \u001b[36m0.0129\u001b[0m  0.0137\n",
            "     15        \u001b[36m0.0123\u001b[0m  0.0161\n",
            "     16        \u001b[36m0.0109\u001b[0m  0.0164\n",
            "     17        \u001b[36m0.0101\u001b[0m  0.0170\n",
            "     18        \u001b[36m0.0098\u001b[0m  0.0139\n",
            "     19        \u001b[36m0.0093\u001b[0m  0.0157\n",
            "     20        \u001b[36m0.0090\u001b[0m  0.0157\n",
            "     21        \u001b[36m0.0083\u001b[0m  0.0149\n",
            "     22        \u001b[36m0.0081\u001b[0m  0.0135\n",
            "     23        \u001b[36m0.0081\u001b[0m  0.0158\n",
            "     24        \u001b[36m0.0075\u001b[0m  0.0166\n",
            "     25        \u001b[36m0.0070\u001b[0m  0.0146\n",
            "     26        0.0076  0.0135\n",
            "     27        \u001b[36m0.0068\u001b[0m  0.0150\n",
            "     28        0.0068  0.0179\n",
            "     29        \u001b[36m0.0067\u001b[0m  0.0161\n",
            "     30        \u001b[36m0.0062\u001b[0m  0.0156\n",
            "     31        \u001b[36m0.0060\u001b[0m  0.0169\n",
            "     32        \u001b[36m0.0057\u001b[0m  0.0134\n",
            "     33        0.0058  0.0149\n",
            "     34        \u001b[36m0.0056\u001b[0m  0.0167\n",
            "     35        0.0057  0.0146\n",
            "     36        \u001b[36m0.0054\u001b[0m  0.0152\n",
            "     37        0.0055  0.0149\n",
            "     38        \u001b[36m0.0052\u001b[0m  0.0176\n",
            "     39        0.0053  0.0154\n",
            "     40        \u001b[36m0.0050\u001b[0m  0.0151\n",
            "     41        \u001b[36m0.0050\u001b[0m  0.0149\n",
            "     42        \u001b[36m0.0048\u001b[0m  0.0153\n",
            "     43        \u001b[36m0.0047\u001b[0m  0.0135\n",
            "     44        \u001b[36m0.0047\u001b[0m  0.0168\n",
            "     45        0.0048  0.0171\n",
            "     46        0.0047  0.0156\n",
            "     47        0.0051  0.0167\n",
            "     48        \u001b[36m0.0047\u001b[0m  0.0136\n",
            "     49        0.0050  0.0162\n",
            "     50        \u001b[36m0.0046\u001b[0m  0.0156\n",
            "     51        0.0047  0.0168\n",
            "     52        \u001b[36m0.0045\u001b[0m  0.0149\n",
            "     53        \u001b[36m0.0043\u001b[0m  0.0149\n",
            "     54        \u001b[36m0.0041\u001b[0m  0.0149\n",
            "     55        \u001b[36m0.0040\u001b[0m  0.0133\n",
            "     56        0.0041  0.0145\n",
            "     57        \u001b[36m0.0040\u001b[0m  0.0177\n",
            "     58        0.0041  0.0156\n",
            "     59        0.0041  0.0149\n",
            "     60        0.0042  0.0174\n",
            "     61        \u001b[36m0.0039\u001b[0m  0.0165\n",
            "     62        0.0043  0.0203\n",
            "     63        \u001b[36m0.0037\u001b[0m  0.0216\n",
            "     64        \u001b[36m0.0037\u001b[0m  0.0148\n",
            "     65        0.0039  0.0154\n",
            "     66        0.0038  0.0151\n",
            "     67        0.0039  0.0152\n",
            "     68        0.0040  0.0140\n",
            "     69        0.0040  0.0169\n",
            "     70        0.0040  0.0164\n",
            "     71        0.0037  0.0152\n",
            "     72        0.0040  0.0134\n",
            "     73        0.0038  0.0142\n",
            "     74        0.0038  0.0183\n",
            "     75        \u001b[36m0.0037\u001b[0m  0.0160\n",
            "     76        \u001b[36m0.0037\u001b[0m  0.0134\n",
            "     77        0.0038  0.0160\n",
            "     78        \u001b[36m0.0035\u001b[0m  0.0163\n",
            "     79        0.0036  0.0146\n",
            "     80        0.0036  0.0151\n",
            "     81        \u001b[36m0.0033\u001b[0m  0.0172\n",
            "     82        0.0034  0.0136\n",
            "     83        0.0038  0.0165\n",
            "     84        0.0036  0.0153\n",
            "     85        0.0033  0.0154\n",
            "     86        0.0037  0.0132\n",
            "     87        0.0036  0.0151\n",
            "     88        0.0034  0.0183\n",
            "     89        0.0034  0.0148\n",
            "     90        0.0034  0.0134\n",
            "     91        0.0036  0.0192\n",
            "     92        \u001b[36m0.0032\u001b[0m  0.0179\n",
            "     93        0.0034  0.0146\n",
            "     94        0.0032  0.0155\n",
            "     95        \u001b[36m0.0032\u001b[0m  0.0167\n",
            "     96        \u001b[36m0.0032\u001b[0m  0.0133\n",
            "     97        0.0032  0.0155\n",
            "     98        \u001b[36m0.0030\u001b[0m  0.0153\n",
            "     99        0.0032  0.0147\n",
            "    100        0.0030  0.0151\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1699\u001b[0m  0.0072\n",
            "      2        \u001b[36m0.1057\u001b[0m  0.0058\n",
            "      3        \u001b[36m0.0809\u001b[0m  0.0060\n",
            "      4        \u001b[36m0.0647\u001b[0m  0.0067\n",
            "      5        \u001b[36m0.0540\u001b[0m  0.0076\n",
            "      6        \u001b[36m0.0477\u001b[0m  0.0071\n",
            "      7        \u001b[36m0.0422\u001b[0m  0.0072\n",
            "      8        \u001b[36m0.0366\u001b[0m  0.0070\n",
            "      9        \u001b[36m0.0323\u001b[0m  0.0062\n",
            "     10        \u001b[36m0.0290\u001b[0m  0.0070\n",
            "     11        \u001b[36m0.0267\u001b[0m  0.0068\n",
            "     12        \u001b[36m0.0235\u001b[0m  0.0082\n",
            "     13        \u001b[36m0.0207\u001b[0m  0.0075\n",
            "     14        \u001b[36m0.0199\u001b[0m  0.0071\n",
            "     15        \u001b[36m0.0179\u001b[0m  0.0072\n",
            "     16        \u001b[36m0.0169\u001b[0m  0.0074\n",
            "     17        \u001b[36m0.0147\u001b[0m  0.0061\n",
            "     18        \u001b[36m0.0145\u001b[0m  0.0072\n",
            "     19        \u001b[36m0.0128\u001b[0m  0.0071\n",
            "     20        \u001b[36m0.0116\u001b[0m  0.0071\n",
            "     21        \u001b[36m0.0112\u001b[0m  0.0072\n",
            "     22        \u001b[36m0.0099\u001b[0m  0.0071\n",
            "     23        0.0102  0.0068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     24        \u001b[36m0.0092\u001b[0m  0.0062\n",
            "     25        \u001b[36m0.0087\u001b[0m  0.0069\n",
            "     26        \u001b[36m0.0079\u001b[0m  0.0074\n",
            "     27        0.0084  0.0071\n",
            "     28        0.0079  0.0070\n",
            "     29        \u001b[36m0.0068\u001b[0m  0.0071\n",
            "     30        0.0069  0.0071\n",
            "     31        \u001b[36m0.0068\u001b[0m  0.0070\n",
            "     32        \u001b[36m0.0066\u001b[0m  0.0070\n",
            "     33        \u001b[36m0.0063\u001b[0m  0.0071\n",
            "     34        \u001b[36m0.0060\u001b[0m  0.0077\n",
            "     35        0.0063  0.0064\n",
            "     36        \u001b[36m0.0057\u001b[0m  0.0070\n",
            "     37        0.0060  0.0074\n",
            "     38        \u001b[36m0.0057\u001b[0m  0.0074\n",
            "     39        \u001b[36m0.0052\u001b[0m  0.0076\n",
            "     40        0.0054  0.0068\n",
            "     41        \u001b[36m0.0050\u001b[0m  0.0077\n",
            "     42        \u001b[36m0.0046\u001b[0m  0.0072\n",
            "     43        \u001b[36m0.0045\u001b[0m  0.0071\n",
            "     44        \u001b[36m0.0044\u001b[0m  0.0075\n",
            "     45        0.0047  0.0067\n",
            "     46        0.0046  0.0070\n",
            "     47        0.0044  0.0073\n",
            "     48        \u001b[36m0.0041\u001b[0m  0.0091\n",
            "     49        0.0044  0.0071\n",
            "     50        0.0044  0.0077\n",
            "     51        \u001b[36m0.0038\u001b[0m  0.0077\n",
            "     52        0.0041  0.0119\n",
            "     53        0.0041  0.0112\n",
            "     54        0.0042  0.0130\n",
            "     55        0.0041  0.0096\n",
            "     56        0.0040  0.0083\n",
            "     57        \u001b[36m0.0037\u001b[0m  0.0075\n",
            "     58        \u001b[36m0.0036\u001b[0m  0.0070\n",
            "     59        \u001b[36m0.0034\u001b[0m  0.0079\n",
            "     60        0.0035  0.0123\n",
            "     61        0.0036  0.0079\n",
            "     62        0.0035  0.0077\n",
            "     63        0.0041  0.0066\n",
            "     64        0.0035  0.0077\n",
            "     65        \u001b[36m0.0031\u001b[0m  0.0074\n",
            "     66        0.0035  0.0116\n",
            "     67        \u001b[36m0.0030\u001b[0m  0.0080\n",
            "     68        0.0035  0.0078\n",
            "     69        0.0037  0.0078\n",
            "     70        0.0033  0.0072\n",
            "     71        \u001b[36m0.0029\u001b[0m  0.0070\n",
            "     72        0.0032  0.0077\n",
            "     73        0.0032  0.0070\n",
            "     74        0.0030  0.0074\n",
            "     75        0.0033  0.0085\n",
            "     76        0.0031  0.0095\n",
            "     77        0.0030  0.0069\n",
            "     78        0.0030  0.0076\n",
            "     79        0.0030  0.0077\n",
            "     80        \u001b[36m0.0025\u001b[0m  0.0076\n",
            "     81        0.0030  0.0073\n",
            "     82        0.0027  0.0068\n",
            "     83        0.0030  0.0065\n",
            "     84        0.0027  0.0073\n",
            "     85        0.0026  0.0069\n",
            "     86        \u001b[36m0.0025\u001b[0m  0.0074\n",
            "     87        0.0030  0.0069\n",
            "     88        \u001b[36m0.0023\u001b[0m  0.0069\n",
            "     89        0.0026  0.0072\n",
            "     90        0.0026  0.0090\n",
            "     91        0.0024  0.0079\n",
            "     92        0.0028  0.0077\n",
            "     93        0.0027  0.0071\n",
            "     94        0.0026  0.0072\n",
            "     95        0.0026  0.0076\n",
            "     96        0.0026  0.0065\n",
            "     97        0.0029  0.0081\n",
            "     98        \u001b[36m0.0023\u001b[0m  0.0083\n",
            "     99        0.0023  0.0082\n",
            "    100        0.0024  0.0067\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1691\u001b[0m  0.0178\n",
            "      2        \u001b[36m0.0863\u001b[0m  0.0153\n",
            "      3        \u001b[36m0.0636\u001b[0m  0.0136\n",
            "      4        \u001b[36m0.0516\u001b[0m  0.0134\n",
            "      5        \u001b[36m0.0426\u001b[0m  0.0134\n",
            "      6        \u001b[36m0.0366\u001b[0m  0.0133\n",
            "      7        \u001b[36m0.0313\u001b[0m  0.0134\n",
            "      8        \u001b[36m0.0268\u001b[0m  0.0135\n",
            "      9        \u001b[36m0.0234\u001b[0m  0.0135\n",
            "     10        \u001b[36m0.0212\u001b[0m  0.0137\n",
            "     11        \u001b[36m0.0188\u001b[0m  0.0138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0175\u001b[0m  0.0156\n",
            "     13        \u001b[36m0.0159\u001b[0m  0.0140\n",
            "     14        \u001b[36m0.0140\u001b[0m  0.0147\n",
            "     15        \u001b[36m0.0135\u001b[0m  0.0133\n",
            "     16        \u001b[36m0.0132\u001b[0m  0.0131\n",
            "     17        \u001b[36m0.0124\u001b[0m  0.0142\n",
            "     18        \u001b[36m0.0115\u001b[0m  0.0132\n",
            "     19        0.0118  0.0151\n",
            "     20        \u001b[36m0.0108\u001b[0m  0.0164\n",
            "     21        \u001b[36m0.0097\u001b[0m  0.0192\n",
            "     22        \u001b[36m0.0094\u001b[0m  0.0190\n",
            "     23        \u001b[36m0.0090\u001b[0m  0.0134\n",
            "     24        0.0091  0.0144\n",
            "     25        \u001b[36m0.0085\u001b[0m  0.0138\n",
            "     26        0.0085  0.0137\n",
            "     27        \u001b[36m0.0080\u001b[0m  0.0136\n",
            "     28        \u001b[36m0.0078\u001b[0m  0.0145\n",
            "     29        \u001b[36m0.0073\u001b[0m  0.0137\n",
            "     30        0.0074  0.0140\n",
            "     31        0.0080  0.0136\n",
            "     32        \u001b[36m0.0072\u001b[0m  0.0137\n",
            "     33        \u001b[36m0.0065\u001b[0m  0.0133\n",
            "     34        0.0065  0.0133\n",
            "     35        0.0066  0.0134\n",
            "     36        0.0067  0.0138\n",
            "     37        \u001b[36m0.0063\u001b[0m  0.0138\n",
            "     38        0.0063  0.0166\n",
            "     39        \u001b[36m0.0058\u001b[0m  0.0190\n",
            "     40        0.0061  0.0157\n",
            "     41        0.0066  0.0178\n",
            "     42        0.0060  0.0183\n",
            "     43        \u001b[36m0.0054\u001b[0m  0.0168\n",
            "     44        0.0057  0.0165\n",
            "     45        \u001b[36m0.0054\u001b[0m  0.0137\n",
            "     46        0.0058  0.0146\n",
            "     47        0.0059  0.0141\n",
            "     48        0.0055  0.0141\n",
            "     49        \u001b[36m0.0052\u001b[0m  0.0139\n",
            "     50        \u001b[36m0.0051\u001b[0m  0.0136\n",
            "     51        0.0053  0.0134\n",
            "     52        \u001b[36m0.0050\u001b[0m  0.0134\n",
            "     53        \u001b[36m0.0047\u001b[0m  0.0136\n",
            "     54        0.0049  0.0139\n",
            "     55        0.0052  0.0137\n",
            "     56        0.0054  0.0137\n",
            "     57        0.0050  0.0135\n",
            "     58        \u001b[36m0.0046\u001b[0m  0.0135\n",
            "     59        0.0049  0.0137\n",
            "     60        0.0051  0.0139\n",
            "     61        0.0047  0.0135\n",
            "     62        0.0046  0.0137\n",
            "     63        0.0048  0.0154\n",
            "     64        \u001b[36m0.0045\u001b[0m  0.0144\n",
            "     65        \u001b[36m0.0044\u001b[0m  0.0138\n",
            "     66        0.0046  0.0135\n",
            "     67        0.0047  0.0135\n",
            "     68        0.0048  0.0134\n",
            "     69        0.0046  0.0136\n",
            "     70        \u001b[36m0.0044\u001b[0m  0.0137\n",
            "     71        \u001b[36m0.0043\u001b[0m  0.0141\n",
            "     72        0.0047  0.0254\n",
            "     73        \u001b[36m0.0042\u001b[0m  0.0288\n",
            "     74        \u001b[36m0.0042\u001b[0m  0.0327\n",
            "     75        0.0044  0.0368\n",
            "     76        \u001b[36m0.0042\u001b[0m  0.0416\n",
            "     77        \u001b[36m0.0038\u001b[0m  0.0342\n",
            "     78        0.0042  0.0411\n",
            "     79        0.0041  0.0310\n",
            "     80        0.0040  0.0363\n",
            "     81        0.0039  0.0408\n",
            "     82        0.0039  0.0332\n",
            "     83        \u001b[36m0.0038\u001b[0m  0.0369\n",
            "     84        \u001b[36m0.0037\u001b[0m  0.0414\n",
            "     85        0.0042  0.0366\n",
            "     86        0.0041  0.0310\n",
            "     87        0.0041  0.0397\n",
            "     88        0.0041  0.0331\n",
            "     89        0.0039  0.0430\n",
            "     90        0.0041  0.0416\n",
            "     91        0.0043  0.0260\n",
            "     92        0.0038  0.0243\n",
            "     93        0.0038  0.0556\n",
            "     94        0.0038  0.0575\n",
            "     95        0.0040  0.0483\n",
            "     96        0.0039  0.0364\n",
            "     97        0.0039  0.0235\n",
            "     98        0.0041  0.0205\n",
            "     99        0.0037  0.0557\n",
            "    100        0.0039  0.0453\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1555\u001b[0m  0.0502\n",
            "      2        \u001b[36m0.0841\u001b[0m  0.0491\n",
            "      3        \u001b[36m0.0581\u001b[0m  0.0508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.0466\u001b[0m  0.0430\n",
            "      5        \u001b[36m0.0387\u001b[0m  0.0266\n",
            "      6        \u001b[36m0.0329\u001b[0m  0.0229\n",
            "      7        \u001b[36m0.0264\u001b[0m  0.0606\n",
            "      8        \u001b[36m0.0236\u001b[0m  0.0567\n",
            "      9        \u001b[36m0.0206\u001b[0m  0.0553\n",
            "     10        \u001b[36m0.0176\u001b[0m  0.0622\n",
            "     11        \u001b[36m0.0156\u001b[0m  0.0534\n",
            "     12        \u001b[36m0.0137\u001b[0m  0.0638\n",
            "     13        \u001b[36m0.0125\u001b[0m  0.0347\n",
            "     14        \u001b[36m0.0115\u001b[0m  0.0423\n",
            "     15        \u001b[36m0.0113\u001b[0m  0.0533\n",
            "     16        \u001b[36m0.0103\u001b[0m  0.0603\n",
            "     17        \u001b[36m0.0094\u001b[0m  0.0179\n",
            "     18        0.0095  0.0149\n",
            "     19        \u001b[36m0.0089\u001b[0m  0.0409\n",
            "     20        \u001b[36m0.0084\u001b[0m  0.0496\n",
            "     21        \u001b[36m0.0081\u001b[0m  0.0266\n",
            "     22        \u001b[36m0.0076\u001b[0m  0.0170\n",
            "     23        0.0077  0.0195\n",
            "     24        \u001b[36m0.0070\u001b[0m  0.0392\n",
            "     25        \u001b[36m0.0067\u001b[0m  0.0369\n",
            "     26        0.0068  0.0475\n",
            "     27        \u001b[36m0.0066\u001b[0m  0.0407\n",
            "     28        \u001b[36m0.0064\u001b[0m  0.0433\n",
            "     29        \u001b[36m0.0058\u001b[0m  0.0148\n",
            "     30        0.0059  0.0132\n",
            "     31        0.0061  0.0135\n",
            "     32        0.0060  0.0170\n",
            "     33        0.0058  0.0117\n",
            "     34        \u001b[36m0.0055\u001b[0m  0.0121\n",
            "     35        0.0059  0.0155\n",
            "     36        \u001b[36m0.0053\u001b[0m  0.0163\n",
            "     37        0.0054  0.0201\n",
            "     38        \u001b[36m0.0050\u001b[0m  0.0133\n",
            "     39        0.0051  0.0155\n",
            "     40        \u001b[36m0.0049\u001b[0m  0.0124\n",
            "     41        0.0057  0.0134\n",
            "     42        \u001b[36m0.0046\u001b[0m  0.0146\n",
            "     43        0.0051  0.0132\n",
            "     44        0.0047  0.0129\n",
            "     45        \u001b[36m0.0046\u001b[0m  0.0131\n",
            "     46        \u001b[36m0.0045\u001b[0m  0.0149\n",
            "     47        0.0046  0.0130\n",
            "     48        0.0045  0.0159\n",
            "     49        0.0045  0.0127\n",
            "     50        \u001b[36m0.0044\u001b[0m  0.0116\n",
            "     51        \u001b[36m0.0043\u001b[0m  0.0119\n",
            "     52        \u001b[36m0.0042\u001b[0m  0.0156\n",
            "     53        0.0043  0.0129\n",
            "     54        \u001b[36m0.0041\u001b[0m  0.0149\n",
            "     55        0.0041  0.0134\n",
            "     56        0.0042  0.0129\n",
            "     57        \u001b[36m0.0040\u001b[0m  0.0138\n",
            "     58        0.0042  0.0116\n",
            "     59        0.0042  0.0117\n",
            "     60        0.0041  0.0148\n",
            "     61        \u001b[36m0.0039\u001b[0m  0.0139\n",
            "     62        0.0043  0.0130\n",
            "     63        0.0040  0.0137\n",
            "     64        \u001b[36m0.0038\u001b[0m  0.0139\n",
            "     65        \u001b[36m0.0037\u001b[0m  0.0118\n",
            "     66        0.0039  0.0116\n",
            "     67        0.0040  0.0158\n",
            "     68        0.0038  0.0134\n",
            "     69        0.0039  0.0157\n",
            "     70        0.0040  0.0120\n",
            "     71        0.0039  0.0118\n",
            "     72        0.0039  0.0157\n",
            "     73        0.0040  0.0152\n",
            "     74        \u001b[36m0.0033\u001b[0m  0.0131\n",
            "     75        0.0034  0.0135\n",
            "     76        0.0037  0.0146\n",
            "     77        0.0037  0.0133\n",
            "     78        0.0035  0.0117\n",
            "     79        0.0036  0.0117\n",
            "     80        0.0035  0.0145\n",
            "     81        0.0034  0.0136\n",
            "     82        0.0036  0.0143\n",
            "     83        0.0038  0.0123\n",
            "     84        0.0035  0.0119\n",
            "     85        0.0037  0.0150\n",
            "     86        0.0034  0.0148\n",
            "     87        0.0034  0.0131\n",
            "     88        0.0034  0.0115\n",
            "     89        0.0035  0.0118\n",
            "     90        0.0033  0.0153\n",
            "     91        0.0034  0.0140\n",
            "     92        0.0034  0.0132\n",
            "     93        0.0036  0.0117\n",
            "     94        \u001b[36m0.0032\u001b[0m  0.0118\n",
            "     95        \u001b[36m0.0031\u001b[0m  0.0143\n",
            "     96        0.0033  0.0145\n",
            "     97        0.0035  0.0134\n",
            "     98        0.0035  0.0133\n",
            "     99        0.0032  0.0114\n",
            "    100        0.0032  0.0135\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1479\u001b[0m  0.0105\n",
            "      2        \u001b[36m0.1064\u001b[0m  0.0084\n",
            "      3        \u001b[36m0.0864\u001b[0m  0.0079\n",
            "      4        \u001b[36m0.0702\u001b[0m  0.0086\n",
            "      5        \u001b[36m0.0632\u001b[0m  0.0064\n",
            "      6        \u001b[36m0.0583\u001b[0m  0.0066\n",
            "      7        \u001b[36m0.0482\u001b[0m  0.0070\n",
            "      8        \u001b[36m0.0432\u001b[0m  0.0064\n",
            "      9        \u001b[36m0.0390\u001b[0m  0.0158\n",
            "     10        \u001b[36m0.0342\u001b[0m  0.0090\n",
            "     11        \u001b[36m0.0328\u001b[0m  0.0118\n",
            "     12        \u001b[36m0.0296\u001b[0m  0.0093\n",
            "     13        \u001b[36m0.0258\u001b[0m  0.0094\n",
            "     14        \u001b[36m0.0251\u001b[0m  0.0109\n",
            "     15        \u001b[36m0.0225\u001b[0m  0.0085\n",
            "     16        \u001b[36m0.0210\u001b[0m  0.0087\n",
            "     17        \u001b[36m0.0195\u001b[0m  0.0091\n",
            "     18        \u001b[36m0.0182\u001b[0m  0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     19        \u001b[36m0.0154\u001b[0m  0.0074\n",
            "     20        \u001b[36m0.0148\u001b[0m  0.0064\n",
            "     21        \u001b[36m0.0142\u001b[0m  0.0091\n",
            "     22        \u001b[36m0.0132\u001b[0m  0.0106\n",
            "     23        \u001b[36m0.0132\u001b[0m  0.0095\n",
            "     24        \u001b[36m0.0120\u001b[0m  0.0086\n",
            "     25        0.0124  0.0081\n",
            "     26        \u001b[36m0.0104\u001b[0m  0.0082\n",
            "     27        \u001b[36m0.0102\u001b[0m  0.0088\n",
            "     28        \u001b[36m0.0096\u001b[0m  0.0092\n",
            "     29        0.0099  0.0091\n",
            "     30        \u001b[36m0.0092\u001b[0m  0.0090\n",
            "     31        \u001b[36m0.0081\u001b[0m  0.0087\n",
            "     32        0.0090  0.0086\n",
            "     33        0.0086  0.0109\n",
            "     34        \u001b[36m0.0074\u001b[0m  0.0101\n",
            "     35        \u001b[36m0.0073\u001b[0m  0.0094\n",
            "     36        0.0075  0.0092\n",
            "     37        \u001b[36m0.0069\u001b[0m  0.0069\n",
            "     38        \u001b[36m0.0069\u001b[0m  0.0092\n",
            "     39        \u001b[36m0.0066\u001b[0m  0.0084\n",
            "     40        0.0066  0.0083\n",
            "     41        \u001b[36m0.0059\u001b[0m  0.0080\n",
            "     42        \u001b[36m0.0056\u001b[0m  0.0085\n",
            "     43        0.0062  0.0108\n",
            "     44        0.0065  0.0093\n",
            "     45        0.0060  0.0093\n",
            "     46        \u001b[36m0.0052\u001b[0m  0.0092\n",
            "     47        0.0054  0.0087\n",
            "     48        0.0057  0.0074\n",
            "     49        \u001b[36m0.0047\u001b[0m  0.0069\n",
            "     50        0.0050  0.0111\n",
            "     51        0.0049  0.0086\n",
            "     52        0.0050  0.0091\n",
            "     53        \u001b[36m0.0046\u001b[0m  0.0105\n",
            "     54        0.0048  0.0081\n",
            "     55        0.0049  0.0066\n",
            "     56        \u001b[36m0.0045\u001b[0m  0.0070\n",
            "     57        0.0046  0.0100\n",
            "     58        \u001b[36m0.0044\u001b[0m  0.0084\n",
            "     59        \u001b[36m0.0040\u001b[0m  0.0092\n",
            "     60        0.0046  0.0088\n",
            "     61        \u001b[36m0.0039\u001b[0m  0.0084\n",
            "     62        \u001b[36m0.0039\u001b[0m  0.0075\n",
            "     63        \u001b[36m0.0037\u001b[0m  0.0065\n",
            "     64        0.0039  0.0065\n",
            "     65        \u001b[36m0.0035\u001b[0m  0.0092\n",
            "     66        0.0036  0.0083\n",
            "     67        0.0035  0.0082\n",
            "     68        0.0037  0.0081\n",
            "     69        0.0038  0.0087\n",
            "     70        0.0035  0.0088\n",
            "     71        0.0036  0.0068\n",
            "     72        0.0037  0.0080\n",
            "     73        \u001b[36m0.0035\u001b[0m  0.0093\n",
            "     74        \u001b[36m0.0032\u001b[0m  0.0091\n",
            "     75        0.0035  0.0087\n",
            "     76        0.0033  0.0090\n",
            "     77        0.0037  0.0087\n",
            "     78        0.0035  0.0079\n",
            "     79        \u001b[36m0.0032\u001b[0m  0.0086\n",
            "     80        \u001b[36m0.0030\u001b[0m  0.0088\n",
            "     81        0.0032  0.0087\n",
            "     82        \u001b[36m0.0026\u001b[0m  0.0085\n",
            "     83        0.0033  0.0087\n",
            "     84        0.0030  0.0080\n",
            "     85        0.0027  0.0089\n",
            "     86        0.0030  0.0089\n",
            "     87        0.0030  0.0081\n",
            "     88        0.0028  0.0069\n",
            "     89        0.0029  0.0066\n",
            "     90        0.0028  0.0098\n",
            "     91        0.0028  0.0089\n",
            "     92        0.0026  0.0087\n",
            "     93        0.0028  0.0091\n",
            "     94        0.0029  0.0088\n",
            "     95        0.0027  0.0067\n",
            "     96        \u001b[36m0.0025\u001b[0m  0.0085\n",
            "     97        0.0026  0.0083\n",
            "     98        \u001b[36m0.0025\u001b[0m  0.0084\n",
            "     99        0.0025  0.0088\n",
            "    100        \u001b[36m0.0023\u001b[0m  0.0121\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1765\u001b[0m  0.0162\n",
            "      2        \u001b[36m0.1161\u001b[0m  0.0141\n",
            "      3        \u001b[36m0.0932\u001b[0m  0.0146\n",
            "      4        \u001b[36m0.0774\u001b[0m  0.0144\n",
            "      5        \u001b[36m0.0671\u001b[0m  0.0125\n",
            "      6        \u001b[36m0.0603\u001b[0m  0.0122\n",
            "      7        \u001b[36m0.0507\u001b[0m  0.0171\n",
            "      8        \u001b[36m0.0449\u001b[0m  0.0143\n",
            "      9        \u001b[36m0.0391\u001b[0m  0.0142\n",
            "     10        \u001b[36m0.0366\u001b[0m  0.0266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0323\u001b[0m  0.0172\n",
            "     12        \u001b[36m0.0282\u001b[0m  0.0145\n",
            "     13        \u001b[36m0.0262\u001b[0m  0.0139\n",
            "     14        \u001b[36m0.0230\u001b[0m  0.0142\n",
            "     15        \u001b[36m0.0218\u001b[0m  0.0132\n",
            "     16        \u001b[36m0.0195\u001b[0m  0.0159\n",
            "     17        \u001b[36m0.0186\u001b[0m  0.0161\n",
            "     18        \u001b[36m0.0178\u001b[0m  0.0129\n",
            "     19        \u001b[36m0.0165\u001b[0m  0.0124\n",
            "     20        \u001b[36m0.0158\u001b[0m  0.0168\n",
            "     21        \u001b[36m0.0148\u001b[0m  0.0158\n",
            "     22        \u001b[36m0.0142\u001b[0m  0.0152\n",
            "     23        \u001b[36m0.0129\u001b[0m  0.0161\n",
            "     24        \u001b[36m0.0127\u001b[0m  0.0135\n",
            "     25        \u001b[36m0.0122\u001b[0m  0.0143\n",
            "     26        \u001b[36m0.0122\u001b[0m  0.0170\n",
            "     27        \u001b[36m0.0111\u001b[0m  0.0145\n",
            "     28        0.0114  0.0124\n",
            "     29        \u001b[36m0.0110\u001b[0m  0.0124\n",
            "     30        \u001b[36m0.0104\u001b[0m  0.0187\n",
            "     31        \u001b[36m0.0100\u001b[0m  0.0154\n",
            "     32        \u001b[36m0.0093\u001b[0m  0.0127\n",
            "     33        \u001b[36m0.0092\u001b[0m  0.0133\n",
            "     34        0.0096  0.0176\n",
            "     35        \u001b[36m0.0090\u001b[0m  0.0166\n",
            "     36        \u001b[36m0.0085\u001b[0m  0.0154\n",
            "     37        \u001b[36m0.0082\u001b[0m  0.0141\n",
            "     38        0.0087  0.0125\n",
            "     39        \u001b[36m0.0082\u001b[0m  0.0126\n",
            "     40        0.0082  0.0172\n",
            "     41        0.0082  0.0157\n",
            "     42        \u001b[36m0.0074\u001b[0m  0.0141\n",
            "     43        0.0077  0.0123\n",
            "     44        \u001b[36m0.0073\u001b[0m  0.0124\n",
            "     45        \u001b[36m0.0072\u001b[0m  0.0170\n",
            "     46        \u001b[36m0.0071\u001b[0m  0.0155\n",
            "     47        0.0073  0.0136\n",
            "     48        0.0072  0.0152\n",
            "     49        \u001b[36m0.0065\u001b[0m  0.0166\n",
            "     50        \u001b[36m0.0062\u001b[0m  0.0139\n",
            "     51        0.0067  0.0165\n",
            "     52        0.0063  0.0121\n",
            "     53        \u001b[36m0.0060\u001b[0m  0.0133\n",
            "     54        \u001b[36m0.0059\u001b[0m  0.0164\n",
            "     55        0.0060  0.0164\n",
            "     56        0.0060  0.0142\n",
            "     57        0.0061  0.0152\n",
            "     58        \u001b[36m0.0056\u001b[0m  0.0131\n",
            "     59        0.0058  0.0132\n",
            "     60        0.0063  0.0182\n",
            "     61        0.0060  0.0177\n",
            "     62        0.0056  0.0151\n",
            "     63        \u001b[36m0.0053\u001b[0m  0.0154\n",
            "     64        0.0058  0.0168\n",
            "     65        0.0054  0.0158\n",
            "     66        \u001b[36m0.0049\u001b[0m  0.0148\n",
            "     67        0.0051  0.0127\n",
            "     68        0.0050  0.0136\n",
            "     69        0.0052  0.0166\n",
            "     70        0.0051  0.0141\n",
            "     71        \u001b[36m0.0048\u001b[0m  0.0125\n",
            "     72        0.0052  0.0123\n",
            "     73        0.0049  0.0168\n",
            "     74        0.0050  0.0191\n",
            "     75        0.0056  0.0192\n",
            "     76        \u001b[36m0.0047\u001b[0m  0.0178\n",
            "     77        0.0051  0.0144\n",
            "     78        0.0052  0.0148\n",
            "     79        0.0054  0.0155\n",
            "     80        \u001b[36m0.0046\u001b[0m  0.0126\n",
            "     81        0.0053  0.0133\n",
            "     82        0.0049  0.0165\n",
            "     83        \u001b[36m0.0043\u001b[0m  0.0148\n",
            "     84        0.0044  0.0126\n",
            "     85        0.0044  0.0125\n",
            "     86        \u001b[36m0.0042\u001b[0m  0.0165\n",
            "     87        0.0044  0.0138\n",
            "     88        0.0043  0.0142\n",
            "     89        0.0048  0.0152\n",
            "     90        0.0043  0.0126\n",
            "     91        \u001b[36m0.0041\u001b[0m  0.0126\n",
            "     92        0.0044  0.0165\n",
            "     93        \u001b[36m0.0041\u001b[0m  0.0139\n",
            "     94        \u001b[36m0.0040\u001b[0m  0.0152\n",
            "     95        0.0042  0.0149\n",
            "     96        0.0041  0.0140\n",
            "     97        \u001b[36m0.0039\u001b[0m  0.0145\n",
            "     98        0.0039  0.0179\n",
            "     99        0.0041  0.0147\n",
            "    100        0.0040  0.0143\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1472\u001b[0m  0.0183\n",
            "      2        \u001b[36m0.1011\u001b[0m  0.0182\n",
            "      3        \u001b[36m0.0765\u001b[0m  0.0145\n",
            "      4        \u001b[36m0.0645\u001b[0m  0.0162\n",
            "      5        \u001b[36m0.0547\u001b[0m  0.0129\n",
            "      6        \u001b[36m0.0472\u001b[0m  0.0140\n",
            "      7        \u001b[36m0.0415\u001b[0m  0.0177\n",
            "      8        \u001b[36m0.0360\u001b[0m  0.0163\n",
            "      9        \u001b[36m0.0323\u001b[0m  0.0130\n",
            "     10        \u001b[36m0.0291\u001b[0m  0.0150\n",
            "     11        \u001b[36m0.0266\u001b[0m  0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0245\u001b[0m  0.0164\n",
            "     13        \u001b[36m0.0215\u001b[0m  0.0129\n",
            "     14        \u001b[36m0.0192\u001b[0m  0.0133\n",
            "     15        \u001b[36m0.0187\u001b[0m  0.0188\n",
            "     16        \u001b[36m0.0164\u001b[0m  0.0171\n",
            "     17        \u001b[36m0.0155\u001b[0m  0.0135\n",
            "     18        \u001b[36m0.0148\u001b[0m  0.0161\n",
            "     19        \u001b[36m0.0135\u001b[0m  0.0166\n",
            "     20        \u001b[36m0.0126\u001b[0m  0.0183\n",
            "     21        \u001b[36m0.0121\u001b[0m  0.0145\n",
            "     22        \u001b[36m0.0110\u001b[0m  0.0130\n",
            "     23        \u001b[36m0.0109\u001b[0m  0.0133\n",
            "     24        \u001b[36m0.0098\u001b[0m  0.0178\n",
            "     25        \u001b[36m0.0095\u001b[0m  0.0149\n",
            "     26        \u001b[36m0.0095\u001b[0m  0.0165\n",
            "     27        \u001b[36m0.0086\u001b[0m  0.0160\n",
            "     28        0.0088  0.0160\n",
            "     29        \u001b[36m0.0084\u001b[0m  0.0149\n",
            "     30        \u001b[36m0.0082\u001b[0m  0.0151\n",
            "     31        \u001b[36m0.0076\u001b[0m  0.0173\n",
            "     32        \u001b[36m0.0075\u001b[0m  0.0131\n",
            "     33        \u001b[36m0.0074\u001b[0m  0.0155\n",
            "     34        \u001b[36m0.0071\u001b[0m  0.0159\n",
            "     35        \u001b[36m0.0070\u001b[0m  0.0147\n",
            "     36        \u001b[36m0.0069\u001b[0m  0.0131\n",
            "     37        \u001b[36m0.0068\u001b[0m  0.0286\n",
            "     38        \u001b[36m0.0065\u001b[0m  0.0177\n",
            "     39        \u001b[36m0.0063\u001b[0m  0.0150\n",
            "     40        \u001b[36m0.0061\u001b[0m  0.0128\n",
            "     41        0.0061  0.0157\n",
            "     42        \u001b[36m0.0058\u001b[0m  0.0164\n",
            "     43        \u001b[36m0.0057\u001b[0m  0.0148\n",
            "     44        \u001b[36m0.0057\u001b[0m  0.0149\n",
            "     45        \u001b[36m0.0056\u001b[0m  0.0131\n",
            "     46        0.0058  0.0145\n",
            "     47        0.0057  0.0168\n",
            "     48        \u001b[36m0.0053\u001b[0m  0.0153\n",
            "     49        0.0053  0.0128\n",
            "     50        \u001b[36m0.0051\u001b[0m  0.0143\n",
            "     51        0.0051  0.0161\n",
            "     52        0.0054  0.0146\n",
            "     53        0.0051  0.0166\n",
            "     54        \u001b[36m0.0048\u001b[0m  0.0131\n",
            "     55        0.0050  0.0144\n",
            "     56        0.0049  0.0184\n",
            "     57        \u001b[36m0.0046\u001b[0m  0.0154\n",
            "     58        0.0047  0.0144\n",
            "     59        0.0048  0.0159\n",
            "     60        \u001b[36m0.0046\u001b[0m  0.0166\n",
            "     61        \u001b[36m0.0044\u001b[0m  0.0148\n",
            "     62        0.0045  0.0153\n",
            "     63        0.0047  0.0130\n",
            "     64        0.0045  0.0148\n",
            "     65        \u001b[36m0.0043\u001b[0m  0.0158\n",
            "     66        \u001b[36m0.0040\u001b[0m  0.0147\n",
            "     67        0.0041  0.0162\n",
            "     68        0.0042  0.0140\n",
            "     69        0.0041  0.0149\n",
            "     70        \u001b[36m0.0040\u001b[0m  0.0156\n",
            "     71        \u001b[36m0.0039\u001b[0m  0.0148\n",
            "     72        \u001b[36m0.0038\u001b[0m  0.0149\n",
            "     73        0.0039  0.0146\n",
            "     74        0.0039  0.0151\n",
            "     75        \u001b[36m0.0038\u001b[0m  0.0165\n",
            "     76        \u001b[36m0.0038\u001b[0m  0.0141\n",
            "     77        0.0039  0.0148\n",
            "     78        \u001b[36m0.0038\u001b[0m  0.0131\n",
            "     79        \u001b[36m0.0035\u001b[0m  0.0157\n",
            "     80        0.0040  0.0168\n",
            "     81        0.0036  0.0150\n",
            "     82        0.0037  0.0171\n",
            "     83        0.0036  0.0130\n",
            "     84        \u001b[36m0.0035\u001b[0m  0.0145\n",
            "     85        0.0036  0.0164\n",
            "     86        0.0035  0.0145\n",
            "     87        0.0036  0.0151\n",
            "     88        0.0038  0.0130\n",
            "     89        0.0035  0.0191\n",
            "     90        \u001b[36m0.0035\u001b[0m  0.0176\n",
            "     91        0.0037  0.0147\n",
            "     92        \u001b[36m0.0033\u001b[0m  0.0153\n",
            "     93        0.0034  0.0152\n",
            "     94        0.0033  0.0148\n",
            "     95        0.0036  0.0153\n",
            "     96        0.0033  0.0129\n",
            "     97        0.0035  0.0135\n",
            "     98        0.0033  0.0187\n",
            "     99        \u001b[36m0.0032\u001b[0m  0.0148\n",
            "    100        0.0033  0.0195\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1403\u001b[0m  0.0078\n",
            "      2        \u001b[36m0.0915\u001b[0m  0.0070\n",
            "      3        \u001b[36m0.0688\u001b[0m  0.0074\n",
            "      4        \u001b[36m0.0553\u001b[0m  0.0075\n",
            "      5        \u001b[36m0.0463\u001b[0m  0.0081\n",
            "      6        \u001b[36m0.0408\u001b[0m  0.0070\n",
            "      7        \u001b[36m0.0369\u001b[0m  0.0064\n",
            "      8        \u001b[36m0.0317\u001b[0m  0.0059\n",
            "      9        \u001b[36m0.0293\u001b[0m  0.0061\n",
            "     10        \u001b[36m0.0256\u001b[0m  0.0060\n",
            "     11        \u001b[36m0.0236\u001b[0m  0.0070\n",
            "     12        \u001b[36m0.0213\u001b[0m  0.0075\n",
            "     13        \u001b[36m0.0206\u001b[0m  0.0075\n",
            "     14        \u001b[36m0.0176\u001b[0m  0.0077\n",
            "     15        \u001b[36m0.0174\u001b[0m  0.0077\n",
            "     16        \u001b[36m0.0150\u001b[0m  0.0077\n",
            "     17        \u001b[36m0.0148\u001b[0m  0.0059\n",
            "     18        \u001b[36m0.0131\u001b[0m  0.0095\n",
            "     19        \u001b[36m0.0131\u001b[0m  0.0075\n",
            "     20        \u001b[36m0.0124\u001b[0m  0.0077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     21        \u001b[36m0.0116\u001b[0m  0.0078\n",
            "     22        \u001b[36m0.0101\u001b[0m  0.0071\n",
            "     23        \u001b[36m0.0099\u001b[0m  0.0071\n",
            "     24        \u001b[36m0.0095\u001b[0m  0.0066\n",
            "     25        \u001b[36m0.0092\u001b[0m  0.0071\n",
            "     26        \u001b[36m0.0085\u001b[0m  0.0072\n",
            "     27        \u001b[36m0.0080\u001b[0m  0.0071\n",
            "     28        0.0081  0.0071\n",
            "     29        0.0082  0.0070\n",
            "     30        \u001b[36m0.0078\u001b[0m  0.0098\n",
            "     31        \u001b[36m0.0069\u001b[0m  0.0073\n",
            "     32        \u001b[36m0.0061\u001b[0m  0.0071\n",
            "     33        \u001b[36m0.0058\u001b[0m  0.0070\n",
            "     34        0.0059  0.0107\n",
            "     35        \u001b[36m0.0057\u001b[0m  0.0065\n",
            "     36        0.0064  0.0072\n",
            "     37        0.0061  0.0071\n",
            "     38        \u001b[36m0.0053\u001b[0m  0.0071\n",
            "     39        0.0059  0.0071\n",
            "     40        \u001b[36m0.0051\u001b[0m  0.0069\n",
            "     41        0.0053  0.0069\n",
            "     42        0.0054  0.0071\n",
            "     43        \u001b[36m0.0051\u001b[0m  0.0086\n",
            "     44        \u001b[36m0.0047\u001b[0m  0.0072\n",
            "     45        \u001b[36m0.0046\u001b[0m  0.0070\n",
            "     46        0.0048  0.0069\n",
            "     47        0.0046  0.0074\n",
            "     48        0.0048  0.0081\n",
            "     49        \u001b[36m0.0043\u001b[0m  0.0073\n",
            "     50        0.0047  0.0071\n",
            "     51        0.0045  0.0074\n",
            "     52        \u001b[36m0.0039\u001b[0m  0.0071\n",
            "     53        0.0043  0.0092\n",
            "     54        0.0045  0.0073\n",
            "     55        0.0040  0.0073\n",
            "     56        0.0041  0.0069\n",
            "     57        0.0047  0.0071\n",
            "     58        \u001b[36m0.0034\u001b[0m  0.0072\n",
            "     59        0.0035  0.0074\n",
            "     60        0.0037  0.0073\n",
            "     61        0.0038  0.0073\n",
            "     62        0.0034  0.0063\n",
            "     63        \u001b[36m0.0032\u001b[0m  0.0073\n",
            "     64        0.0033  0.0084\n",
            "     65        0.0038  0.0081\n",
            "     66        0.0033  0.0079\n",
            "     67        0.0033  0.0077\n",
            "     68        0.0036  0.0074\n",
            "     69        \u001b[36m0.0031\u001b[0m  0.0071\n",
            "     70        0.0033  0.0060\n",
            "     71        0.0036  0.0070\n",
            "     72        0.0032  0.0074\n",
            "     73        0.0033  0.0071\n",
            "     74        \u001b[36m0.0030\u001b[0m  0.0071\n",
            "     75        0.0031  0.0071\n",
            "     76        \u001b[36m0.0030\u001b[0m  0.0072\n",
            "     77        0.0032  0.0065\n",
            "     78        0.0031  0.0074\n",
            "     79        \u001b[36m0.0027\u001b[0m  0.0073\n",
            "     80        0.0028  0.0074\n",
            "     81        0.0029  0.0074\n",
            "     82        0.0030  0.0076\n",
            "     83        \u001b[36m0.0026\u001b[0m  0.0075\n",
            "     84        0.0029  0.0074\n",
            "     85        0.0028  0.0072\n",
            "     86        0.0031  0.0062\n",
            "     87        \u001b[36m0.0026\u001b[0m  0.0086\n",
            "     88        0.0027  0.0074\n",
            "     89        \u001b[36m0.0026\u001b[0m  0.0074\n",
            "     90        0.0027  0.0074\n",
            "     91        \u001b[36m0.0024\u001b[0m  0.0081\n",
            "     92        0.0025  0.0073\n",
            "     93        0.0026  0.0081\n",
            "     94        0.0026  0.0076\n",
            "     95        0.0026  0.0076\n",
            "     96        0.0028  0.0096\n",
            "     97        0.0029  0.0070\n",
            "     98        0.0027  0.0072\n",
            "     99        0.0024  0.0062\n",
            "    100        0.0024  0.0086\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1774\u001b[0m  0.0174\n",
            "      2        \u001b[36m0.1013\u001b[0m  0.0147\n",
            "      3        \u001b[36m0.0768\u001b[0m  0.0142\n",
            "      4        \u001b[36m0.0643\u001b[0m  0.0143\n",
            "      5        \u001b[36m0.0543\u001b[0m  0.0115\n",
            "      6        \u001b[36m0.0465\u001b[0m  0.0114\n",
            "      7        \u001b[36m0.0409\u001b[0m  0.0150\n",
            "      8        \u001b[36m0.0352\u001b[0m  0.0157\n",
            "      9        \u001b[36m0.0304\u001b[0m  0.0206\n",
            "     10        \u001b[36m0.0266\u001b[0m  0.0134\n",
            "     11        \u001b[36m0.0240\u001b[0m  0.0141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0210\u001b[0m  0.0149\n",
            "     13        \u001b[36m0.0192\u001b[0m  0.0152\n",
            "     14        \u001b[36m0.0168\u001b[0m  0.0128\n",
            "     15        \u001b[36m0.0155\u001b[0m  0.0112\n",
            "     16        \u001b[36m0.0148\u001b[0m  0.0113\n",
            "     17        \u001b[36m0.0135\u001b[0m  0.0150\n",
            "     18        \u001b[36m0.0119\u001b[0m  0.0136\n",
            "     19        0.0120  0.0135\n",
            "     20        \u001b[36m0.0112\u001b[0m  0.0111\n",
            "     21        \u001b[36m0.0100\u001b[0m  0.0113\n",
            "     22        \u001b[36m0.0092\u001b[0m  0.0139\n",
            "     23        \u001b[36m0.0084\u001b[0m  0.0166\n",
            "     24        0.0087  0.0126\n",
            "     25        \u001b[36m0.0082\u001b[0m  0.0124\n",
            "     26        \u001b[36m0.0078\u001b[0m  0.0110\n",
            "     27        \u001b[36m0.0076\u001b[0m  0.0139\n",
            "     28        \u001b[36m0.0073\u001b[0m  0.0138\n",
            "     29        \u001b[36m0.0071\u001b[0m  0.0148\n",
            "     30        \u001b[36m0.0068\u001b[0m  0.0113\n",
            "     31        0.0068  0.0120\n",
            "     32        \u001b[36m0.0068\u001b[0m  0.0152\n",
            "     33        \u001b[36m0.0063\u001b[0m  0.0132\n",
            "     34        \u001b[36m0.0059\u001b[0m  0.0126\n",
            "     35        \u001b[36m0.0059\u001b[0m  0.0109\n",
            "     36        0.0060  0.0108\n",
            "     37        0.0060  0.0134\n",
            "     38        \u001b[36m0.0055\u001b[0m  0.0138\n",
            "     39        0.0055  0.0140\n",
            "     40        0.0056  0.0132\n",
            "     41        \u001b[36m0.0053\u001b[0m  0.0123\n",
            "     42        0.0055  0.0110\n",
            "     43        \u001b[36m0.0050\u001b[0m  0.0111\n",
            "     44        0.0050  0.0148\n",
            "     45        0.0053  0.0143\n",
            "     46        0.0051  0.0127\n",
            "     47        0.0054  0.0110\n",
            "     48        0.0050  0.0109\n",
            "     49        0.0052  0.0151\n",
            "     50        \u001b[36m0.0049\u001b[0m  0.0150\n",
            "     51        \u001b[36m0.0048\u001b[0m  0.0139\n",
            "     52        \u001b[36m0.0043\u001b[0m  0.0200\n",
            "     53        0.0047  0.0149\n",
            "     54        0.0045  0.0164\n",
            "     55        0.0044  0.0148\n",
            "     56        0.0045  0.0114\n",
            "     57        0.0045  0.0113\n",
            "     58        0.0044  0.0149\n",
            "     59        \u001b[36m0.0043\u001b[0m  0.0146\n",
            "     60        0.0044  0.0125\n",
            "     61        0.0044  0.0135\n",
            "     62        0.0043  0.0131\n",
            "     63        \u001b[36m0.0040\u001b[0m  0.0135\n",
            "     64        0.0043  0.0112\n",
            "     65        0.0040  0.0112\n",
            "     66        \u001b[36m0.0038\u001b[0m  0.0144\n",
            "     67        0.0041  0.0153\n",
            "     68        0.0038  0.0142\n",
            "     69        0.0040  0.0133\n",
            "     70        0.0039  0.0112\n",
            "     71        0.0042  0.0114\n",
            "     72        \u001b[36m0.0037\u001b[0m  0.0175\n",
            "     73        0.0040  0.0145\n",
            "     74        0.0038  0.0133\n",
            "     75        0.0039  0.0124\n",
            "     76        0.0040  0.0113\n",
            "     77        0.0038  0.0114\n",
            "     78        \u001b[36m0.0035\u001b[0m  0.0144\n",
            "     79        \u001b[36m0.0035\u001b[0m  0.0144\n",
            "     80        0.0036  0.0192\n",
            "     81        0.0039  0.0186\n",
            "     82        0.0035  0.0155\n",
            "     83        0.0042  0.0133\n",
            "     84        \u001b[36m0.0034\u001b[0m  0.0139\n",
            "     85        0.0034  0.0113\n",
            "     86        \u001b[36m0.0034\u001b[0m  0.0114\n",
            "     87        0.0037  0.0153\n",
            "     88        0.0037  0.0142\n",
            "     89        0.0035  0.0129\n",
            "     90        0.0034  0.0115\n",
            "     91        \u001b[36m0.0033\u001b[0m  0.0111\n",
            "     92        0.0037  0.0139\n",
            "     93        0.0034  0.0144\n",
            "     94        0.0034  0.0156\n",
            "     95        0.0034  0.0112\n",
            "     96        0.0041  0.0109\n",
            "     97        \u001b[36m0.0032\u001b[0m  0.0168\n",
            "     98        0.0035  0.0142\n",
            "     99        0.0032  0.0140\n",
            "    100        0.0035  0.0125\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1328\u001b[0m  0.0163\n",
            "      2        \u001b[36m0.0723\u001b[0m  0.0148\n",
            "      3        \u001b[36m0.0532\u001b[0m  0.0153\n",
            "      4        \u001b[36m0.0429\u001b[0m  0.0138\n",
            "      5        \u001b[36m0.0346\u001b[0m  0.0121\n",
            "      6        \u001b[36m0.0287\u001b[0m  0.0122\n",
            "      7        \u001b[36m0.0240\u001b[0m  0.0186\n",
            "      8        \u001b[36m0.0216\u001b[0m  0.0147\n",
            "      9        \u001b[36m0.0186\u001b[0m  0.0121\n",
            "     10        \u001b[36m0.0163\u001b[0m  0.0122\n",
            "     11        \u001b[36m0.0149\u001b[0m  0.0165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0131\u001b[0m  0.0160\n",
            "     13        \u001b[36m0.0122\u001b[0m  0.0157\n",
            "     14        \u001b[36m0.0115\u001b[0m  0.0136\n",
            "     15        \u001b[36m0.0112\u001b[0m  0.0121\n",
            "     16        \u001b[36m0.0105\u001b[0m  0.0119\n",
            "     17        \u001b[36m0.0095\u001b[0m  0.0163\n",
            "     18        \u001b[36m0.0089\u001b[0m  0.0169\n",
            "     19        \u001b[36m0.0084\u001b[0m  0.0136\n",
            "     20        \u001b[36m0.0078\u001b[0m  0.0119\n",
            "     21        \u001b[36m0.0075\u001b[0m  0.0122\n",
            "     22        0.0076  0.0167\n",
            "     23        \u001b[36m0.0065\u001b[0m  0.0147\n",
            "     24        0.0067  0.0137\n",
            "     25        0.0069  0.0184\n",
            "     26        0.0066  0.0148\n",
            "     27        \u001b[36m0.0063\u001b[0m  0.0173\n",
            "     28        \u001b[36m0.0058\u001b[0m  0.0180\n",
            "     29        \u001b[36m0.0056\u001b[0m  0.0217\n",
            "     30        \u001b[36m0.0056\u001b[0m  0.0167\n",
            "     31        0.0057  0.0153\n",
            "     32        0.0057  0.0137\n",
            "     33        \u001b[36m0.0048\u001b[0m  0.0159\n",
            "     34        0.0055  0.0136\n",
            "     35        0.0055  0.0133\n",
            "     36        0.0050  0.0156\n",
            "     37        0.0051  0.0136\n",
            "     38        0.0049  0.0123\n",
            "     39        \u001b[36m0.0047\u001b[0m  0.0121\n",
            "     40        0.0047  0.0175\n",
            "     41        0.0048  0.0149\n",
            "     42        0.0048  0.0138\n",
            "     43        \u001b[36m0.0045\u001b[0m  0.0122\n",
            "     44        0.0046  0.0122\n",
            "     45        0.0046  0.0164\n",
            "     46        0.0045  0.0207\n",
            "     47        \u001b[36m0.0043\u001b[0m  0.0185\n",
            "     48        \u001b[36m0.0043\u001b[0m  0.0148\n",
            "     49        \u001b[36m0.0042\u001b[0m  0.0141\n",
            "     50        0.0043  0.0149\n",
            "     51        \u001b[36m0.0038\u001b[0m  0.0137\n",
            "     52        0.0039  0.0165\n",
            "     53        0.0041  0.0140\n",
            "     54        0.0039  0.0140\n",
            "     55        0.0039  0.0122\n",
            "     56        0.0039  0.0125\n",
            "     57        0.0039  0.0164\n",
            "     58        0.0039  0.0157\n",
            "     59        \u001b[36m0.0038\u001b[0m  0.0122\n",
            "     60        0.0039  0.0134\n",
            "     61        0.0039  0.0165\n",
            "     62        \u001b[36m0.0036\u001b[0m  0.0143\n",
            "     63        0.0038  0.0122\n",
            "     64        0.0037  0.0122\n",
            "     65        0.0038  0.0181\n",
            "     66        0.0037  0.0134\n",
            "     67        \u001b[36m0.0036\u001b[0m  0.0131\n",
            "     68        0.0038  0.0124\n",
            "     69        \u001b[36m0.0036\u001b[0m  0.0164\n",
            "     70        \u001b[36m0.0034\u001b[0m  0.0142\n",
            "     71        0.0034  0.0153\n",
            "     72        0.0035  0.0121\n",
            "     73        \u001b[36m0.0033\u001b[0m  0.0125\n",
            "     74        0.0034  0.0170\n",
            "     75        0.0035  0.0136\n",
            "     76        0.0035  0.0137\n",
            "     77        0.0035  0.0121\n",
            "     78        0.0035  0.0118\n",
            "     79        0.0035  0.0167\n",
            "     80        0.0033  0.0144\n",
            "     81        0.0035  0.0138\n",
            "     82        \u001b[36m0.0032\u001b[0m  0.0126\n",
            "     83        0.0034  0.0127\n",
            "     84        0.0035  0.0158\n",
            "     85        0.0033  0.0159\n",
            "     86        0.0032  0.0131\n",
            "     87        \u001b[36m0.0031\u001b[0m  0.0123\n",
            "     88        \u001b[36m0.0031\u001b[0m  0.0166\n",
            "     89        \u001b[36m0.0031\u001b[0m  0.0138\n",
            "     90        \u001b[36m0.0030\u001b[0m  0.0121\n",
            "     91        \u001b[36m0.0030\u001b[0m  0.0121\n",
            "     92        0.0031  0.0158\n",
            "     93        \u001b[36m0.0029\u001b[0m  0.0158\n",
            "     94        0.0031  0.0140\n",
            "     95        \u001b[36m0.0029\u001b[0m  0.0138\n",
            "     96        0.0031  0.0139\n",
            "     97        0.0030  0.0158\n",
            "     98        0.0030  0.0163\n",
            "     99        0.0030  0.0123\n",
            "    100        0.0031  0.0128\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1667\u001b[0m  0.0071\n",
            "      2        \u001b[36m0.1040\u001b[0m  0.0081\n",
            "      3        \u001b[36m0.0781\u001b[0m  0.0094\n",
            "      4        \u001b[36m0.0620\u001b[0m  0.0085\n",
            "      5        \u001b[36m0.0518\u001b[0m  0.0073\n",
            "      6        \u001b[36m0.0472\u001b[0m  0.0062\n",
            "      7        \u001b[36m0.0417\u001b[0m  0.0069\n",
            "      8        \u001b[36m0.0360\u001b[0m  0.0071\n",
            "      9        \u001b[36m0.0327\u001b[0m  0.0110\n",
            "     10        \u001b[36m0.0304\u001b[0m  0.0089\n",
            "     11        \u001b[36m0.0275\u001b[0m  0.0076\n",
            "     12        \u001b[36m0.0239\u001b[0m  0.0073\n",
            "     13        \u001b[36m0.0212\u001b[0m  0.0074\n",
            "     14        \u001b[36m0.0202\u001b[0m  0.0069\n",
            "     15        \u001b[36m0.0181\u001b[0m  0.0068\n",
            "     16        \u001b[36m0.0175\u001b[0m  0.0075\n",
            "     17        \u001b[36m0.0153\u001b[0m  0.0072\n",
            "     18        \u001b[36m0.0150\u001b[0m  0.0074\n",
            "     19        \u001b[36m0.0131\u001b[0m  0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     20        \u001b[36m0.0121\u001b[0m  0.0078\n",
            "     21        \u001b[36m0.0120\u001b[0m  0.0082\n",
            "     22        0.0120  0.0077\n",
            "     23        \u001b[36m0.0103\u001b[0m  0.0074\n",
            "     24        \u001b[36m0.0097\u001b[0m  0.0077\n",
            "     25        \u001b[36m0.0090\u001b[0m  0.0081\n",
            "     26        \u001b[36m0.0087\u001b[0m  0.0076\n",
            "     27        \u001b[36m0.0079\u001b[0m  0.0079\n",
            "     28        \u001b[36m0.0079\u001b[0m  0.0072\n",
            "     29        \u001b[36m0.0077\u001b[0m  0.0087\n",
            "     30        \u001b[36m0.0076\u001b[0m  0.0071\n",
            "     31        \u001b[36m0.0069\u001b[0m  0.0073\n",
            "     32        \u001b[36m0.0068\u001b[0m  0.0072\n",
            "     33        0.0072  0.0074\n",
            "     34        \u001b[36m0.0063\u001b[0m  0.0069\n",
            "     35        0.0066  0.0075\n",
            "     36        \u001b[36m0.0060\u001b[0m  0.0089\n",
            "     37        \u001b[36m0.0059\u001b[0m  0.0072\n",
            "     38        \u001b[36m0.0052\u001b[0m  0.0069\n",
            "     39        0.0052  0.0071\n",
            "     40        0.0053  0.0070\n",
            "     41        0.0055  0.0079\n",
            "     42        \u001b[36m0.0049\u001b[0m  0.0071\n",
            "     43        0.0053  0.0069\n",
            "     44        \u001b[36m0.0047\u001b[0m  0.0105\n",
            "     45        0.0048  0.0080\n",
            "     46        0.0051  0.0086\n",
            "     47        0.0049  0.0081\n",
            "     48        \u001b[36m0.0045\u001b[0m  0.0083\n",
            "     49        0.0046  0.0076\n",
            "     50        0.0048  0.0080\n",
            "     51        0.0048  0.0072\n",
            "     52        \u001b[36m0.0041\u001b[0m  0.0079\n",
            "     53        \u001b[36m0.0040\u001b[0m  0.0098\n",
            "     54        0.0047  0.0081\n",
            "     55        0.0043  0.0084\n",
            "     56        \u001b[36m0.0040\u001b[0m  0.0083\n",
            "     57        0.0040  0.0077\n",
            "     58        \u001b[36m0.0039\u001b[0m  0.0076\n",
            "     59        0.0040  0.0081\n",
            "     60        \u001b[36m0.0037\u001b[0m  0.0078\n",
            "     61        \u001b[36m0.0035\u001b[0m  0.0079\n",
            "     62        \u001b[36m0.0035\u001b[0m  0.0107\n",
            "     63        \u001b[36m0.0034\u001b[0m  0.0083\n",
            "     64        0.0039  0.0079\n",
            "     65        \u001b[36m0.0033\u001b[0m  0.0099\n",
            "     66        0.0038  0.0090\n",
            "     67        0.0036  0.0079\n",
            "     68        \u001b[36m0.0031\u001b[0m  0.0076\n",
            "     69        0.0037  0.0080\n",
            "     70        \u001b[36m0.0030\u001b[0m  0.0073\n",
            "     71        0.0035  0.0071\n",
            "     72        0.0033  0.0068\n",
            "     73        0.0033  0.0074\n",
            "     74        0.0032  0.0070\n",
            "     75        \u001b[36m0.0029\u001b[0m  0.0077\n",
            "     76        0.0031  0.0073\n",
            "     77        0.0033  0.0069\n",
            "     78        \u001b[36m0.0027\u001b[0m  0.0073\n",
            "     79        0.0030  0.0078\n",
            "     80        0.0031  0.0078\n",
            "     81        0.0029  0.0075\n",
            "     82        0.0034  0.0072\n",
            "     83        0.0028  0.0075\n",
            "     84        0.0029  0.0072\n",
            "     85        0.0029  0.0067\n",
            "     86        0.0028  0.0098\n",
            "     87        \u001b[36m0.0026\u001b[0m  0.0083\n",
            "     88        \u001b[36m0.0025\u001b[0m  0.0084\n",
            "     89        0.0029  0.0076\n",
            "     90        0.0029  0.0073\n",
            "     91        0.0027  0.0121\n",
            "     92        \u001b[36m0.0025\u001b[0m  0.0093\n",
            "     93        0.0029  0.0073\n",
            "     94        0.0028  0.0069\n",
            "     95        0.0025  0.0070\n",
            "     96        0.0025  0.0066\n",
            "     97        0.0025  0.0069\n",
            "     98        0.0026  0.0071\n",
            "     99        0.0028  0.0070\n",
            "    100        \u001b[36m0.0024\u001b[0m  0.0072\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1760\u001b[0m  0.0152\n",
            "      2        \u001b[36m0.0919\u001b[0m  0.0142\n",
            "      3        \u001b[36m0.0651\u001b[0m  0.0138\n",
            "      4        \u001b[36m0.0516\u001b[0m  0.0161\n",
            "      5        \u001b[36m0.0425\u001b[0m  0.0160\n",
            "      6        \u001b[36m0.0364\u001b[0m  0.0155\n",
            "      7        \u001b[36m0.0312\u001b[0m  0.0152\n",
            "      8        \u001b[36m0.0275\u001b[0m  0.0138\n",
            "      9        \u001b[36m0.0241\u001b[0m  0.0141\n",
            "     10        \u001b[36m0.0206\u001b[0m  0.0142\n",
            "     11        \u001b[36m0.0193\u001b[0m  0.0144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0178\u001b[0m  0.0147\n",
            "     13        \u001b[36m0.0161\u001b[0m  0.0144\n",
            "     14        \u001b[36m0.0151\u001b[0m  0.0207\n",
            "     15        \u001b[36m0.0133\u001b[0m  0.0148\n",
            "     16        0.0135  0.0142\n",
            "     17        \u001b[36m0.0122\u001b[0m  0.0142\n",
            "     18        \u001b[36m0.0118\u001b[0m  0.0144\n",
            "     19        \u001b[36m0.0110\u001b[0m  0.0142\n",
            "     20        \u001b[36m0.0105\u001b[0m  0.0162\n",
            "     21        \u001b[36m0.0097\u001b[0m  0.0143\n",
            "     22        \u001b[36m0.0093\u001b[0m  0.0146\n",
            "     23        \u001b[36m0.0087\u001b[0m  0.0152\n",
            "     24        \u001b[36m0.0087\u001b[0m  0.0144\n",
            "     25        0.0087  0.0159\n",
            "     26        \u001b[36m0.0084\u001b[0m  0.0151\n",
            "     27        \u001b[36m0.0075\u001b[0m  0.0149\n",
            "     28        0.0079  0.0139\n",
            "     29        \u001b[36m0.0073\u001b[0m  0.0144\n",
            "     30        \u001b[36m0.0071\u001b[0m  0.0140\n",
            "     31        0.0074  0.0144\n",
            "     32        0.0073  0.0139\n",
            "     33        0.0072  0.0150\n",
            "     34        \u001b[36m0.0065\u001b[0m  0.0150\n",
            "     35        0.0065  0.0138\n",
            "     36        0.0066  0.0140\n",
            "     37        \u001b[36m0.0062\u001b[0m  0.0143\n",
            "     38        0.0065  0.0138\n",
            "     39        \u001b[36m0.0060\u001b[0m  0.0160\n",
            "     40        0.0064  0.0166\n",
            "     41        0.0061  0.0139\n",
            "     42        \u001b[36m0.0059\u001b[0m  0.0141\n",
            "     43        \u001b[36m0.0058\u001b[0m  0.0140\n",
            "     44        \u001b[36m0.0056\u001b[0m  0.0137\n",
            "     45        0.0056  0.0141\n",
            "     46        0.0056  0.0138\n",
            "     47        0.0056  0.0144\n",
            "     48        \u001b[36m0.0051\u001b[0m  0.0139\n",
            "     49        0.0052  0.0146\n",
            "     50        0.0056  0.0138\n",
            "     51        \u001b[36m0.0049\u001b[0m  0.0138\n",
            "     52        0.0052  0.0138\n",
            "     53        0.0051  0.0138\n",
            "     54        0.0056  0.0137\n",
            "     55        0.0053  0.0140\n",
            "     56        0.0049  0.0139\n",
            "     57        \u001b[36m0.0047\u001b[0m  0.0161\n",
            "     58        0.0049  0.0159\n",
            "     59        0.0050  0.0156\n",
            "     60        \u001b[36m0.0046\u001b[0m  0.0141\n",
            "     61        0.0051  0.0144\n",
            "     62        0.0053  0.0142\n",
            "     63        0.0046  0.0138\n",
            "     64        0.0048  0.0142\n",
            "     65        0.0047  0.0142\n",
            "     66        0.0048  0.0141\n",
            "     67        \u001b[36m0.0044\u001b[0m  0.0139\n",
            "     68        0.0047  0.0140\n",
            "     69        0.0046  0.0141\n",
            "     70        0.0044  0.0142\n",
            "     71        \u001b[36m0.0043\u001b[0m  0.0188\n",
            "     72        0.0044  0.0182\n",
            "     73        0.0048  0.0211\n",
            "     74        \u001b[36m0.0042\u001b[0m  0.0174\n",
            "     75        \u001b[36m0.0041\u001b[0m  0.0138\n",
            "     76        \u001b[36m0.0040\u001b[0m  0.0139\n",
            "     77        0.0043  0.0145\n",
            "     78        0.0041  0.0136\n",
            "     79        0.0041  0.0143\n",
            "     80        0.0043  0.0139\n",
            "     81        0.0041  0.0137\n",
            "     82        \u001b[36m0.0038\u001b[0m  0.0137\n",
            "     83        0.0041  0.0138\n",
            "     84        \u001b[36m0.0037\u001b[0m  0.0134\n",
            "     85        0.0041  0.0138\n",
            "     86        0.0039  0.0141\n",
            "     87        0.0037  0.0139\n",
            "     88        0.0042  0.0143\n",
            "     89        0.0039  0.0144\n",
            "     90        0.0039  0.0146\n",
            "     91        0.0037  0.0166\n",
            "     92        0.0038  0.0158\n",
            "     93        0.0037  0.0147\n",
            "     94        0.0038  0.0147\n",
            "     95        0.0041  0.0151\n",
            "     96        0.0038  0.0146\n",
            "     97        \u001b[36m0.0036\u001b[0m  0.0139\n",
            "     98        0.0038  0.0177\n",
            "     99        0.0036  0.0155\n",
            "    100        0.0037  0.0151\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1634\u001b[0m  0.0179\n",
            "      2        \u001b[36m0.1022\u001b[0m  0.0152\n",
            "      3        \u001b[36m0.0797\u001b[0m  0.0148\n",
            "      4        \u001b[36m0.0666\u001b[0m  0.0166\n",
            "      5        \u001b[36m0.0554\u001b[0m  0.0148\n",
            "      6        \u001b[36m0.0468\u001b[0m  0.0147\n",
            "      7        \u001b[36m0.0414\u001b[0m  0.0146\n",
            "      8        \u001b[36m0.0363\u001b[0m  0.0151\n",
            "      9        \u001b[36m0.0308\u001b[0m  0.0148\n",
            "     10        \u001b[36m0.0273\u001b[0m  0.0149\n",
            "     11        \u001b[36m0.0243\u001b[0m  0.0143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0214\u001b[0m  0.0149\n",
            "     13        \u001b[36m0.0189\u001b[0m  0.0147\n",
            "     14        \u001b[36m0.0168\u001b[0m  0.0149\n",
            "     15        \u001b[36m0.0151\u001b[0m  0.0150\n",
            "     16        \u001b[36m0.0145\u001b[0m  0.0148\n",
            "     17        \u001b[36m0.0126\u001b[0m  0.0147\n",
            "     18        \u001b[36m0.0114\u001b[0m  0.0150\n",
            "     19        \u001b[36m0.0105\u001b[0m  0.0147\n",
            "     20        0.0105  0.0165\n",
            "     21        \u001b[36m0.0092\u001b[0m  0.0164\n",
            "     22        \u001b[36m0.0088\u001b[0m  0.0163\n",
            "     23        \u001b[36m0.0082\u001b[0m  0.0148\n",
            "     24        \u001b[36m0.0078\u001b[0m  0.0147\n",
            "     25        \u001b[36m0.0075\u001b[0m  0.0148\n",
            "     26        \u001b[36m0.0070\u001b[0m  0.0147\n",
            "     27        \u001b[36m0.0065\u001b[0m  0.0148\n",
            "     28        0.0069  0.0149\n",
            "     29        \u001b[36m0.0063\u001b[0m  0.0151\n",
            "     30        0.0065  0.0193\n",
            "     31        \u001b[36m0.0058\u001b[0m  0.0152\n",
            "     32        0.0060  0.0158\n",
            "     33        0.0060  0.0157\n",
            "     34        0.0058  0.0156\n",
            "     35        \u001b[36m0.0057\u001b[0m  0.0207\n",
            "     36        \u001b[36m0.0052\u001b[0m  0.0188\n",
            "     37        0.0054  0.0174\n",
            "     38        \u001b[36m0.0050\u001b[0m  0.0193\n",
            "     39        0.0052  0.0173\n",
            "     40        0.0050  0.0157\n",
            "     41        0.0051  0.0152\n",
            "     42        \u001b[36m0.0049\u001b[0m  0.0161\n",
            "     43        \u001b[36m0.0047\u001b[0m  0.0197\n",
            "     44        0.0049  0.0163\n",
            "     45        0.0048  0.0203\n",
            "     46        0.0049  0.0156\n",
            "     47        0.0048  0.0175\n",
            "     48        \u001b[36m0.0044\u001b[0m  0.0228\n",
            "     49        0.0044  0.0178\n",
            "     50        0.0047  0.0187\n",
            "     51        \u001b[36m0.0041\u001b[0m  0.0183\n",
            "     52        \u001b[36m0.0040\u001b[0m  0.0197\n",
            "     53        0.0043  0.0160\n",
            "     54        0.0040  0.0167\n",
            "     55        0.0042  0.0163\n",
            "     56        0.0043  0.0163\n",
            "     57        \u001b[36m0.0040\u001b[0m  0.0174\n",
            "     58        0.0041  0.0172\n",
            "     59        \u001b[36m0.0038\u001b[0m  0.0165\n",
            "     60        0.0040  0.0176\n",
            "     61        \u001b[36m0.0038\u001b[0m  0.0169\n",
            "     62        \u001b[36m0.0038\u001b[0m  0.0178\n",
            "     63        0.0038  0.0188\n",
            "     64        0.0039  0.0189\n",
            "     65        \u001b[36m0.0036\u001b[0m  0.0165\n",
            "     66        0.0037  0.0166\n",
            "     67        \u001b[36m0.0036\u001b[0m  0.0201\n",
            "     68        0.0038  0.0174\n",
            "     69        0.0038  0.0197\n",
            "     70        0.0040  0.0219\n",
            "     71        \u001b[36m0.0036\u001b[0m  0.0162\n",
            "     72        \u001b[36m0.0034\u001b[0m  0.0163\n",
            "     73        0.0036  0.0160\n",
            "     74        0.0036  0.0154\n",
            "     75        \u001b[36m0.0032\u001b[0m  0.0196\n",
            "     76        0.0035  0.0175\n",
            "     77        0.0033  0.0163\n",
            "     78        0.0034  0.0165\n",
            "     79        0.0034  0.0148\n",
            "     80        0.0036  0.0150\n",
            "     81        0.0036  0.0201\n",
            "     82        0.0036  0.0169\n",
            "     83        0.0032  0.0166\n",
            "     84        0.0033  0.0170\n",
            "     85        0.0033  0.0170\n",
            "     86        0.0033  0.0172\n",
            "     87        0.0035  0.0167\n",
            "     88        \u001b[36m0.0031\u001b[0m  0.0171\n",
            "     89        \u001b[36m0.0031\u001b[0m  0.0168\n",
            "     90        \u001b[36m0.0031\u001b[0m  0.0198\n",
            "     91        0.0032  0.0170\n",
            "     92        \u001b[36m0.0030\u001b[0m  0.0169\n",
            "     93        0.0033  0.0188\n",
            "     94        0.0032  0.0176\n",
            "     95        0.0033  0.0167\n",
            "     96        0.0030  0.0214\n",
            "     97        0.0031  0.0189\n",
            "     98        0.0030  0.0166\n",
            "     99        0.0032  0.0197\n",
            "    100        0.0031  0.0192\n",
            "Best CNN params: {'model__module__filters': (32, 64), 'model__module__kernel_size': 7, 'model__lr': 0.001} score: -0.12526510655879974\n",
            "Best TCN params: {'model__module__filters': (32, 64), 'model__module__kernel_size': 5, 'model__module__dilations': (1, 2, 4, 8), 'model__lr': 0.001} score: -0.14985625445842743\n",
            "Best CRNN params: {'model__module__filters': (32, 64), 'model__module__kernel_size': 3, 'model__module__rnn_type': 'lstm', 'model__module__rnn_units': 128, 'model__lr': 0.001} score: -0.0861889123916626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Amostra de dados (ex.: 30% final) para acelerar a busca\n",
        "frac = 0.3\n",
        "start = int((1.0-frac) * len(X_full))\n",
        "X_part = X_full[start:]\n",
        "\n",
        "# Grids\n",
        "pca_param = {\"n_components\": [0.9, 0.95, 0.99]}\n",
        "\n",
        "cnn_param = {\n",
        "    \"model__module__filters\": [(32,64), (32,64,128)],\n",
        "    \"model__module__kernel_size\": [3,5,7],\n",
        "    \"model__lr\": [1e-3, 5e-4],\n",
        "}\n",
        "\n",
        "tcn_param = {\n",
        "    \"model__module__filters\": [(32,64), (32,64,128)],\n",
        "    \"model__module__kernel_size\": [3,5],\n",
        "    \"model__module__dilations\": [(1,2,4,8), (1,2,4,8,16)],\n",
        "    \"model__lr\": [1e-3, 5e-4],\n",
        "}\n",
        "\n",
        "crnn_param = {\n",
        "    \"model__module__filters\": [(32,64), (32,64,128)],\n",
        "    \"model__module__kernel_size\": [3,5],\n",
        "    \"model__module__rnn_type\": [\"gru\", \"lstm\"],\n",
        "    \"model__module__rnn_units\": [32, 64, 128],\n",
        "    \"model__lr\": [1e-3, 5e-4],\n",
        "}\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=3)\n",
        "\n",
        "def randomized_search_pipe(pipe, param_distributions, n_iter=8):\n",
        "    best_score = -np.inf; best_params = None\n",
        "    keys = list(param_distributions.keys())\n",
        "    for it in range(n_iter):\n",
        "        params = {k: random.choice(v) for k,v in param_distributions.items()}\n",
        "        scores = []\n",
        "        for tr, va in tscv.split(X_part):\n",
        "            Xtr, Xva = X_part[tr], X_part[va]\n",
        "            pipe.set_params(**params)\n",
        "            # fit AE no treino\n",
        "            Xw_tr = pipe[:-1].fit_transform(Xtr)  # (N,T,F)\n",
        "            model = pipe.named_steps[\"model\"]\n",
        "            model.fit(Xw_tr, Xw_tr)\n",
        "            # score no val (MAE de reconstrução negativo para usar como max)\n",
        "            Xw_va = pipe[:-1].transform(Xva)\n",
        "            yhat = model.predict(Xw_va)\n",
        "            score = -np.mean(np.abs(yhat - Xw_va))\n",
        "            scores.append(score)\n",
        "        avg = float(np.mean(scores)) if scores else -np.inf\n",
        "        if avg > best_score:\n",
        "            best_score = avg; best_params = params\n",
        "    return best_params, best_score\n",
        "\n",
        "best_pca = {\"n_components\": 0.95}\n",
        "best_cnn_params, best_cnn_score = randomized_search_pipe(cnn_ae_pipeline, cnn_param, n_iter=8)\n",
        "best_tcn_params, best_tcn_score = randomized_search_pipe(tcn_ae_pipeline, tcn_param, n_iter=8)\n",
        "best_crnn_params, best_crnn_score = randomized_search_pipe(crnn_ae_pipeline, crnn_param, n_iter=8)\n",
        "\n",
        "print(\"Best CNN params:\", best_cnn_params, \"score:\", best_cnn_score)\n",
        "print(\"Best TCN params:\", best_tcn_params, \"score:\", best_tcn_score)\n",
        "print(\"Best CRNN params:\", best_crnn_params, \"score:\", best_crnn_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6445d5a0",
      "metadata": {
        "id": "6445d5a0"
      },
      "source": [
        "## Célula 5 — Treino completo (10 folds) com melhores hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "49886487",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49886487",
        "outputId": "8dacb67e-948c-47b1-83aa-981a345d9307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1392\u001b[0m  0.0380\n",
            "      2        \u001b[36m0.1038\u001b[0m  0.0110\n",
            "      3        \u001b[36m0.0890\u001b[0m  0.0061\n",
            "      4        \u001b[36m0.0792\u001b[0m  0.0126\n",
            "      5        \u001b[36m0.0724\u001b[0m  0.0107\n",
            "      6        \u001b[36m0.0686\u001b[0m  0.0060\n",
            "      7        \u001b[36m0.0629\u001b[0m  0.0120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.0591\u001b[0m  0.0076\n",
            "      9        \u001b[36m0.0549\u001b[0m  0.0064\n",
            "     10        0.0552  0.0065\n",
            "     11        \u001b[36m0.0498\u001b[0m  0.0065\n",
            "     12        \u001b[36m0.0481\u001b[0m  0.0066\n",
            "     13        \u001b[36m0.0459\u001b[0m  0.0064\n",
            "     14        \u001b[36m0.0435\u001b[0m  0.0064\n",
            "     15        \u001b[36m0.0421\u001b[0m  0.0080\n",
            "     16        \u001b[36m0.0402\u001b[0m  0.0070\n",
            "     17        \u001b[36m0.0383\u001b[0m  0.0066\n",
            "     18        \u001b[36m0.0360\u001b[0m  0.0079\n",
            "     19        \u001b[36m0.0339\u001b[0m  0.0082\n",
            "     20        0.0343  0.0070\n",
            "     21        \u001b[36m0.0334\u001b[0m  0.0070\n",
            "     22        \u001b[36m0.0320\u001b[0m  0.0062\n",
            "     23        \u001b[36m0.0302\u001b[0m  0.0064\n",
            "     24        \u001b[36m0.0288\u001b[0m  0.0060\n",
            "     25        \u001b[36m0.0273\u001b[0m  0.0063\n",
            "     26        \u001b[36m0.0265\u001b[0m  0.0063\n",
            "     27        \u001b[36m0.0259\u001b[0m  0.0063\n",
            "     28        \u001b[36m0.0259\u001b[0m  0.0064\n",
            "     29        0.0259  0.0065\n",
            "     30        \u001b[36m0.0243\u001b[0m  0.0067\n",
            "     31        \u001b[36m0.0224\u001b[0m  0.0066\n",
            "     32        0.0225  0.0063\n",
            "     33        \u001b[36m0.0215\u001b[0m  0.0063\n",
            "     34        \u001b[36m0.0208\u001b[0m  0.0063\n",
            "     35        0.0215  0.0078\n",
            "     36        \u001b[36m0.0190\u001b[0m  0.0068\n",
            "     37        \u001b[36m0.0182\u001b[0m  0.0060\n",
            "     38        0.0187  0.0054\n",
            "     39        \u001b[36m0.0180\u001b[0m  0.0057\n",
            "     40        \u001b[36m0.0177\u001b[0m  0.0055\n",
            "     41        \u001b[36m0.0170\u001b[0m  0.0057\n",
            "     42        \u001b[36m0.0160\u001b[0m  0.0052\n",
            "     43        0.0167  0.0051\n",
            "     44        \u001b[36m0.0160\u001b[0m  0.0052\n",
            "     45        \u001b[36m0.0153\u001b[0m  0.0053\n",
            "     46        0.0156  0.0053\n",
            "     47        \u001b[36m0.0151\u001b[0m  0.0061\n",
            "     48        \u001b[36m0.0142\u001b[0m  0.0053\n",
            "     49        0.0148  0.0057\n",
            "     50        \u001b[36m0.0142\u001b[0m  0.0052\n",
            "     51        \u001b[36m0.0127\u001b[0m  0.0056\n",
            "     52        0.0143  0.0069\n",
            "     53        0.0131  0.0055\n",
            "     54        0.0129  0.0052\n",
            "     55        \u001b[36m0.0125\u001b[0m  0.0065\n",
            "     56        \u001b[36m0.0121\u001b[0m  0.0057\n",
            "     57        \u001b[36m0.0120\u001b[0m  0.0057\n",
            "     58        \u001b[36m0.0114\u001b[0m  0.0054\n",
            "     59        \u001b[36m0.0103\u001b[0m  0.0053\n",
            "     60        0.0104  0.0054\n",
            "     61        0.0105  0.0054\n",
            "     62        0.0105  0.0055\n",
            "     63        0.0107  0.0063\n",
            "     64        \u001b[36m0.0102\u001b[0m  0.0057\n",
            "     65        0.0112  0.0057\n",
            "     66        \u001b[36m0.0099\u001b[0m  0.0056\n",
            "     67        0.0106  0.0056\n",
            "     68        \u001b[36m0.0094\u001b[0m  0.0059\n",
            "     69        0.0103  0.0056\n",
            "     70        \u001b[36m0.0092\u001b[0m  0.0057\n",
            "     71        0.0095  0.0056\n",
            "     72        \u001b[36m0.0090\u001b[0m  0.0057\n",
            "     73        0.0095  0.0056\n",
            "     74        0.0091  0.0056\n",
            "     75        \u001b[36m0.0088\u001b[0m  0.0058\n",
            "     76        0.0089  0.0053\n",
            "     77        \u001b[36m0.0082\u001b[0m  0.0054\n",
            "     78        0.0093  0.0053\n",
            "     79        0.0085  0.0054\n",
            "     80        0.0087  0.0054\n",
            "     81        0.0083  0.0084\n",
            "     82        0.0084  0.0058\n",
            "     83        0.0083  0.0067\n",
            "     84        \u001b[36m0.0080\u001b[0m  0.0055\n",
            "     85        \u001b[36m0.0079\u001b[0m  0.0054\n",
            "     86        0.0079  0.0061\n",
            "     87        0.0083  0.0053\n",
            "     88        \u001b[36m0.0075\u001b[0m  0.0054\n",
            "     89        0.0079  0.0052\n",
            "     90        \u001b[36m0.0073\u001b[0m  0.0063\n",
            "     91        \u001b[36m0.0067\u001b[0m  0.0065\n",
            "     92        0.0072  0.0061\n",
            "     93        0.0072  0.0058\n",
            "     94        0.0068  0.0056\n",
            "     95        0.0075  0.0055\n",
            "     96        0.0073  0.0054\n",
            "     97        \u001b[36m0.0066\u001b[0m  0.0053\n",
            "     98        0.0072  0.0055\n",
            "     99        0.0069  0.0054\n",
            "    100        0.0068  0.0060\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1494\u001b[0m  0.0185\n",
            "      2        \u001b[36m0.0999\u001b[0m  0.0100\n",
            "      3        \u001b[36m0.0836\u001b[0m  0.0097\n",
            "      4        \u001b[36m0.0724\u001b[0m  0.0097\n",
            "      5        \u001b[36m0.0657\u001b[0m  0.0096\n",
            "      6        \u001b[36m0.0610\u001b[0m  0.0098\n",
            "      7        \u001b[36m0.0574\u001b[0m  0.0096\n",
            "      8        \u001b[36m0.0529\u001b[0m  0.0102\n",
            "      9        \u001b[36m0.0490\u001b[0m  0.0108\n",
            "     10        \u001b[36m0.0466\u001b[0m  0.0096\n",
            "     11        \u001b[36m0.0435\u001b[0m  0.0108\n",
            "     12        \u001b[36m0.0409\u001b[0m  0.0101\n",
            "     13        \u001b[36m0.0392\u001b[0m  0.0100\n",
            "     14        \u001b[36m0.0359\u001b[0m  0.0103\n",
            "     15        \u001b[36m0.0344\u001b[0m  0.0101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     16        \u001b[36m0.0319\u001b[0m  0.0163\n",
            "     17        \u001b[36m0.0294\u001b[0m  0.0128\n",
            "     18        0.0294  0.0095\n",
            "     19        \u001b[36m0.0271\u001b[0m  0.0099\n",
            "     20        \u001b[36m0.0251\u001b[0m  0.0097\n",
            "     21        \u001b[36m0.0246\u001b[0m  0.0098\n",
            "     22        \u001b[36m0.0237\u001b[0m  0.0095\n",
            "     23        \u001b[36m0.0215\u001b[0m  0.0097\n",
            "     24        \u001b[36m0.0205\u001b[0m  0.0093\n",
            "     25        \u001b[36m0.0198\u001b[0m  0.0102\n",
            "     26        \u001b[36m0.0196\u001b[0m  0.0096\n",
            "     27        \u001b[36m0.0191\u001b[0m  0.0094\n",
            "     28        \u001b[36m0.0184\u001b[0m  0.0094\n",
            "     29        \u001b[36m0.0174\u001b[0m  0.0096\n",
            "     30        \u001b[36m0.0166\u001b[0m  0.0102\n",
            "     31        \u001b[36m0.0163\u001b[0m  0.0097\n",
            "     32        \u001b[36m0.0163\u001b[0m  0.0094\n",
            "     33        \u001b[36m0.0149\u001b[0m  0.0096\n",
            "     34        0.0153  0.0094\n",
            "     35        \u001b[36m0.0138\u001b[0m  0.0104\n",
            "     36        0.0143  0.0097\n",
            "     37        \u001b[36m0.0131\u001b[0m  0.0098\n",
            "     38        0.0137  0.0097\n",
            "     39        0.0131  0.0118\n",
            "     40        0.0131  0.0117\n",
            "     41        0.0131  0.0096\n",
            "     42        \u001b[36m0.0119\u001b[0m  0.0101\n",
            "     43        0.0126  0.0102\n",
            "     44        0.0125  0.0097\n",
            "     45        0.0121  0.0100\n",
            "     46        \u001b[36m0.0112\u001b[0m  0.0095\n",
            "     47        \u001b[36m0.0108\u001b[0m  0.0094\n",
            "     48        0.0124  0.0094\n",
            "     49        \u001b[36m0.0106\u001b[0m  0.0123\n",
            "     50        0.0115  0.0100\n",
            "     51        0.0109  0.0100\n",
            "     52        0.0106  0.0099\n",
            "     53        0.0108  0.0097\n",
            "     54        \u001b[36m0.0102\u001b[0m  0.0095\n",
            "     55        0.0104  0.0095\n",
            "     56        \u001b[36m0.0095\u001b[0m  0.0093\n",
            "     57        0.0096  0.0099\n",
            "     58        0.0106  0.0100\n",
            "     59        0.0096  0.0100\n",
            "     60        \u001b[36m0.0092\u001b[0m  0.0095\n",
            "     61        0.0095  0.0094\n",
            "     62        0.0097  0.0098\n",
            "     63        0.0101  0.0118\n",
            "     64        0.0101  0.0099\n",
            "     65        0.0094  0.0095\n",
            "     66        \u001b[36m0.0088\u001b[0m  0.0095\n",
            "     67        \u001b[36m0.0085\u001b[0m  0.0094\n",
            "     68        0.0089  0.0102\n",
            "     69        0.0089  0.0094\n",
            "     70        0.0095  0.0099\n",
            "     71        0.0093  0.0094\n",
            "     72        0.0087  0.0096\n",
            "     73        0.0086  0.0094\n",
            "     74        0.0093  0.0107\n",
            "     75        0.0093  0.0098\n",
            "     76        0.0092  0.0094\n",
            "     77        0.0087  0.0096\n",
            "     78        0.0086  0.0094\n",
            "     79        \u001b[36m0.0084\u001b[0m  0.0109\n",
            "     80        0.0086  0.0101\n",
            "     81        \u001b[36m0.0082\u001b[0m  0.0098\n",
            "     82        0.0084  0.0099\n",
            "     83        0.0082  0.0105\n",
            "     84        0.0087  0.0098\n",
            "     85        0.0087  0.0094\n",
            "     86        \u001b[36m0.0080\u001b[0m  0.0093\n",
            "     87        \u001b[36m0.0077\u001b[0m  0.0106\n",
            "     88        0.0082  0.0099\n",
            "     89        \u001b[36m0.0076\u001b[0m  0.0098\n",
            "     90        0.0081  0.0098\n",
            "     91        \u001b[36m0.0074\u001b[0m  0.0097\n",
            "     92        \u001b[36m0.0072\u001b[0m  0.0099\n",
            "     93        0.0075  0.0096\n",
            "     94        0.0079  0.0093\n",
            "     95        0.0083  0.0092\n",
            "     96        0.0074  0.0094\n",
            "     97        0.0074  0.0103\n",
            "     98        0.0080  0.0097\n",
            "     99        \u001b[36m0.0071\u001b[0m  0.0093\n",
            "    100        0.0073  0.0094\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1439\u001b[0m  0.0248\n",
            "      2        \u001b[36m0.0913\u001b[0m  0.0151\n",
            "      3        \u001b[36m0.0777\u001b[0m  0.0145\n",
            "      4        \u001b[36m0.0696\u001b[0m  0.0141\n",
            "      5        \u001b[36m0.0631\u001b[0m  0.0136\n",
            "      6        \u001b[36m0.0578\u001b[0m  0.0202\n",
            "      7        \u001b[36m0.0533\u001b[0m  0.0219\n",
            "      8        \u001b[36m0.0496\u001b[0m  0.0139\n",
            "      9        \u001b[36m0.0458\u001b[0m  0.0138\n",
            "     10        \u001b[36m0.0426\u001b[0m  0.0142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     11        \u001b[36m0.0401\u001b[0m  0.0155\n",
            "     12        \u001b[36m0.0368\u001b[0m  0.0141\n",
            "     13        \u001b[36m0.0353\u001b[0m  0.0140\n",
            "     14        \u001b[36m0.0334\u001b[0m  0.0141\n",
            "     15        \u001b[36m0.0316\u001b[0m  0.0144\n",
            "     16        \u001b[36m0.0301\u001b[0m  0.0143\n",
            "     17        \u001b[36m0.0290\u001b[0m  0.0143\n",
            "     18        \u001b[36m0.0270\u001b[0m  0.0139\n",
            "     19        \u001b[36m0.0258\u001b[0m  0.0145\n",
            "     20        \u001b[36m0.0245\u001b[0m  0.0145\n",
            "     21        \u001b[36m0.0236\u001b[0m  0.0141\n",
            "     22        \u001b[36m0.0222\u001b[0m  0.0169\n",
            "     23        \u001b[36m0.0212\u001b[0m  0.0158\n",
            "     24        \u001b[36m0.0201\u001b[0m  0.0141\n",
            "     25        \u001b[36m0.0199\u001b[0m  0.0143\n",
            "     26        \u001b[36m0.0193\u001b[0m  0.0141\n",
            "     27        \u001b[36m0.0189\u001b[0m  0.0143\n",
            "     28        \u001b[36m0.0187\u001b[0m  0.0140\n",
            "     29        \u001b[36m0.0176\u001b[0m  0.0143\n",
            "     30        \u001b[36m0.0168\u001b[0m  0.0138\n",
            "     31        0.0172  0.0145\n",
            "     32        \u001b[36m0.0165\u001b[0m  0.0140\n",
            "     33        \u001b[36m0.0162\u001b[0m  0.0148\n",
            "     34        \u001b[36m0.0148\u001b[0m  0.0141\n",
            "     35        0.0157  0.0141\n",
            "     36        0.0149  0.0150\n",
            "     37        \u001b[36m0.0143\u001b[0m  0.0148\n",
            "     38        \u001b[36m0.0141\u001b[0m  0.0143\n",
            "     39        0.0142  0.0155\n",
            "     40        0.0143  0.0138\n",
            "     41        0.0141  0.0145\n",
            "     42        \u001b[36m0.0140\u001b[0m  0.0143\n",
            "     43        0.0143  0.0150\n",
            "     44        \u001b[36m0.0138\u001b[0m  0.0143\n",
            "     45        \u001b[36m0.0134\u001b[0m  0.0142\n",
            "     46        \u001b[36m0.0133\u001b[0m  0.0142\n",
            "     47        \u001b[36m0.0125\u001b[0m  0.0139\n",
            "     48        0.0132  0.0147\n",
            "     49        \u001b[36m0.0124\u001b[0m  0.0154\n",
            "     50        \u001b[36m0.0115\u001b[0m  0.0144\n",
            "     51        0.0119  0.0154\n",
            "     52        0.0120  0.0140\n",
            "     53        0.0119  0.0145\n",
            "     54        0.0116  0.0140\n",
            "     55        \u001b[36m0.0112\u001b[0m  0.0142\n",
            "     56        \u001b[36m0.0107\u001b[0m  0.0149\n",
            "     57        0.0112  0.0145\n",
            "     58        0.0108  0.0145\n",
            "     59        \u001b[36m0.0101\u001b[0m  0.0142\n",
            "     60        0.0104  0.0139\n",
            "     61        0.0106  0.0147\n",
            "     62        0.0103  0.0143\n",
            "     63        0.0104  0.0147\n",
            "     64        \u001b[36m0.0099\u001b[0m  0.0142\n",
            "     65        0.0105  0.0159\n",
            "     66        0.0103  0.0157\n",
            "     67        0.0103  0.0141\n",
            "     68        0.0103  0.0136\n",
            "     69        0.0102  0.0151\n",
            "     70        0.0105  0.0140\n",
            "     71        \u001b[36m0.0097\u001b[0m  0.0144\n",
            "     72        0.0101  0.0152\n",
            "     73        \u001b[36m0.0096\u001b[0m  0.0171\n",
            "     74        0.0097  0.0213\n",
            "     75        \u001b[36m0.0092\u001b[0m  0.0149\n",
            "     76        0.0096  0.0138\n",
            "     77        0.0098  0.0141\n",
            "     78        \u001b[36m0.0091\u001b[0m  0.0141\n",
            "     79        0.0096  0.0136\n",
            "     80        0.0091  0.0147\n",
            "     81        0.0094  0.0144\n",
            "     82        0.0094  0.0141\n",
            "     83        0.0092  0.0137\n",
            "     84        \u001b[36m0.0088\u001b[0m  0.0147\n",
            "     85        \u001b[36m0.0084\u001b[0m  0.0142\n",
            "     86        0.0087  0.0140\n",
            "     87        0.0090  0.0135\n",
            "     88        0.0086  0.0144\n",
            "     89        0.0092  0.0140\n",
            "     90        0.0085  0.0175\n",
            "     91        0.0090  0.0148\n",
            "     92        0.0091  0.0144\n",
            "     93        0.0091  0.0143\n",
            "     94        \u001b[36m0.0083\u001b[0m  0.0143\n",
            "     95        0.0094  0.0138\n",
            "     96        0.0090  0.0146\n",
            "     97        0.0090  0.0141\n",
            "     98        0.0084  0.0224\n",
            "     99        0.0085  0.0166\n",
            "    100        \u001b[36m0.0081\u001b[0m  0.0143\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1358\u001b[0m  0.0245\n",
            "      2        \u001b[36m0.0904\u001b[0m  0.0143\n",
            "      3        \u001b[36m0.0745\u001b[0m  0.0154\n",
            "      4        \u001b[36m0.0645\u001b[0m  0.0163\n",
            "      5        \u001b[36m0.0571\u001b[0m  0.0144\n",
            "      6        \u001b[36m0.0514\u001b[0m  0.0147\n",
            "      7        \u001b[36m0.0458\u001b[0m  0.0148\n",
            "      8        \u001b[36m0.0425\u001b[0m  0.0147\n",
            "      9        \u001b[36m0.0380\u001b[0m  0.0147\n",
            "     10        \u001b[36m0.0350\u001b[0m  0.0157\n",
            "     11        \u001b[36m0.0316\u001b[0m  0.0168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     12        \u001b[36m0.0298\u001b[0m  0.0157\n",
            "     13        \u001b[36m0.0268\u001b[0m  0.0149\n",
            "     14        \u001b[36m0.0249\u001b[0m  0.0151\n",
            "     15        \u001b[36m0.0237\u001b[0m  0.0149\n",
            "     16        \u001b[36m0.0223\u001b[0m  0.0148\n",
            "     17        \u001b[36m0.0208\u001b[0m  0.0145\n",
            "     18        \u001b[36m0.0199\u001b[0m  0.0150\n",
            "     19        \u001b[36m0.0191\u001b[0m  0.0149\n",
            "     20        \u001b[36m0.0187\u001b[0m  0.0157\n",
            "     21        \u001b[36m0.0171\u001b[0m  0.0144\n",
            "     22        \u001b[36m0.0169\u001b[0m  0.0151\n",
            "     23        \u001b[36m0.0162\u001b[0m  0.0150\n",
            "     24        0.0162  0.0148\n",
            "     25        \u001b[36m0.0151\u001b[0m  0.0145\n",
            "     26        \u001b[36m0.0146\u001b[0m  0.0161\n",
            "     27        \u001b[36m0.0146\u001b[0m  0.0158\n",
            "     28        \u001b[36m0.0146\u001b[0m  0.0168\n",
            "     29        \u001b[36m0.0135\u001b[0m  0.0145\n",
            "     30        \u001b[36m0.0135\u001b[0m  0.0152\n",
            "     31        0.0135  0.0149\n",
            "     32        \u001b[36m0.0125\u001b[0m  0.0151\n",
            "     33        0.0133  0.0154\n",
            "     34        0.0126  0.0144\n",
            "     35        \u001b[36m0.0122\u001b[0m  0.0146\n",
            "     36        0.0125  0.0157\n",
            "     37        \u001b[36m0.0121\u001b[0m  0.0227\n",
            "     38        \u001b[36m0.0120\u001b[0m  0.0155\n",
            "     39        0.0120  0.0151\n",
            "     40        \u001b[36m0.0118\u001b[0m  0.0146\n",
            "     41        \u001b[36m0.0115\u001b[0m  0.0170\n",
            "     42        \u001b[36m0.0110\u001b[0m  0.0151\n",
            "     43        0.0111  0.0147\n",
            "     44        \u001b[36m0.0104\u001b[0m  0.0143\n",
            "     45        0.0107  0.0148\n",
            "     46        0.0111  0.0146\n",
            "     47        0.0110  0.0149\n",
            "     48        \u001b[36m0.0104\u001b[0m  0.0143\n",
            "     49        \u001b[36m0.0101\u001b[0m  0.0149\n",
            "     50        \u001b[36m0.0099\u001b[0m  0.0147\n",
            "     51        0.0101  0.0147\n",
            "     52        0.0101  0.0176\n",
            "     53        0.0103  0.0160\n",
            "     54        \u001b[36m0.0097\u001b[0m  0.0148\n",
            "     55        0.0101  0.0144\n",
            "     56        0.0099  0.0152\n",
            "     57        \u001b[36m0.0095\u001b[0m  0.0148\n",
            "     58        0.0099  0.0149\n",
            "     59        0.0095  0.0149\n",
            "     60        0.0095  0.0149\n",
            "     61        0.0097  0.0146\n",
            "     62        \u001b[36m0.0087\u001b[0m  0.0153\n",
            "     63        0.0088  0.0147\n",
            "     64        0.0090  0.0151\n",
            "     65        0.0090  0.0149\n",
            "     66        0.0091  0.0142\n",
            "     67        0.0089  0.0153\n",
            "     68        0.0094  0.0161\n",
            "     69        0.0092  0.0147\n",
            "     70        \u001b[36m0.0087\u001b[0m  0.0143\n",
            "     71        0.0092  0.0150\n",
            "     72        \u001b[36m0.0086\u001b[0m  0.0147\n",
            "     73        \u001b[36m0.0084\u001b[0m  0.0155\n",
            "     74        0.0088  0.0150\n",
            "     75        \u001b[36m0.0083\u001b[0m  0.0142\n",
            "     76        0.0090  0.0155\n",
            "     77        0.0085  0.0158\n",
            "     78        0.0086  0.0147\n",
            "     79        \u001b[36m0.0081\u001b[0m  0.0143\n",
            "     80        0.0084  0.0149\n",
            "     81        0.0083  0.0147\n",
            "     82        0.0081  0.0146\n",
            "     83        0.0082  0.0142\n",
            "     84        0.0082  0.0162\n",
            "     85        0.0084  0.0148\n",
            "     86        0.0081  0.0151\n",
            "     87        0.0082  0.0143\n",
            "     88        \u001b[36m0.0080\u001b[0m  0.0148\n",
            "     89        \u001b[36m0.0075\u001b[0m  0.0158\n",
            "     90        0.0079  0.0162\n",
            "     91        0.0080  0.0160\n",
            "     92        0.0078  0.0151\n",
            "     93        0.0078  0.0145\n",
            "     94        0.0077  0.0151\n",
            "     95        \u001b[36m0.0074\u001b[0m  0.0149\n",
            "     96        0.0080  0.0153\n",
            "     97        0.0080  0.0150\n",
            "     98        0.0078  0.0149\n",
            "     99        0.0077  0.0143\n",
            "    100        0.0080  0.0187\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1389\u001b[0m  0.0302\n",
            "      2        \u001b[36m0.0902\u001b[0m  0.0194\n",
            "      3        \u001b[36m0.0752\u001b[0m  0.0193\n",
            "      4        \u001b[36m0.0663\u001b[0m  0.0195\n",
            "      5        \u001b[36m0.0591\u001b[0m  0.0188\n",
            "      6        \u001b[36m0.0535\u001b[0m  0.0194\n",
            "      7        \u001b[36m0.0480\u001b[0m  0.0196\n",
            "      8        \u001b[36m0.0422\u001b[0m  0.0191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      9        \u001b[36m0.0382\u001b[0m  0.0198\n",
            "     10        \u001b[36m0.0338\u001b[0m  0.0195\n",
            "     11        \u001b[36m0.0302\u001b[0m  0.0206\n",
            "     12        \u001b[36m0.0275\u001b[0m  0.0194\n",
            "     13        \u001b[36m0.0244\u001b[0m  0.0186\n",
            "     14        \u001b[36m0.0218\u001b[0m  0.0191\n",
            "     15        \u001b[36m0.0200\u001b[0m  0.0189\n",
            "     16        \u001b[36m0.0194\u001b[0m  0.0192\n",
            "     17        \u001b[36m0.0180\u001b[0m  0.0190\n",
            "     18        \u001b[36m0.0173\u001b[0m  0.0198\n",
            "     19        \u001b[36m0.0168\u001b[0m  0.0195\n",
            "     20        \u001b[36m0.0160\u001b[0m  0.0196\n",
            "     21        \u001b[36m0.0150\u001b[0m  0.0193\n",
            "     22        \u001b[36m0.0147\u001b[0m  0.0200\n",
            "     23        \u001b[36m0.0144\u001b[0m  0.0193\n",
            "     24        \u001b[36m0.0141\u001b[0m  0.0204\n",
            "     25        \u001b[36m0.0138\u001b[0m  0.0191\n",
            "     26        \u001b[36m0.0133\u001b[0m  0.0198\n",
            "     27        \u001b[36m0.0131\u001b[0m  0.0194\n",
            "     28        0.0134  0.0195\n",
            "     29        \u001b[36m0.0130\u001b[0m  0.0192\n",
            "     30        \u001b[36m0.0128\u001b[0m  0.0192\n",
            "     31        \u001b[36m0.0127\u001b[0m  0.0201\n",
            "     32        \u001b[36m0.0122\u001b[0m  0.0191\n",
            "     33        \u001b[36m0.0117\u001b[0m  0.0191\n",
            "     34        \u001b[36m0.0110\u001b[0m  0.0194\n",
            "     35        0.0116  0.0198\n",
            "     36        0.0110  0.0198\n",
            "     37        \u001b[36m0.0108\u001b[0m  0.0210\n",
            "     38        \u001b[36m0.0107\u001b[0m  0.0194\n",
            "     39        \u001b[36m0.0107\u001b[0m  0.0204\n",
            "     40        \u001b[36m0.0103\u001b[0m  0.0217\n",
            "     41        \u001b[36m0.0103\u001b[0m  0.0196\n",
            "     42        \u001b[36m0.0102\u001b[0m  0.0196\n",
            "     43        \u001b[36m0.0100\u001b[0m  0.0197\n",
            "     44        \u001b[36m0.0098\u001b[0m  0.0197\n",
            "     45        0.0098  0.0196\n",
            "     46        \u001b[36m0.0098\u001b[0m  0.0195\n",
            "     47        \u001b[36m0.0096\u001b[0m  0.0193\n",
            "     48        0.0097  0.0194\n",
            "     49        \u001b[36m0.0094\u001b[0m  0.0205\n",
            "     50        \u001b[36m0.0088\u001b[0m  0.0314\n",
            "     51        0.0098  0.0192\n",
            "     52        0.0094  0.0190\n",
            "     53        0.0097  0.0195\n",
            "     54        \u001b[36m0.0088\u001b[0m  0.0188\n",
            "     55        0.0091  0.0195\n",
            "     56        0.0089  0.0191\n",
            "     57        0.0093  0.0195\n",
            "     58        0.0092  0.0189\n",
            "     59        \u001b[36m0.0085\u001b[0m  0.0198\n",
            "     60        0.0089  0.0194\n",
            "     61        0.0087  0.0192\n",
            "     62        0.0088  0.0190\n",
            "     63        \u001b[36m0.0083\u001b[0m  0.0197\n",
            "     64        \u001b[36m0.0082\u001b[0m  0.0195\n",
            "     65        0.0088  0.0197\n",
            "     66        \u001b[36m0.0080\u001b[0m  0.0198\n",
            "     67        0.0081  0.0197\n",
            "     68        0.0086  0.0198\n",
            "     69        0.0088  0.0197\n",
            "     70        0.0084  0.0189\n",
            "     71        0.0085  0.0192\n",
            "     72        0.0085  0.0195\n",
            "     73        0.0083  0.0192\n",
            "     74        0.0085  0.0187\n",
            "     75        0.0082  0.0201\n",
            "     76        \u001b[36m0.0078\u001b[0m  0.0193\n",
            "     77        0.0081  0.0196\n",
            "     78        \u001b[36m0.0077\u001b[0m  0.0193\n",
            "     79        0.0083  0.0206\n",
            "     80        \u001b[36m0.0076\u001b[0m  0.0193\n",
            "     81        0.0082  0.0193\n",
            "     82        0.0076  0.0193\n",
            "     83        0.0076  0.0197\n",
            "     84        0.0077  0.0189\n",
            "     85        \u001b[36m0.0075\u001b[0m  0.0198\n",
            "     86        0.0075  0.0192\n",
            "     87        0.0080  0.0201\n",
            "     88        0.0077  0.0192\n",
            "     89        0.0077  0.0212\n",
            "     90        0.0080  0.0194\n",
            "     91        0.0075  0.0190\n",
            "     92        \u001b[36m0.0073\u001b[0m  0.0195\n",
            "     93        0.0079  0.0193\n",
            "     94        0.0077  0.0194\n",
            "     95        0.0076  0.0195\n",
            "     96        0.0075  0.0188\n",
            "     97        0.0073  0.0191\n",
            "     98        0.0075  0.0187\n",
            "     99        \u001b[36m0.0072\u001b[0m  0.0190\n",
            "    100        0.0074  0.0210\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1231\u001b[0m  0.0372\n",
            "      2        \u001b[36m0.0804\u001b[0m  0.0235\n",
            "      3        \u001b[36m0.0679\u001b[0m  0.0239\n",
            "      4        \u001b[36m0.0596\u001b[0m  0.0238\n",
            "      5        \u001b[36m0.0518\u001b[0m  0.0239\n",
            "      6        \u001b[36m0.0453\u001b[0m  0.0241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.0411\u001b[0m  0.0258\n",
            "      8        \u001b[36m0.0361\u001b[0m  0.0241\n",
            "      9        \u001b[36m0.0325\u001b[0m  0.0242\n",
            "     10        \u001b[36m0.0291\u001b[0m  0.0243\n",
            "     11        \u001b[36m0.0261\u001b[0m  0.0258\n",
            "     12        \u001b[36m0.0236\u001b[0m  0.0238\n",
            "     13        \u001b[36m0.0215\u001b[0m  0.0238\n",
            "     14        \u001b[36m0.0206\u001b[0m  0.0245\n",
            "     15        \u001b[36m0.0192\u001b[0m  0.0241\n",
            "     16        \u001b[36m0.0184\u001b[0m  0.0239\n",
            "     17        \u001b[36m0.0173\u001b[0m  0.0237\n",
            "     18        \u001b[36m0.0165\u001b[0m  0.0245\n",
            "     19        \u001b[36m0.0165\u001b[0m  0.0236\n",
            "     20        \u001b[36m0.0152\u001b[0m  0.0262\n",
            "     21        \u001b[36m0.0147\u001b[0m  0.0245\n",
            "     22        \u001b[36m0.0146\u001b[0m  0.0238\n",
            "     23        \u001b[36m0.0140\u001b[0m  0.0243\n",
            "     24        \u001b[36m0.0137\u001b[0m  0.0242\n",
            "     25        \u001b[36m0.0134\u001b[0m  0.0236\n",
            "     26        \u001b[36m0.0131\u001b[0m  0.0240\n",
            "     27        0.0133  0.0260\n",
            "     28        \u001b[36m0.0127\u001b[0m  0.0267\n",
            "     29        \u001b[36m0.0122\u001b[0m  0.0315\n",
            "     30        \u001b[36m0.0118\u001b[0m  0.0307\n",
            "     31        \u001b[36m0.0118\u001b[0m  0.0262\n",
            "     32        0.0120  0.0241\n",
            "     33        \u001b[36m0.0110\u001b[0m  0.0236\n",
            "     34        0.0117  0.0238\n",
            "     35        \u001b[36m0.0109\u001b[0m  0.0238\n",
            "     36        \u001b[36m0.0107\u001b[0m  0.0239\n",
            "     37        0.0107  0.0237\n",
            "     38        \u001b[36m0.0104\u001b[0m  0.0238\n",
            "     39        \u001b[36m0.0103\u001b[0m  0.0300\n",
            "     40        0.0107  0.0273\n",
            "     41        \u001b[36m0.0102\u001b[0m  0.0277\n",
            "     42        \u001b[36m0.0101\u001b[0m  0.0239\n",
            "     43        0.0101  0.0245\n",
            "     44        0.0101  0.0241\n",
            "     45        \u001b[36m0.0100\u001b[0m  0.0247\n",
            "     46        \u001b[36m0.0099\u001b[0m  0.0244\n",
            "     47        \u001b[36m0.0095\u001b[0m  0.0241\n",
            "     48        0.0100  0.0239\n",
            "     49        0.0097  0.0249\n",
            "     50        \u001b[36m0.0093\u001b[0m  0.0238\n",
            "     51        0.0095  0.0249\n",
            "     52        0.0094  0.0239\n",
            "     53        0.0093  0.0235\n",
            "     54        0.0096  0.0236\n",
            "     55        \u001b[36m0.0093\u001b[0m  0.0237\n",
            "     56        0.0094  0.0235\n",
            "     57        0.0093  0.0242\n",
            "     58        0.0095  0.0244\n",
            "     59        \u001b[36m0.0087\u001b[0m  0.0235\n",
            "     60        0.0090  0.0234\n",
            "     61        0.0090  0.0248\n",
            "     62        0.0088  0.0240\n",
            "     63        0.0089  0.0241\n",
            "     64        \u001b[36m0.0087\u001b[0m  0.0233\n",
            "     65        0.0088  0.0234\n",
            "     66        \u001b[36m0.0086\u001b[0m  0.0246\n",
            "     67        0.0086  0.0243\n",
            "     68        0.0087  0.0247\n",
            "     69        \u001b[36m0.0084\u001b[0m  0.0234\n",
            "     70        \u001b[36m0.0082\u001b[0m  0.0234\n",
            "     71        0.0086  0.0237\n",
            "     72        0.0083  0.0241\n",
            "     73        0.0085  0.0249\n",
            "     74        0.0084  0.0237\n",
            "     75        0.0083  0.0240\n",
            "     76        \u001b[36m0.0080\u001b[0m  0.0235\n",
            "     77        0.0086  0.0237\n",
            "     78        0.0085  0.0236\n",
            "     79        0.0081  0.0237\n",
            "     80        \u001b[36m0.0077\u001b[0m  0.0288\n",
            "     81        0.0081  0.0279\n",
            "     82        \u001b[36m0.0077\u001b[0m  0.0236\n",
            "     83        0.0080  0.0274\n",
            "     84        \u001b[36m0.0075\u001b[0m  0.0235\n",
            "     85        0.0082  0.0237\n",
            "     86        0.0082  0.0234\n",
            "     87        0.0077  0.0236\n",
            "     88        0.0078  0.0237\n",
            "     89        0.0082  0.0235\n",
            "     90        0.0078  0.0235\n",
            "     91        0.0076  0.0234\n",
            "     92        0.0077  0.0235\n",
            "     93        0.0079  0.0236\n",
            "     94        0.0077  0.0245\n",
            "     95        0.0077  0.0236\n",
            "     96        \u001b[36m0.0075\u001b[0m  0.0235\n",
            "     97        0.0078  0.0243\n",
            "     98        0.0075  0.0240\n",
            "     99        0.0076  0.0233\n",
            "    100        \u001b[36m0.0073\u001b[0m  0.0234\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1208\u001b[0m  0.0331\n",
            "      2        \u001b[36m0.0806\u001b[0m  0.0247\n",
            "      3        \u001b[36m0.0676\u001b[0m  0.0252\n",
            "      4        \u001b[36m0.0585\u001b[0m  0.0243\n",
            "      5        \u001b[36m0.0511\u001b[0m  0.0259\n",
            "      6        \u001b[36m0.0439\u001b[0m  0.0290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.0391\u001b[0m  0.0406\n",
            "      8        \u001b[36m0.0339\u001b[0m  0.0366\n",
            "      9        \u001b[36m0.0304\u001b[0m  0.0337\n",
            "     10        \u001b[36m0.0265\u001b[0m  0.0330\n",
            "     11        \u001b[36m0.0247\u001b[0m  0.0368\n",
            "     12        \u001b[36m0.0219\u001b[0m  0.0296\n",
            "     13        \u001b[36m0.0199\u001b[0m  0.0327\n",
            "     14        \u001b[36m0.0190\u001b[0m  0.0303\n",
            "     15        \u001b[36m0.0172\u001b[0m  0.0334\n",
            "     16        \u001b[36m0.0165\u001b[0m  0.0426\n",
            "     17        \u001b[36m0.0158\u001b[0m  0.0297\n",
            "     18        \u001b[36m0.0157\u001b[0m  0.0306\n",
            "     19        \u001b[36m0.0146\u001b[0m  0.0346\n",
            "     20        \u001b[36m0.0144\u001b[0m  0.0302\n",
            "     21        \u001b[36m0.0138\u001b[0m  0.0301\n",
            "     22        \u001b[36m0.0135\u001b[0m  0.0301\n",
            "     23        \u001b[36m0.0127\u001b[0m  0.0310\n",
            "     24        0.0128  0.0304\n",
            "     25        \u001b[36m0.0125\u001b[0m  0.0302\n",
            "     26        0.0125  0.0302\n",
            "     27        \u001b[36m0.0124\u001b[0m  0.0310\n",
            "     28        \u001b[36m0.0119\u001b[0m  0.0300\n",
            "     29        \u001b[36m0.0114\u001b[0m  0.0306\n",
            "     30        0.0114  0.0301\n",
            "     31        \u001b[36m0.0111\u001b[0m  0.0305\n",
            "     32        \u001b[36m0.0109\u001b[0m  0.0302\n",
            "     33        \u001b[36m0.0107\u001b[0m  0.0331\n",
            "     34        \u001b[36m0.0102\u001b[0m  0.0313\n",
            "     35        0.0111  0.0296\n",
            "     36        0.0109  0.0296\n",
            "     37        0.0106  0.0305\n",
            "     38        0.0105  0.0312\n",
            "     39        \u001b[36m0.0099\u001b[0m  0.0288\n",
            "     40        0.0101  0.0289\n",
            "     41        0.0102  0.0292\n",
            "     42        0.0100  0.0287\n",
            "     43        0.0100  0.0371\n",
            "     44        \u001b[36m0.0097\u001b[0m  0.0284\n",
            "     45        0.0097  0.0283\n",
            "     46        0.0099  0.0287\n",
            "     47        \u001b[36m0.0094\u001b[0m  0.0296\n",
            "     48        \u001b[36m0.0091\u001b[0m  0.0454\n",
            "     49        0.0092  0.0400\n",
            "     50        \u001b[36m0.0090\u001b[0m  0.0356\n",
            "     51        \u001b[36m0.0088\u001b[0m  0.0334\n",
            "     52        0.0090  0.0344\n",
            "     53        0.0091  0.0317\n",
            "     54        0.0092  0.0300\n",
            "     55        0.0089  0.0292\n",
            "     56        \u001b[36m0.0088\u001b[0m  0.0350\n",
            "     57        0.0090  0.0373\n",
            "     58        \u001b[36m0.0086\u001b[0m  0.0386\n",
            "     59        0.0089  0.0322\n",
            "     60        0.0089  0.0297\n",
            "     61        0.0086  0.0338\n",
            "     62        0.0088  0.0347\n",
            "     63        \u001b[36m0.0084\u001b[0m  0.0355\n",
            "     64        \u001b[36m0.0077\u001b[0m  0.0360\n",
            "     65        0.0084  0.0375\n",
            "     66        0.0086  0.0389\n",
            "     67        0.0084  0.0301\n",
            "     68        0.0080  0.0297\n",
            "     69        0.0084  0.0296\n",
            "     70        0.0082  0.0274\n",
            "     71        0.0084  0.0236\n",
            "     72        0.0082  0.0239\n",
            "     73        0.0082  0.0244\n",
            "     74        0.0087  0.0239\n",
            "     75        0.0080  0.0280\n",
            "     76        \u001b[36m0.0077\u001b[0m  0.0239\n",
            "     77        0.0080  0.0240\n",
            "     78        0.0079  0.0240\n",
            "     79        0.0081  0.0239\n",
            "     80        \u001b[36m0.0077\u001b[0m  0.0286\n",
            "     81        0.0082  0.0320\n",
            "     82        0.0081  0.0241\n",
            "     83        \u001b[36m0.0075\u001b[0m  0.0239\n",
            "     84        \u001b[36m0.0075\u001b[0m  0.0240\n",
            "     85        0.0080  0.0249\n",
            "     86        0.0076  0.0239\n",
            "     87        0.0079  0.0237\n",
            "     88        0.0077  0.0239\n",
            "     89        0.0081  0.0239\n",
            "     90        0.0080  0.0239\n",
            "     91        \u001b[36m0.0073\u001b[0m  0.0244\n",
            "     92        0.0075  0.0237\n",
            "     93        0.0077  0.0247\n",
            "     94        0.0076  0.0243\n",
            "     95        0.0075  0.0240\n",
            "     96        0.0075  0.0248\n",
            "     97        0.0074  0.0241\n",
            "     98        0.0075  0.0238\n",
            "     99        0.0077  0.0242\n",
            "    100        \u001b[36m0.0071\u001b[0m  0.0238\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1231\u001b[0m  0.0342\n",
            "      2        \u001b[36m0.0775\u001b[0m  0.0300\n",
            "      3        \u001b[36m0.0636\u001b[0m  0.0289\n",
            "      4        \u001b[36m0.0539\u001b[0m  0.0299\n",
            "      5        \u001b[36m0.0470\u001b[0m  0.0285\n",
            "      6        \u001b[36m0.0407\u001b[0m  0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      7        \u001b[36m0.0352\u001b[0m  0.0288\n",
            "      8        \u001b[36m0.0307\u001b[0m  0.0290\n",
            "      9        \u001b[36m0.0262\u001b[0m  0.0276\n",
            "     10        \u001b[36m0.0244\u001b[0m  0.0279\n",
            "     11        \u001b[36m0.0219\u001b[0m  0.0280\n",
            "     12        \u001b[36m0.0194\u001b[0m  0.0278\n",
            "     13        \u001b[36m0.0177\u001b[0m  0.0280\n",
            "     14        \u001b[36m0.0171\u001b[0m  0.0319\n",
            "     15        \u001b[36m0.0159\u001b[0m  0.0278\n",
            "     16        \u001b[36m0.0153\u001b[0m  0.0280\n",
            "     17        \u001b[36m0.0146\u001b[0m  0.0371\n",
            "     18        \u001b[36m0.0138\u001b[0m  0.0317\n",
            "     19        0.0142  0.0287\n",
            "     20        \u001b[36m0.0133\u001b[0m  0.0305\n",
            "     21        \u001b[36m0.0128\u001b[0m  0.0285\n",
            "     22        \u001b[36m0.0126\u001b[0m  0.0291\n",
            "     23        \u001b[36m0.0124\u001b[0m  0.0282\n",
            "     24        \u001b[36m0.0122\u001b[0m  0.0279\n",
            "     25        \u001b[36m0.0116\u001b[0m  0.0290\n",
            "     26        0.0117  0.0280\n",
            "     27        0.0116  0.0289\n",
            "     28        \u001b[36m0.0113\u001b[0m  0.0384\n",
            "     29        \u001b[36m0.0110\u001b[0m  0.0280\n",
            "     30        \u001b[36m0.0108\u001b[0m  0.0282\n",
            "     31        \u001b[36m0.0107\u001b[0m  0.0289\n",
            "     32        \u001b[36m0.0102\u001b[0m  0.0282\n",
            "     33        0.0105  0.0286\n",
            "     34        \u001b[36m0.0100\u001b[0m  0.0292\n",
            "     35        \u001b[36m0.0095\u001b[0m  0.0284\n",
            "     36        0.0101  0.0304\n",
            "     37        0.0098  0.0287\n",
            "     38        \u001b[36m0.0091\u001b[0m  0.0280\n",
            "     39        0.0097  0.0281\n",
            "     40        0.0095  0.0322\n",
            "     41        0.0095  0.0285\n",
            "     42        0.0093  0.0281\n",
            "     43        \u001b[36m0.0091\u001b[0m  0.0284\n",
            "     44        \u001b[36m0.0088\u001b[0m  0.0283\n",
            "     45        0.0093  0.0281\n",
            "     46        0.0089  0.0281\n",
            "     47        0.0092  0.0281\n",
            "     48        \u001b[36m0.0087\u001b[0m  0.0280\n",
            "     49        0.0088  0.0292\n",
            "     50        \u001b[36m0.0084\u001b[0m  0.0284\n",
            "     51        0.0092  0.0285\n",
            "     52        0.0087  0.0368\n",
            "     53        \u001b[36m0.0084\u001b[0m  0.0282\n",
            "     54        0.0086  0.0292\n",
            "     55        0.0090  0.0280\n",
            "     56        0.0086  0.0277\n",
            "     57        \u001b[36m0.0081\u001b[0m  0.0280\n",
            "     58        \u001b[36m0.0081\u001b[0m  0.0289\n",
            "     59        0.0083  0.0289\n",
            "     60        0.0081  0.0287\n",
            "     61        \u001b[36m0.0080\u001b[0m  0.0279\n",
            "     62        \u001b[36m0.0080\u001b[0m  0.0280\n",
            "     63        0.0080  0.0281\n",
            "     64        \u001b[36m0.0078\u001b[0m  0.0278\n",
            "     65        0.0081  0.0280\n",
            "     66        0.0081  0.0291\n",
            "     67        \u001b[36m0.0078\u001b[0m  0.0293\n",
            "     68        0.0079  0.0292\n",
            "     69        \u001b[36m0.0078\u001b[0m  0.0281\n",
            "     70        \u001b[36m0.0077\u001b[0m  0.0301\n",
            "     71        \u001b[36m0.0076\u001b[0m  0.0277\n",
            "     72        0.0078  0.0284\n",
            "     73        0.0078  0.0285\n",
            "     74        0.0080  0.0284\n",
            "     75        0.0079  0.0282\n",
            "     76        \u001b[36m0.0074\u001b[0m  0.0322\n",
            "     77        0.0078  0.0281\n",
            "     78        0.0077  0.0282\n",
            "     79        0.0079  0.0284\n",
            "     80        0.0076  0.0280\n",
            "     81        0.0078  0.0280\n",
            "     82        0.0076  0.0284\n",
            "     83        0.0075  0.0282\n",
            "     84        \u001b[36m0.0071\u001b[0m  0.0281\n",
            "     85        0.0073  0.0294\n",
            "     86        0.0074  0.0301\n",
            "     87        \u001b[36m0.0071\u001b[0m  0.0371\n",
            "     88        0.0075  0.0293\n",
            "     89        0.0072  0.0283\n",
            "     90        0.0073  0.0283\n",
            "     91        0.0072  0.0282\n",
            "     92        0.0072  0.0280\n",
            "     93        0.0071  0.0306\n",
            "     94        \u001b[36m0.0067\u001b[0m  0.0299\n",
            "     95        0.0072  0.0289\n",
            "     96        0.0075  0.0279\n",
            "     97        0.0070  0.0280\n",
            "     98        0.0072  0.0281\n",
            "     99        0.0070  0.0279\n",
            "    100        0.0068  0.0293\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1100\u001b[0m  0.0453\n",
            "      2        \u001b[36m0.0699\u001b[0m  0.0348\n",
            "      3        \u001b[36m0.0566\u001b[0m  0.0326\n",
            "      4        \u001b[36m0.0467\u001b[0m  0.0322\n",
            "      5        \u001b[36m0.0387\u001b[0m  0.0329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0325\u001b[0m  0.0344\n",
            "      7        \u001b[36m0.0278\u001b[0m  0.0328\n",
            "      8        \u001b[36m0.0242\u001b[0m  0.0327\n",
            "      9        \u001b[36m0.0215\u001b[0m  0.0375\n",
            "     10        \u001b[36m0.0192\u001b[0m  0.0331\n",
            "     11        \u001b[36m0.0176\u001b[0m  0.0329\n",
            "     12        \u001b[36m0.0162\u001b[0m  0.0326\n",
            "     13        \u001b[36m0.0156\u001b[0m  0.0329\n",
            "     14        \u001b[36m0.0145\u001b[0m  0.0324\n",
            "     15        \u001b[36m0.0139\u001b[0m  0.0347\n",
            "     16        \u001b[36m0.0135\u001b[0m  0.0326\n",
            "     17        \u001b[36m0.0126\u001b[0m  0.0439\n",
            "     18        0.0129  0.0354\n",
            "     19        0.0126  0.0329\n",
            "     20        \u001b[36m0.0120\u001b[0m  0.0329\n",
            "     21        \u001b[36m0.0117\u001b[0m  0.0338\n",
            "     22        \u001b[36m0.0115\u001b[0m  0.0323\n",
            "     23        \u001b[36m0.0113\u001b[0m  0.0332\n",
            "     24        0.0113  0.0331\n",
            "     25        \u001b[36m0.0108\u001b[0m  0.0325\n",
            "     26        \u001b[36m0.0107\u001b[0m  0.0328\n",
            "     27        0.0109  0.0325\n",
            "     28        \u001b[36m0.0106\u001b[0m  0.0324\n",
            "     29        \u001b[36m0.0099\u001b[0m  0.0327\n",
            "     30        0.0102  0.0339\n",
            "     31        0.0099  0.0340\n",
            "     32        0.0102  0.0340\n",
            "     33        0.0099  0.0327\n",
            "     34        \u001b[36m0.0098\u001b[0m  0.0327\n",
            "     35        \u001b[36m0.0092\u001b[0m  0.0326\n",
            "     36        0.0097  0.0331\n",
            "     37        0.0096  0.0326\n",
            "     38        0.0094  0.0324\n",
            "     39        \u001b[36m0.0091\u001b[0m  0.0333\n",
            "     40        \u001b[36m0.0088\u001b[0m  0.0357\n",
            "     41        \u001b[36m0.0088\u001b[0m  0.0323\n",
            "     42        0.0089  0.0340\n",
            "     43        0.0090  0.0327\n",
            "     44        \u001b[36m0.0087\u001b[0m  0.0329\n",
            "     45        \u001b[36m0.0084\u001b[0m  0.0327\n",
            "     46        0.0087  0.0329\n",
            "     47        0.0086  0.0395\n",
            "     48        0.0086  0.0421\n",
            "     49        0.0085  0.0353\n",
            "     50        \u001b[36m0.0084\u001b[0m  0.0341\n",
            "     51        \u001b[36m0.0083\u001b[0m  0.0322\n",
            "     52        0.0084  0.0331\n",
            "     53        \u001b[36m0.0082\u001b[0m  0.0325\n",
            "     54        0.0083  0.0324\n",
            "     55        0.0087  0.0323\n",
            "     56        0.0086  0.0329\n",
            "     57        0.0083  0.0328\n",
            "     58        \u001b[36m0.0081\u001b[0m  0.0328\n",
            "     59        0.0081  0.0335\n",
            "     60        0.0084  0.0341\n",
            "     61        0.0082  0.0328\n",
            "     62        \u001b[36m0.0080\u001b[0m  0.0321\n",
            "     63        0.0081  0.0318\n",
            "     64        \u001b[36m0.0076\u001b[0m  0.0361\n",
            "     65        0.0079  0.0318\n",
            "     66        0.0080  0.0321\n",
            "     67        0.0078  0.0318\n",
            "     68        0.0078  0.0317\n",
            "     69        0.0080  0.0328\n",
            "     70        0.0080  0.0313\n",
            "     71        0.0079  0.0316\n",
            "     72        \u001b[36m0.0076\u001b[0m  0.0332\n",
            "     73        0.0076  0.0329\n",
            "     74        \u001b[36m0.0076\u001b[0m  0.0321\n",
            "     75        \u001b[36m0.0075\u001b[0m  0.0325\n",
            "     76        0.0075  0.0326\n",
            "     77        0.0077  0.0336\n",
            "     78        \u001b[36m0.0074\u001b[0m  0.0444\n",
            "     79        0.0075  0.0330\n",
            "     80        0.0076  0.0344\n",
            "     81        \u001b[36m0.0073\u001b[0m  0.0338\n",
            "     82        0.0073  0.0323\n",
            "     83        0.0074  0.0322\n",
            "     84        \u001b[36m0.0070\u001b[0m  0.0325\n",
            "     85        0.0073  0.0323\n",
            "     86        0.0074  0.0325\n",
            "     87        0.0074  0.0327\n",
            "     88        0.0074  0.0349\n",
            "     89        0.0074  0.0326\n",
            "     90        0.0073  0.0346\n",
            "     91        0.0075  0.0329\n",
            "     92        0.0071  0.0336\n",
            "     93        0.0074  0.0332\n",
            "     94        0.0074  0.0328\n",
            "     95        0.0073  0.0325\n",
            "     96        0.0071  0.0367\n",
            "     97        0.0072  0.0323\n",
            "     98        0.0073  0.0323\n",
            "     99        \u001b[36m0.0069\u001b[0m  0.0324\n",
            "    100        0.0073  0.0325\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1090\u001b[0m  0.0460\n",
            "      2        \u001b[36m0.0719\u001b[0m  0.0368\n",
            "      3        \u001b[36m0.0599\u001b[0m  0.0387\n",
            "      4        \u001b[36m0.0507\u001b[0m  0.0379\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.0435\u001b[0m  0.0402\n",
            "      6        \u001b[36m0.0377\u001b[0m  0.0492\n",
            "      7        \u001b[36m0.0328\u001b[0m  0.0379\n",
            "      8        \u001b[36m0.0284\u001b[0m  0.0377\n",
            "      9        \u001b[36m0.0251\u001b[0m  0.0366\n",
            "     10        \u001b[36m0.0225\u001b[0m  0.0372\n",
            "     11        \u001b[36m0.0208\u001b[0m  0.0379\n",
            "     12        \u001b[36m0.0191\u001b[0m  0.0371\n",
            "     13        \u001b[36m0.0182\u001b[0m  0.0372\n",
            "     14        \u001b[36m0.0173\u001b[0m  0.0373\n",
            "     15        \u001b[36m0.0164\u001b[0m  0.0413\n",
            "     16        \u001b[36m0.0156\u001b[0m  0.0390\n",
            "     17        \u001b[36m0.0152\u001b[0m  0.0365\n",
            "     18        \u001b[36m0.0142\u001b[0m  0.0370\n",
            "     19        0.0143  0.0371\n",
            "     20        \u001b[36m0.0141\u001b[0m  0.0371\n",
            "     21        \u001b[36m0.0139\u001b[0m  0.0370\n",
            "     22        \u001b[36m0.0135\u001b[0m  0.0367\n",
            "     23        \u001b[36m0.0135\u001b[0m  0.0367\n",
            "     24        \u001b[36m0.0128\u001b[0m  0.0405\n",
            "     25        \u001b[36m0.0121\u001b[0m  0.0368\n",
            "     26        \u001b[36m0.0119\u001b[0m  0.0367\n",
            "     27        0.0120  0.0365\n",
            "     28        \u001b[36m0.0117\u001b[0m  0.0367\n",
            "     29        \u001b[36m0.0114\u001b[0m  0.0367\n",
            "     30        \u001b[36m0.0114\u001b[0m  0.0362\n",
            "     31        \u001b[36m0.0113\u001b[0m  0.0383\n",
            "     32        \u001b[36m0.0111\u001b[0m  0.0365\n",
            "     33        \u001b[36m0.0108\u001b[0m  0.0488\n",
            "     34        \u001b[36m0.0107\u001b[0m  0.0370\n",
            "     35        \u001b[36m0.0103\u001b[0m  0.0361\n",
            "     36        \u001b[36m0.0102\u001b[0m  0.0363\n",
            "     37        \u001b[36m0.0101\u001b[0m  0.0365\n",
            "     38        \u001b[36m0.0101\u001b[0m  0.0410\n",
            "     39        0.0102  0.0374\n",
            "     40        0.0104  0.0371\n",
            "     41        0.0104  0.0374\n",
            "     42        0.0102  0.0395\n",
            "     43        \u001b[36m0.0097\u001b[0m  0.0371\n",
            "     44        0.0101  0.0370\n",
            "     45        0.0099  0.0416\n",
            "     46        \u001b[36m0.0096\u001b[0m  0.0369\n",
            "     47        \u001b[36m0.0094\u001b[0m  0.0367\n",
            "     48        \u001b[36m0.0093\u001b[0m  0.0368\n",
            "     49        0.0096  0.0365\n",
            "     50        \u001b[36m0.0093\u001b[0m  0.0370\n",
            "     51        0.0093  0.0367\n",
            "     52        0.0095  0.0377\n",
            "     53        0.0093  0.0368\n",
            "     54        0.0095  0.0366\n",
            "     55        \u001b[36m0.0086\u001b[0m  0.0364\n",
            "     56        0.0089  0.0363\n",
            "     57        0.0090  0.0377\n",
            "     58        0.0090  0.0370\n",
            "     59        0.0088  0.0425\n",
            "     60        0.0090  0.0454\n",
            "     61        0.0091  0.0364\n",
            "     62        0.0090  0.0362\n",
            "     63        \u001b[36m0.0082\u001b[0m  0.0364\n",
            "     64        0.0087  0.0365\n",
            "     65        0.0086  0.0368\n",
            "     66        0.0090  0.0381\n",
            "     67        0.0083  0.0404\n",
            "     68        0.0087  0.0386\n",
            "     69        0.0085  0.0371\n",
            "     70        0.0085  0.0370\n",
            "     71        0.0086  0.0518\n",
            "     72        0.0087  0.0534\n",
            "     73        0.0086  0.0566\n",
            "     74        0.0082  0.0487\n",
            "     75        0.0085  0.0479\n",
            "     76        0.0082  0.0482\n",
            "     77        0.0083  0.0451\n",
            "     78        \u001b[36m0.0080\u001b[0m  0.0487\n",
            "     79        \u001b[36m0.0079\u001b[0m  0.0462\n",
            "     80        0.0081  0.0472\n",
            "     81        0.0084  0.0471\n",
            "     82        0.0082  0.0534\n",
            "     83        0.0080  0.0498\n",
            "     84        \u001b[36m0.0076\u001b[0m  0.0476\n",
            "     85        0.0076  0.0462\n",
            "     86        0.0078  0.0463\n",
            "     87        0.0078  0.0515\n",
            "     88        0.0077  0.0501\n",
            "     89        0.0080  0.0464\n",
            "     90        0.0078  0.0492\n",
            "     91        0.0080  0.0441\n",
            "     92        0.0080  0.0445\n",
            "     93        0.0078  0.0463\n",
            "     94        0.0077  0.0456\n",
            "     95        \u001b[36m0.0075\u001b[0m  0.0445\n",
            "     96        0.0076  0.0448\n",
            "     97        0.0077  0.0504\n",
            "     98        \u001b[36m0.0074\u001b[0m  0.0547\n",
            "     99        0.0078  0.0589\n",
            "    100        0.0079  0.0589\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1403\u001b[0m  0.0587\n",
            "      2        \u001b[36m0.1255\u001b[0m  0.0238\n",
            "      3        \u001b[36m0.1186\u001b[0m  0.0193\n",
            "      4        \u001b[36m0.1113\u001b[0m  0.0212\n",
            "      5        \u001b[36m0.0981\u001b[0m  0.0247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0973\u001b[0m  0.0239\n",
            "      7        \u001b[36m0.0961\u001b[0m  0.0168\n",
            "      8        \u001b[36m0.0909\u001b[0m  0.0181\n",
            "      9        \u001b[36m0.0870\u001b[0m  0.0175\n",
            "     10        \u001b[36m0.0844\u001b[0m  0.0199\n",
            "     11        \u001b[36m0.0829\u001b[0m  0.0215\n",
            "     12        \u001b[36m0.0789\u001b[0m  0.0215\n",
            "     13        \u001b[36m0.0752\u001b[0m  0.0238\n",
            "     14        0.0754  0.0227\n",
            "     15        \u001b[36m0.0735\u001b[0m  0.0235\n",
            "     16        \u001b[36m0.0707\u001b[0m  0.0259\n",
            "     17        \u001b[36m0.0704\u001b[0m  0.0223\n",
            "     18        \u001b[36m0.0673\u001b[0m  0.0211\n",
            "     19        \u001b[36m0.0646\u001b[0m  0.0233\n",
            "     20        \u001b[36m0.0617\u001b[0m  0.0227\n",
            "     21        \u001b[36m0.0608\u001b[0m  0.0174\n",
            "     22        \u001b[36m0.0587\u001b[0m  0.0167\n",
            "     23        \u001b[36m0.0570\u001b[0m  0.0282\n",
            "     24        0.0571  0.0182\n",
            "     25        \u001b[36m0.0540\u001b[0m  0.0203\n",
            "     26        \u001b[36m0.0509\u001b[0m  0.0177\n",
            "     27        0.0516  0.0174\n",
            "     28        \u001b[36m0.0505\u001b[0m  0.0178\n",
            "     29        \u001b[36m0.0488\u001b[0m  0.0166\n",
            "     30        \u001b[36m0.0476\u001b[0m  0.0170\n",
            "     31        \u001b[36m0.0451\u001b[0m  0.0139\n",
            "     32        \u001b[36m0.0442\u001b[0m  0.0140\n",
            "     33        \u001b[36m0.0439\u001b[0m  0.0140\n",
            "     34        \u001b[36m0.0425\u001b[0m  0.0156\n",
            "     35        \u001b[36m0.0403\u001b[0m  0.0142\n",
            "     36        0.0406  0.0148\n",
            "     37        \u001b[36m0.0396\u001b[0m  0.0139\n",
            "     38        \u001b[36m0.0389\u001b[0m  0.0144\n",
            "     39        \u001b[36m0.0376\u001b[0m  0.0141\n",
            "     40        \u001b[36m0.0368\u001b[0m  0.0141\n",
            "     41        \u001b[36m0.0368\u001b[0m  0.0140\n",
            "     42        0.0369  0.0141\n",
            "     43        \u001b[36m0.0353\u001b[0m  0.0141\n",
            "     44        \u001b[36m0.0320\u001b[0m  0.0142\n",
            "     45        0.0328  0.0153\n",
            "     46        0.0321  0.0150\n",
            "     47        0.0324  0.0138\n",
            "     48        \u001b[36m0.0293\u001b[0m  0.0135\n",
            "     49        \u001b[36m0.0292\u001b[0m  0.0155\n",
            "     50        0.0311  0.0142\n",
            "     51        \u001b[36m0.0291\u001b[0m  0.0145\n",
            "     52        0.0291  0.0140\n",
            "     53        \u001b[36m0.0270\u001b[0m  0.0142\n",
            "     54        \u001b[36m0.0264\u001b[0m  0.0142\n",
            "     55        \u001b[36m0.0262\u001b[0m  0.0160\n",
            "     56        0.0267  0.0215\n",
            "     57        \u001b[36m0.0253\u001b[0m  0.0170\n",
            "     58        \u001b[36m0.0242\u001b[0m  0.0142\n",
            "     59        \u001b[36m0.0236\u001b[0m  0.0136\n",
            "     60        0.0237  0.0132\n",
            "     61        0.0239  0.0162\n",
            "     62        \u001b[36m0.0227\u001b[0m  0.0140\n",
            "     63        \u001b[36m0.0219\u001b[0m  0.0140\n",
            "     64        0.0231  0.0139\n",
            "     65        \u001b[36m0.0210\u001b[0m  0.0145\n",
            "     66        0.0217  0.0145\n",
            "     67        \u001b[36m0.0208\u001b[0m  0.0140\n",
            "     68        0.0211  0.0139\n",
            "     69        \u001b[36m0.0196\u001b[0m  0.0142\n",
            "     70        \u001b[36m0.0190\u001b[0m  0.0149\n",
            "     71        0.0208  0.0141\n",
            "     72        \u001b[36m0.0189\u001b[0m  0.0131\n",
            "     73        \u001b[36m0.0186\u001b[0m  0.0149\n",
            "     74        0.0206  0.0138\n",
            "     75        \u001b[36m0.0174\u001b[0m  0.0140\n",
            "     76        0.0190  0.0146\n",
            "     77        \u001b[36m0.0165\u001b[0m  0.0138\n",
            "     78        0.0170  0.0183\n",
            "     79        0.0173  0.0154\n",
            "     80        0.0173  0.0139\n",
            "     81        0.0170  0.0144\n",
            "     82        \u001b[36m0.0156\u001b[0m  0.0174\n",
            "     83        0.0163  0.0158\n",
            "     84        0.0161  0.0159\n",
            "     85        \u001b[36m0.0153\u001b[0m  0.0153\n",
            "     86        \u001b[36m0.0146\u001b[0m  0.0144\n",
            "     87        0.0162  0.0157\n",
            "     88        0.0150  0.0153\n",
            "     89        \u001b[36m0.0143\u001b[0m  0.0157\n",
            "     90        0.0144  0.0136\n",
            "     91        0.0152  0.0146\n",
            "     92        0.0149  0.0140\n",
            "     93        \u001b[36m0.0142\u001b[0m  0.0139\n",
            "     94        \u001b[36m0.0138\u001b[0m  0.0148\n",
            "     95        \u001b[36m0.0135\u001b[0m  0.0144\n",
            "     96        \u001b[36m0.0132\u001b[0m  0.0139\n",
            "     97        0.0137  0.0137\n",
            "     98        \u001b[36m0.0125\u001b[0m  0.0132\n",
            "     99        0.0132  0.0136\n",
            "    100        0.0131  0.0141\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1601\u001b[0m  0.0506\n",
            "      2        \u001b[36m0.1291\u001b[0m  0.0264\n",
            "      3        \u001b[36m0.1145\u001b[0m  0.0284\n",
            "      4        \u001b[36m0.1055\u001b[0m  0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.0996\u001b[0m  0.0284\n",
            "      6        \u001b[36m0.0939\u001b[0m  0.0272\n",
            "      7        \u001b[36m0.0870\u001b[0m  0.0267\n",
            "      8        \u001b[36m0.0844\u001b[0m  0.0264\n",
            "      9        \u001b[36m0.0800\u001b[0m  0.0279\n",
            "     10        \u001b[36m0.0778\u001b[0m  0.0357\n",
            "     11        \u001b[36m0.0743\u001b[0m  0.0273\n",
            "     12        \u001b[36m0.0733\u001b[0m  0.0272\n",
            "     13        \u001b[36m0.0688\u001b[0m  0.0288\n",
            "     14        \u001b[36m0.0678\u001b[0m  0.0282\n",
            "     15        \u001b[36m0.0642\u001b[0m  0.0272\n",
            "     16        \u001b[36m0.0624\u001b[0m  0.0285\n",
            "     17        \u001b[36m0.0586\u001b[0m  0.0267\n",
            "     18        \u001b[36m0.0581\u001b[0m  0.0261\n",
            "     19        \u001b[36m0.0542\u001b[0m  0.0265\n",
            "     20        \u001b[36m0.0534\u001b[0m  0.0266\n",
            "     21        \u001b[36m0.0512\u001b[0m  0.0263\n",
            "     22        \u001b[36m0.0485\u001b[0m  0.0337\n",
            "     23        \u001b[36m0.0471\u001b[0m  0.0264\n",
            "     24        \u001b[36m0.0462\u001b[0m  0.0284\n",
            "     25        \u001b[36m0.0442\u001b[0m  0.0272\n",
            "     26        \u001b[36m0.0423\u001b[0m  0.0262\n",
            "     27        \u001b[36m0.0420\u001b[0m  0.0264\n",
            "     28        \u001b[36m0.0397\u001b[0m  0.0264\n",
            "     29        \u001b[36m0.0385\u001b[0m  0.0262\n",
            "     30        \u001b[36m0.0384\u001b[0m  0.0273\n",
            "     31        \u001b[36m0.0363\u001b[0m  0.0291\n",
            "     32        \u001b[36m0.0358\u001b[0m  0.0265\n",
            "     33        \u001b[36m0.0347\u001b[0m  0.0276\n",
            "     34        \u001b[36m0.0329\u001b[0m  0.0277\n",
            "     35        0.0341  0.0263\n",
            "     36        \u001b[36m0.0318\u001b[0m  0.0261\n",
            "     37        0.0321  0.0266\n",
            "     38        \u001b[36m0.0307\u001b[0m  0.0276\n",
            "     39        \u001b[36m0.0297\u001b[0m  0.0264\n",
            "     40        \u001b[36m0.0292\u001b[0m  0.0281\n",
            "     41        \u001b[36m0.0282\u001b[0m  0.0264\n",
            "     42        \u001b[36m0.0280\u001b[0m  0.0261\n",
            "     43        \u001b[36m0.0268\u001b[0m  0.0261\n",
            "     44        \u001b[36m0.0253\u001b[0m  0.0263\n",
            "     45        \u001b[36m0.0250\u001b[0m  0.0264\n",
            "     46        \u001b[36m0.0245\u001b[0m  0.0408\n",
            "     47        0.0250  0.0265\n",
            "     48        \u001b[36m0.0237\u001b[0m  0.0265\n",
            "     49        \u001b[36m0.0235\u001b[0m  0.0288\n",
            "     50        0.0236  0.0268\n",
            "     51        \u001b[36m0.0225\u001b[0m  0.0285\n",
            "     52        \u001b[36m0.0214\u001b[0m  0.0267\n",
            "     53        \u001b[36m0.0211\u001b[0m  0.0290\n",
            "     54        0.0215  0.0264\n",
            "     55        \u001b[36m0.0208\u001b[0m  0.0262\n",
            "     56        \u001b[36m0.0201\u001b[0m  0.0262\n",
            "     57        \u001b[36m0.0194\u001b[0m  0.0266\n",
            "     58        \u001b[36m0.0190\u001b[0m  0.0307\n",
            "     59        0.0199  0.0261\n",
            "     60        \u001b[36m0.0182\u001b[0m  0.0262\n",
            "     61        0.0185  0.0262\n",
            "     62        \u001b[36m0.0181\u001b[0m  0.0263\n",
            "     63        \u001b[36m0.0176\u001b[0m  0.0268\n",
            "     64        0.0176  0.0264\n",
            "     65        \u001b[36m0.0167\u001b[0m  0.0268\n",
            "     66        0.0171  0.0264\n",
            "     67        \u001b[36m0.0159\u001b[0m  0.0268\n",
            "     68        0.0166  0.0274\n",
            "     69        \u001b[36m0.0153\u001b[0m  0.0263\n",
            "     70        \u001b[36m0.0152\u001b[0m  0.0263\n",
            "     71        0.0152  0.0264\n",
            "     72        0.0156  0.0276\n",
            "     73        0.0159  0.0263\n",
            "     74        \u001b[36m0.0150\u001b[0m  0.0277\n",
            "     75        \u001b[36m0.0140\u001b[0m  0.0292\n",
            "     76        \u001b[36m0.0139\u001b[0m  0.0265\n",
            "     77        \u001b[36m0.0137\u001b[0m  0.0273\n",
            "     78        \u001b[36m0.0134\u001b[0m  0.0263\n",
            "     79        0.0136  0.0265\n",
            "     80        \u001b[36m0.0131\u001b[0m  0.0266\n",
            "     81        \u001b[36m0.0130\u001b[0m  0.0263\n",
            "     82        0.0133  0.0263\n",
            "     83        \u001b[36m0.0122\u001b[0m  0.0437\n",
            "     84        0.0136  0.0276\n",
            "     85        0.0128  0.0275\n",
            "     86        \u001b[36m0.0119\u001b[0m  0.0291\n",
            "     87        0.0130  0.0291\n",
            "     88        \u001b[36m0.0118\u001b[0m  0.0294\n",
            "     89        0.0118  0.0274\n",
            "     90        \u001b[36m0.0115\u001b[0m  0.0280\n",
            "     91        0.0118  0.0264\n",
            "     92        \u001b[36m0.0113\u001b[0m  0.0269\n",
            "     93        0.0117  0.0267\n",
            "     94        \u001b[36m0.0112\u001b[0m  0.0263\n",
            "     95        0.0114  0.0313\n",
            "     96        \u001b[36m0.0110\u001b[0m  0.0263\n",
            "     97        \u001b[36m0.0106\u001b[0m  0.0263\n",
            "     98        \u001b[36m0.0106\u001b[0m  0.0269\n",
            "     99        \u001b[36m0.0101\u001b[0m  0.0268\n",
            "    100        0.0103  0.0266\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1700\u001b[0m  0.0651\n",
            "      2        \u001b[36m0.1290\u001b[0m  0.0400\n",
            "      3        \u001b[36m0.1125\u001b[0m  0.0404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.1057\u001b[0m  0.0410\n",
            "      5        \u001b[36m0.0980\u001b[0m  0.0415\n",
            "      6        \u001b[36m0.0929\u001b[0m  0.0387\n",
            "      7        \u001b[36m0.0885\u001b[0m  0.0388\n",
            "      8        \u001b[36m0.0838\u001b[0m  0.0387\n",
            "      9        \u001b[36m0.0816\u001b[0m  0.0402\n",
            "     10        \u001b[36m0.0769\u001b[0m  0.0394\n",
            "     11        \u001b[36m0.0743\u001b[0m  0.0439\n",
            "     12        \u001b[36m0.0708\u001b[0m  0.0474\n",
            "     13        \u001b[36m0.0686\u001b[0m  0.0392\n",
            "     14        \u001b[36m0.0671\u001b[0m  0.0405\n",
            "     15        \u001b[36m0.0637\u001b[0m  0.0434\n",
            "     16        0.0638  0.0391\n",
            "     17        \u001b[36m0.0589\u001b[0m  0.0390\n",
            "     18        \u001b[36m0.0588\u001b[0m  0.0388\n",
            "     19        \u001b[36m0.0561\u001b[0m  0.0383\n",
            "     20        \u001b[36m0.0554\u001b[0m  0.0386\n",
            "     21        \u001b[36m0.0532\u001b[0m  0.0384\n",
            "     22        \u001b[36m0.0502\u001b[0m  0.0401\n",
            "     23        \u001b[36m0.0488\u001b[0m  0.0425\n",
            "     24        \u001b[36m0.0465\u001b[0m  0.0388\n",
            "     25        \u001b[36m0.0451\u001b[0m  0.0384\n",
            "     26        \u001b[36m0.0440\u001b[0m  0.0387\n",
            "     27        \u001b[36m0.0423\u001b[0m  0.0382\n",
            "     28        \u001b[36m0.0400\u001b[0m  0.0379\n",
            "     29        \u001b[36m0.0385\u001b[0m  0.0398\n",
            "     30        \u001b[36m0.0374\u001b[0m  0.0398\n",
            "     31        \u001b[36m0.0360\u001b[0m  0.0384\n",
            "     32        \u001b[36m0.0348\u001b[0m  0.0383\n",
            "     33        \u001b[36m0.0333\u001b[0m  0.0386\n",
            "     34        \u001b[36m0.0317\u001b[0m  0.0386\n",
            "     35        \u001b[36m0.0311\u001b[0m  0.0389\n",
            "     36        \u001b[36m0.0300\u001b[0m  0.0405\n",
            "     37        \u001b[36m0.0286\u001b[0m  0.0531\n",
            "     38        \u001b[36m0.0282\u001b[0m  0.0407\n",
            "     39        \u001b[36m0.0258\u001b[0m  0.0387\n",
            "     40        \u001b[36m0.0251\u001b[0m  0.0390\n",
            "     41        \u001b[36m0.0244\u001b[0m  0.0391\n",
            "     42        0.0244  0.0450\n",
            "     43        \u001b[36m0.0230\u001b[0m  0.0386\n",
            "     44        0.0231  0.0386\n",
            "     45        \u001b[36m0.0215\u001b[0m  0.0385\n",
            "     46        0.0216  0.0385\n",
            "     47        \u001b[36m0.0205\u001b[0m  0.0390\n",
            "     48        \u001b[36m0.0197\u001b[0m  0.0392\n",
            "     49        0.0198  0.0408\n",
            "     50        \u001b[36m0.0190\u001b[0m  0.0389\n",
            "     51        \u001b[36m0.0181\u001b[0m  0.0388\n",
            "     52        \u001b[36m0.0177\u001b[0m  0.0388\n",
            "     53        0.0179  0.0392\n",
            "     54        \u001b[36m0.0168\u001b[0m  0.0396\n",
            "     55        \u001b[36m0.0165\u001b[0m  0.0393\n",
            "     56        \u001b[36m0.0162\u001b[0m  0.0403\n",
            "     57        \u001b[36m0.0158\u001b[0m  0.0389\n",
            "     58        \u001b[36m0.0155\u001b[0m  0.0389\n",
            "     59        \u001b[36m0.0147\u001b[0m  0.0408\n",
            "     60        0.0148  0.0399\n",
            "     61        0.0151  0.0411\n",
            "     62        0.0147  0.0533\n",
            "     63        \u001b[36m0.0143\u001b[0m  0.0409\n",
            "     64        0.0143  0.0390\n",
            "     65        0.0146  0.0397\n",
            "     66        \u001b[36m0.0139\u001b[0m  0.0390\n",
            "     67        \u001b[36m0.0126\u001b[0m  0.0389\n",
            "     68        0.0131  0.0388\n",
            "     69        \u001b[36m0.0123\u001b[0m  0.0385\n",
            "     70        \u001b[36m0.0122\u001b[0m  0.0438\n",
            "     71        \u001b[36m0.0122\u001b[0m  0.0393\n",
            "     72        \u001b[36m0.0120\u001b[0m  0.0389\n",
            "     73        0.0122  0.0389\n",
            "     74        \u001b[36m0.0118\u001b[0m  0.0387\n",
            "     75        \u001b[36m0.0115\u001b[0m  0.0389\n",
            "     76        \u001b[36m0.0114\u001b[0m  0.0385\n",
            "     77        \u001b[36m0.0108\u001b[0m  0.0398\n",
            "     78        0.0113  0.0401\n",
            "     79        0.0114  0.0409\n",
            "     80        \u001b[36m0.0105\u001b[0m  0.0383\n",
            "     81        \u001b[36m0.0104\u001b[0m  0.0387\n",
            "     82        0.0106  0.0384\n",
            "     83        \u001b[36m0.0102\u001b[0m  0.0387\n",
            "     84        0.0103  0.0406\n",
            "     85        \u001b[36m0.0098\u001b[0m  0.0385\n",
            "     86        \u001b[36m0.0098\u001b[0m  0.0401\n",
            "     87        0.0099  0.0443\n",
            "     88        \u001b[36m0.0096\u001b[0m  0.0468\n",
            "     89        0.0096  0.0395\n",
            "     90        \u001b[36m0.0092\u001b[0m  0.0436\n",
            "     91        \u001b[36m0.0089\u001b[0m  0.0387\n",
            "     92        0.0092  0.0384\n",
            "     93        0.0100  0.0385\n",
            "     94        0.0092  0.0383\n",
            "     95        \u001b[36m0.0089\u001b[0m  0.0393\n",
            "     96        \u001b[36m0.0088\u001b[0m  0.0408\n",
            "     97        \u001b[36m0.0087\u001b[0m  0.0410\n",
            "     98        0.0087  0.0390\n",
            "     99        0.0089  0.0385\n",
            "    100        \u001b[36m0.0086\u001b[0m  0.0385\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1677\u001b[0m  0.0637\n",
            "      2        \u001b[36m0.1329\u001b[0m  0.0416\n",
            "      3        \u001b[36m0.1114\u001b[0m  0.0396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.1002\u001b[0m  0.0410\n",
            "      5        \u001b[36m0.0947\u001b[0m  0.0399\n",
            "      6        \u001b[36m0.0887\u001b[0m  0.0395\n",
            "      7        \u001b[36m0.0818\u001b[0m  0.0401\n",
            "      8        \u001b[36m0.0771\u001b[0m  0.0409\n",
            "      9        \u001b[36m0.0729\u001b[0m  0.0437\n",
            "     10        \u001b[36m0.0691\u001b[0m  0.0450\n",
            "     11        \u001b[36m0.0655\u001b[0m  0.0507\n",
            "     12        \u001b[36m0.0606\u001b[0m  0.0402\n",
            "     13        \u001b[36m0.0589\u001b[0m  0.0402\n",
            "     14        \u001b[36m0.0566\u001b[0m  0.0402\n",
            "     15        \u001b[36m0.0540\u001b[0m  0.0440\n",
            "     16        \u001b[36m0.0525\u001b[0m  0.0394\n",
            "     17        \u001b[36m0.0502\u001b[0m  0.0397\n",
            "     18        \u001b[36m0.0478\u001b[0m  0.0395\n",
            "     19        \u001b[36m0.0445\u001b[0m  0.0397\n",
            "     20        \u001b[36m0.0434\u001b[0m  0.0396\n",
            "     21        \u001b[36m0.0419\u001b[0m  0.0413\n",
            "     22        \u001b[36m0.0399\u001b[0m  0.0398\n",
            "     23        \u001b[36m0.0381\u001b[0m  0.0396\n",
            "     24        \u001b[36m0.0366\u001b[0m  0.0439\n",
            "     25        \u001b[36m0.0351\u001b[0m  0.0410\n",
            "     26        \u001b[36m0.0327\u001b[0m  0.0395\n",
            "     27        \u001b[36m0.0315\u001b[0m  0.0390\n",
            "     28        \u001b[36m0.0305\u001b[0m  0.0393\n",
            "     29        \u001b[36m0.0303\u001b[0m  0.0407\n",
            "     30        \u001b[36m0.0281\u001b[0m  0.0395\n",
            "     31        0.0283  0.0398\n",
            "     32        \u001b[36m0.0269\u001b[0m  0.0407\n",
            "     33        \u001b[36m0.0253\u001b[0m  0.0397\n",
            "     34        \u001b[36m0.0248\u001b[0m  0.0423\n",
            "     35        \u001b[36m0.0239\u001b[0m  0.0531\n",
            "     36        \u001b[36m0.0224\u001b[0m  0.0453\n",
            "     37        \u001b[36m0.0220\u001b[0m  0.0401\n",
            "     38        \u001b[36m0.0211\u001b[0m  0.0398\n",
            "     39        \u001b[36m0.0209\u001b[0m  0.0399\n",
            "     40        \u001b[36m0.0195\u001b[0m  0.0395\n",
            "     41        \u001b[36m0.0191\u001b[0m  0.0439\n",
            "     42        \u001b[36m0.0180\u001b[0m  0.0491\n",
            "     43        \u001b[36m0.0176\u001b[0m  0.0636\n",
            "     44        \u001b[36m0.0171\u001b[0m  0.0626\n",
            "     45        \u001b[36m0.0170\u001b[0m  0.0555\n",
            "     46        \u001b[36m0.0168\u001b[0m  0.0541\n",
            "     47        \u001b[36m0.0163\u001b[0m  0.0526\n",
            "     48        \u001b[36m0.0161\u001b[0m  0.0531\n",
            "     49        0.0161  0.0530\n",
            "     50        \u001b[36m0.0144\u001b[0m  0.0510\n",
            "     51        0.0151  0.0508\n",
            "     52        0.0145  0.0518\n",
            "     53        \u001b[36m0.0137\u001b[0m  0.0561\n",
            "     54        \u001b[36m0.0133\u001b[0m  0.0505\n",
            "     55        0.0137  0.0714\n",
            "     56        \u001b[36m0.0127\u001b[0m  0.0527\n",
            "     57        0.0128  0.0574\n",
            "     58        0.0128  0.0484\n",
            "     59        \u001b[36m0.0122\u001b[0m  0.0482\n",
            "     60        \u001b[36m0.0120\u001b[0m  0.0481\n",
            "     61        0.0121  0.0486\n",
            "     62        0.0122  0.0485\n",
            "     63        \u001b[36m0.0119\u001b[0m  0.0504\n",
            "     64        \u001b[36m0.0113\u001b[0m  0.0506\n",
            "     65        0.0114  0.0496\n",
            "     66        \u001b[36m0.0113\u001b[0m  0.0559\n",
            "     67        \u001b[36m0.0109\u001b[0m  0.0624\n",
            "     68        \u001b[36m0.0106\u001b[0m  0.0581\n",
            "     69        \u001b[36m0.0103\u001b[0m  0.0563\n",
            "     70        0.0104  0.0507\n",
            "     71        \u001b[36m0.0101\u001b[0m  0.0595\n",
            "     72        0.0104  0.0712\n",
            "     73        \u001b[36m0.0099\u001b[0m  0.0621\n",
            "     74        \u001b[36m0.0098\u001b[0m  0.0603\n",
            "     75        \u001b[36m0.0095\u001b[0m  0.0646\n",
            "     76        0.0100  0.0647\n",
            "     77        0.0099  0.0626\n",
            "     78        \u001b[36m0.0094\u001b[0m  0.0508\n",
            "     79        0.0095  0.0487\n",
            "     80        \u001b[36m0.0092\u001b[0m  0.0399\n",
            "     81        0.0094  0.0410\n",
            "     82        0.0093  0.0395\n",
            "     83        \u001b[36m0.0087\u001b[0m  0.0403\n",
            "     84        0.0089  0.0396\n",
            "     85        \u001b[36m0.0085\u001b[0m  0.0401\n",
            "     86        \u001b[36m0.0084\u001b[0m  0.0401\n",
            "     87        0.0084  0.0420\n",
            "     88        0.0084  0.0411\n",
            "     89        0.0087  0.0397\n",
            "     90        0.0085  0.0444\n",
            "     91        \u001b[36m0.0081\u001b[0m  0.0409\n",
            "     92        0.0086  0.0421\n",
            "     93        0.0084  0.0403\n",
            "     94        0.0083  0.0453\n",
            "     95        \u001b[36m0.0081\u001b[0m  0.0405\n",
            "     96        \u001b[36m0.0078\u001b[0m  0.0535\n",
            "     97        0.0078  0.0398\n",
            "     98        \u001b[36m0.0077\u001b[0m  0.0404\n",
            "     99        \u001b[36m0.0074\u001b[0m  0.0400\n",
            "    100        \u001b[36m0.0074\u001b[0m  0.0420\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1495\u001b[0m  0.0784\n",
            "      2        \u001b[36m0.1165\u001b[0m  0.0530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.1000\u001b[0m  0.0592\n",
            "      4        \u001b[36m0.0900\u001b[0m  0.0533\n",
            "      5        \u001b[36m0.0843\u001b[0m  0.0545\n",
            "      6        \u001b[36m0.0778\u001b[0m  0.0528\n",
            "      7        \u001b[36m0.0727\u001b[0m  0.0525\n",
            "      8        \u001b[36m0.0669\u001b[0m  0.0524\n",
            "      9        \u001b[36m0.0638\u001b[0m  0.0559\n",
            "     10        \u001b[36m0.0602\u001b[0m  0.0544\n",
            "     11        \u001b[36m0.0564\u001b[0m  0.0524\n",
            "     12        \u001b[36m0.0534\u001b[0m  0.0518\n",
            "     13        \u001b[36m0.0504\u001b[0m  0.0518\n",
            "     14        \u001b[36m0.0477\u001b[0m  0.0695\n",
            "     15        \u001b[36m0.0460\u001b[0m  0.0532\n",
            "     16        \u001b[36m0.0444\u001b[0m  0.0519\n",
            "     17        \u001b[36m0.0422\u001b[0m  0.0522\n",
            "     18        \u001b[36m0.0396\u001b[0m  0.0541\n",
            "     19        \u001b[36m0.0379\u001b[0m  0.0516\n",
            "     20        \u001b[36m0.0353\u001b[0m  0.0521\n",
            "     21        \u001b[36m0.0333\u001b[0m  0.0530\n",
            "     22        \u001b[36m0.0323\u001b[0m  0.0527\n",
            "     23        \u001b[36m0.0311\u001b[0m  0.0519\n",
            "     24        \u001b[36m0.0286\u001b[0m  0.0535\n",
            "     25        \u001b[36m0.0274\u001b[0m  0.0519\n",
            "     26        \u001b[36m0.0265\u001b[0m  0.0523\n",
            "     27        \u001b[36m0.0252\u001b[0m  0.0530\n",
            "     28        \u001b[36m0.0240\u001b[0m  0.0523\n",
            "     29        \u001b[36m0.0228\u001b[0m  0.0581\n",
            "     30        \u001b[36m0.0208\u001b[0m  0.0524\n",
            "     31        0.0211  0.0539\n",
            "     32        \u001b[36m0.0197\u001b[0m  0.0523\n",
            "     33        \u001b[36m0.0188\u001b[0m  0.0645\n",
            "     34        \u001b[36m0.0179\u001b[0m  0.0534\n",
            "     35        \u001b[36m0.0170\u001b[0m  0.0520\n",
            "     36        \u001b[36m0.0167\u001b[0m  0.0526\n",
            "     37        \u001b[36m0.0160\u001b[0m  0.0519\n",
            "     38        \u001b[36m0.0160\u001b[0m  0.0519\n",
            "     39        \u001b[36m0.0154\u001b[0m  0.0531\n",
            "     40        \u001b[36m0.0148\u001b[0m  0.0527\n",
            "     41        \u001b[36m0.0141\u001b[0m  0.0519\n",
            "     42        \u001b[36m0.0138\u001b[0m  0.0515\n",
            "     43        \u001b[36m0.0128\u001b[0m  0.0516\n",
            "     44        0.0131  0.0534\n",
            "     45        \u001b[36m0.0125\u001b[0m  0.0521\n",
            "     46        \u001b[36m0.0119\u001b[0m  0.0545\n",
            "     47        \u001b[36m0.0114\u001b[0m  0.0542\n",
            "     48        0.0117  0.0535\n",
            "     49        \u001b[36m0.0111\u001b[0m  0.0564\n",
            "     50        \u001b[36m0.0108\u001b[0m  0.0526\n",
            "     51        0.0109  0.0518\n",
            "     52        \u001b[36m0.0104\u001b[0m  0.0641\n",
            "     53        \u001b[36m0.0102\u001b[0m  0.0522\n",
            "     54        \u001b[36m0.0096\u001b[0m  0.0534\n",
            "     55        0.0097  0.0516\n",
            "     56        0.0100  0.0520\n",
            "     57        0.0096  0.0520\n",
            "     58        \u001b[36m0.0091\u001b[0m  0.0536\n",
            "     59        0.0096  0.0530\n",
            "     60        0.0091  0.0518\n",
            "     61        0.0091  0.0518\n",
            "     62        0.0093  0.0520\n",
            "     63        \u001b[36m0.0086\u001b[0m  0.0522\n",
            "     64        0.0087  0.0557\n",
            "     65        \u001b[36m0.0084\u001b[0m  0.0525\n",
            "     66        0.0085  0.0546\n",
            "     67        0.0085  0.0536\n",
            "     68        \u001b[36m0.0080\u001b[0m  0.0555\n",
            "     69        \u001b[36m0.0078\u001b[0m  0.0565\n",
            "     70        0.0079  0.0524\n",
            "     71        \u001b[36m0.0078\u001b[0m  0.0653\n",
            "     72        \u001b[36m0.0078\u001b[0m  0.0524\n",
            "     73        0.0079  0.0534\n",
            "     74        \u001b[36m0.0076\u001b[0m  0.0519\n",
            "     75        \u001b[36m0.0075\u001b[0m  0.0516\n",
            "     76        \u001b[36m0.0072\u001b[0m  0.0531\n",
            "     77        0.0077  0.0538\n",
            "     78        0.0073  0.0519\n",
            "     79        0.0074  0.0531\n",
            "     80        0.0073  0.0542\n",
            "     81        \u001b[36m0.0070\u001b[0m  0.0528\n",
            "     82        0.0075  0.0519\n",
            "     83        0.0071  0.0518\n",
            "     84        0.0071  0.0577\n",
            "     85        0.0071  0.0520\n",
            "     86        0.0073  0.0524\n",
            "     87        \u001b[36m0.0066\u001b[0m  0.0527\n",
            "     88        0.0068  0.0517\n",
            "     89        \u001b[36m0.0066\u001b[0m  0.0536\n",
            "     90        \u001b[36m0.0066\u001b[0m  0.0654\n",
            "     91        0.0066  0.0523\n",
            "     92        \u001b[36m0.0065\u001b[0m  0.0518\n",
            "     93        0.0067  0.0522\n",
            "     94        0.0066  0.0531\n",
            "     95        \u001b[36m0.0064\u001b[0m  0.0532\n",
            "     96        0.0067  0.0532\n",
            "     97        0.0064  0.0518\n",
            "     98        0.0065  0.0522\n",
            "     99        \u001b[36m0.0062\u001b[0m  0.0538\n",
            "    100        0.0063  0.0522\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1621\u001b[0m  0.0911\n",
            "      2        \u001b[36m0.1188\u001b[0m  0.0690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3        \u001b[36m0.1018\u001b[0m  0.0661\n",
            "      4        \u001b[36m0.0920\u001b[0m  0.0639\n",
            "      5        \u001b[36m0.0815\u001b[0m  0.0647\n",
            "      6        \u001b[36m0.0760\u001b[0m  0.0795\n",
            "      7        \u001b[36m0.0701\u001b[0m  0.0644\n",
            "      8        \u001b[36m0.0662\u001b[0m  0.0643\n",
            "      9        \u001b[36m0.0610\u001b[0m  0.0673\n",
            "     10        \u001b[36m0.0574\u001b[0m  0.0662\n",
            "     11        \u001b[36m0.0551\u001b[0m  0.0642\n",
            "     12        \u001b[36m0.0513\u001b[0m  0.0643\n",
            "     13        \u001b[36m0.0481\u001b[0m  0.0648\n",
            "     14        \u001b[36m0.0462\u001b[0m  0.0649\n",
            "     15        \u001b[36m0.0435\u001b[0m  0.0666\n",
            "     16        \u001b[36m0.0408\u001b[0m  0.0660\n",
            "     17        \u001b[36m0.0380\u001b[0m  0.0645\n",
            "     18        \u001b[36m0.0365\u001b[0m  0.0693\n",
            "     19        \u001b[36m0.0344\u001b[0m  0.0695\n",
            "     20        \u001b[36m0.0325\u001b[0m  0.0660\n",
            "     21        \u001b[36m0.0318\u001b[0m  0.0786\n",
            "     22        \u001b[36m0.0306\u001b[0m  0.0659\n",
            "     23        \u001b[36m0.0290\u001b[0m  0.0641\n",
            "     24        \u001b[36m0.0271\u001b[0m  0.0763\n",
            "     25        \u001b[36m0.0262\u001b[0m  0.0702\n",
            "     26        \u001b[36m0.0249\u001b[0m  0.0648\n",
            "     27        \u001b[36m0.0239\u001b[0m  0.0652\n",
            "     28        \u001b[36m0.0225\u001b[0m  0.0687\n",
            "     29        \u001b[36m0.0217\u001b[0m  0.0665\n",
            "     30        \u001b[36m0.0203\u001b[0m  0.0668\n",
            "     31        \u001b[36m0.0200\u001b[0m  0.0648\n",
            "     32        \u001b[36m0.0188\u001b[0m  0.0647\n",
            "     33        \u001b[36m0.0177\u001b[0m  0.0643\n",
            "     34        \u001b[36m0.0172\u001b[0m  0.0692\n",
            "     35        \u001b[36m0.0160\u001b[0m  0.0649\n",
            "     36        \u001b[36m0.0156\u001b[0m  0.0720\n",
            "     37        \u001b[36m0.0146\u001b[0m  0.0684\n",
            "     38        \u001b[36m0.0145\u001b[0m  0.0656\n",
            "     39        \u001b[36m0.0139\u001b[0m  0.0677\n",
            "     40        \u001b[36m0.0135\u001b[0m  0.0651\n",
            "     41        \u001b[36m0.0132\u001b[0m  0.0642\n",
            "     42        \u001b[36m0.0129\u001b[0m  0.0712\n",
            "     43        \u001b[36m0.0126\u001b[0m  0.0643\n",
            "     44        \u001b[36m0.0121\u001b[0m  0.0662\n",
            "     45        \u001b[36m0.0113\u001b[0m  0.0682\n",
            "     46        0.0115  0.0731\n",
            "     47        \u001b[36m0.0111\u001b[0m  0.0652\n",
            "     48        \u001b[36m0.0111\u001b[0m  0.0651\n",
            "     49        \u001b[36m0.0105\u001b[0m  0.0645\n",
            "     50        0.0108  0.0665\n",
            "     51        \u001b[36m0.0105\u001b[0m  0.0644\n",
            "     52        \u001b[36m0.0102\u001b[0m  0.1006\n",
            "     53        \u001b[36m0.0097\u001b[0m  0.0989\n",
            "     54        0.0099  0.0917\n",
            "     55        \u001b[36m0.0094\u001b[0m  0.0860\n",
            "     56        \u001b[36m0.0091\u001b[0m  0.0845\n",
            "     57        0.0093  0.0853\n",
            "     58        0.0095  0.0860\n",
            "     59        0.0093  0.0864\n",
            "     60        0.0094  0.0840\n",
            "     61        0.0093  0.0850\n",
            "     62        \u001b[36m0.0091\u001b[0m  0.0800\n",
            "     63        \u001b[36m0.0088\u001b[0m  0.0925\n",
            "     64        0.0088  0.0820\n",
            "     65        \u001b[36m0.0085\u001b[0m  0.0792\n",
            "     66        \u001b[36m0.0082\u001b[0m  0.0833\n",
            "     67        \u001b[36m0.0082\u001b[0m  0.0984\n",
            "     68        \u001b[36m0.0077\u001b[0m  0.0958\n",
            "     69        0.0077  0.0949\n",
            "     70        0.0081  0.1398\n",
            "     71        0.0077  0.0920\n",
            "     72        0.0080  0.1035\n",
            "     73        0.0078  0.0972\n",
            "     74        0.0077  0.0952\n",
            "     75        \u001b[36m0.0076\u001b[0m  0.0652\n",
            "     76        \u001b[36m0.0075\u001b[0m  0.0649\n",
            "     77        \u001b[36m0.0074\u001b[0m  0.0644\n",
            "     78        0.0074  0.0673\n",
            "     79        \u001b[36m0.0072\u001b[0m  0.0689\n",
            "     80        \u001b[36m0.0071\u001b[0m  0.0664\n",
            "     81        0.0072  0.0690\n",
            "     82        \u001b[36m0.0069\u001b[0m  0.0643\n",
            "     83        0.0071  0.0693\n",
            "     84        0.0071  0.0641\n",
            "     85        \u001b[36m0.0068\u001b[0m  0.0642\n",
            "     86        \u001b[36m0.0068\u001b[0m  0.0643\n",
            "     87        0.0068  0.0656\n",
            "     88        0.0070  0.0668\n",
            "     89        \u001b[36m0.0067\u001b[0m  0.0784\n",
            "     90        0.0068  0.0642\n",
            "     91        0.0068  0.0966\n",
            "     92        \u001b[36m0.0066\u001b[0m  0.1028\n",
            "     93        0.0067  0.1443\n",
            "     94        \u001b[36m0.0064\u001b[0m  0.1230\n",
            "     95        0.0068  0.1111\n",
            "     96        0.0071  0.1645\n",
            "     97        0.0073  0.1612\n",
            "     98        0.0070  0.2193\n",
            "     99        0.0072  0.1623\n",
            "    100        0.0069  0.1221\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1487\u001b[0m  0.1278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.1106\u001b[0m  0.0700\n",
            "      3        \u001b[36m0.0918\u001b[0m  0.0650\n",
            "      4        \u001b[36m0.0797\u001b[0m  0.0676\n",
            "      5        \u001b[36m0.0717\u001b[0m  0.0694\n",
            "      6        \u001b[36m0.0663\u001b[0m  0.0749\n",
            "      7        \u001b[36m0.0615\u001b[0m  0.0666\n",
            "      8        \u001b[36m0.0565\u001b[0m  0.0680\n",
            "      9        \u001b[36m0.0536\u001b[0m  0.0679\n",
            "     10        \u001b[36m0.0507\u001b[0m  0.0698\n",
            "     11        \u001b[36m0.0473\u001b[0m  0.0668\n",
            "     12        \u001b[36m0.0440\u001b[0m  0.0655\n",
            "     13        \u001b[36m0.0410\u001b[0m  0.0648\n",
            "     14        \u001b[36m0.0372\u001b[0m  0.0665\n",
            "     15        \u001b[36m0.0348\u001b[0m  0.0651\n",
            "     16        \u001b[36m0.0320\u001b[0m  0.0653\n",
            "     17        \u001b[36m0.0292\u001b[0m  0.0651\n",
            "     18        \u001b[36m0.0272\u001b[0m  0.0660\n",
            "     19        \u001b[36m0.0243\u001b[0m  0.0660\n",
            "     20        \u001b[36m0.0225\u001b[0m  0.0653\n",
            "     21        \u001b[36m0.0213\u001b[0m  0.0786\n",
            "     22        \u001b[36m0.0200\u001b[0m  0.0666\n",
            "     23        \u001b[36m0.0183\u001b[0m  0.0669\n",
            "     24        \u001b[36m0.0175\u001b[0m  0.0669\n",
            "     25        \u001b[36m0.0165\u001b[0m  0.0655\n",
            "     26        \u001b[36m0.0157\u001b[0m  0.0709\n",
            "     27        \u001b[36m0.0149\u001b[0m  0.0654\n",
            "     28        \u001b[36m0.0140\u001b[0m  0.0647\n",
            "     29        0.0141  0.0652\n",
            "     30        \u001b[36m0.0132\u001b[0m  0.0664\n",
            "     31        \u001b[36m0.0125\u001b[0m  0.0650\n",
            "     32        \u001b[36m0.0124\u001b[0m  0.0653\n",
            "     33        \u001b[36m0.0117\u001b[0m  0.1073\n",
            "     34        \u001b[36m0.0116\u001b[0m  0.0800\n",
            "     35        \u001b[36m0.0114\u001b[0m  0.0784\n",
            "     36        \u001b[36m0.0111\u001b[0m  0.0657\n",
            "     37        \u001b[36m0.0110\u001b[0m  0.0671\n",
            "     38        \u001b[36m0.0107\u001b[0m  0.0666\n",
            "     39        \u001b[36m0.0105\u001b[0m  0.0670\n",
            "     40        \u001b[36m0.0101\u001b[0m  0.0671\n",
            "     41        0.0101  0.0655\n",
            "     42        \u001b[36m0.0098\u001b[0m  0.0712\n",
            "     43        \u001b[36m0.0096\u001b[0m  0.0740\n",
            "     44        0.0098  0.0798\n",
            "     45        \u001b[36m0.0092\u001b[0m  0.0660\n",
            "     46        0.0093  0.0661\n",
            "     47        \u001b[36m0.0089\u001b[0m  0.0674\n",
            "     48        0.0089  0.0646\n",
            "     49        \u001b[36m0.0084\u001b[0m  0.0649\n",
            "     50        0.0086  0.0800\n",
            "     51        0.0086  0.0719\n",
            "     52        0.0086  0.0742\n",
            "     53        \u001b[36m0.0082\u001b[0m  0.0645\n",
            "     54        0.0084  0.0702\n",
            "     55        \u001b[36m0.0081\u001b[0m  0.0661\n",
            "     56        \u001b[36m0.0079\u001b[0m  0.0662\n",
            "     57        0.0080  0.0700\n",
            "     58        \u001b[36m0.0075\u001b[0m  0.0671\n",
            "     59        0.0078  0.0649\n",
            "     60        \u001b[36m0.0075\u001b[0m  0.0671\n",
            "     61        0.0076  0.0665\n",
            "     62        \u001b[36m0.0073\u001b[0m  0.0672\n",
            "     63        0.0073  0.0651\n",
            "     64        \u001b[36m0.0072\u001b[0m  0.0649\n",
            "     65        0.0075  0.0806\n",
            "     66        0.0074  0.0672\n",
            "     67        \u001b[36m0.0071\u001b[0m  0.0683\n",
            "     68        \u001b[36m0.0070\u001b[0m  0.0673\n",
            "     69        \u001b[36m0.0068\u001b[0m  0.0653\n",
            "     70        \u001b[36m0.0067\u001b[0m  0.0717\n",
            "     71        0.0070  0.0659\n",
            "     72        0.0067  0.0660\n",
            "     73        0.0067  0.0676\n",
            "     74        \u001b[36m0.0066\u001b[0m  0.0652\n",
            "     75        \u001b[36m0.0065\u001b[0m  0.0651\n",
            "     76        0.0066  0.0681\n",
            "     77        0.0067  0.0648\n",
            "     78        \u001b[36m0.0063\u001b[0m  0.0666\n",
            "     79        0.0066  0.0652\n",
            "     80        \u001b[36m0.0062\u001b[0m  0.0793\n",
            "     81        0.0063  0.0669\n",
            "     82        0.0066  0.0715\n",
            "     83        \u001b[36m0.0062\u001b[0m  0.0672\n",
            "     84        0.0063  0.0653\n",
            "     85        0.0062  0.0648\n",
            "     86        \u001b[36m0.0060\u001b[0m  0.0662\n",
            "     87        0.0061  0.0654\n",
            "     88        \u001b[36m0.0060\u001b[0m  0.0655\n",
            "     89        0.0060  0.0647\n",
            "     90        \u001b[36m0.0058\u001b[0m  0.0663\n",
            "     91        0.0060  0.0662\n",
            "     92        0.0059  0.0650\n",
            "     93        0.0059  0.0652\n",
            "     94        0.0058  0.0668\n",
            "     95        0.0058  0.0918\n",
            "     96        \u001b[36m0.0056\u001b[0m  0.0726\n",
            "     97        \u001b[36m0.0056\u001b[0m  0.0676\n",
            "     98        0.0058  0.0716\n",
            "     99        0.0057  0.0657\n",
            "    100        \u001b[36m0.0055\u001b[0m  0.0683\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1456\u001b[0m  0.0911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.1057\u001b[0m  0.0853\n",
            "      3        \u001b[36m0.0896\u001b[0m  0.0857\n",
            "      4        \u001b[36m0.0787\u001b[0m  0.1233\n",
            "      5        \u001b[36m0.0709\u001b[0m  0.1096\n",
            "      6        \u001b[36m0.0660\u001b[0m  0.1208\n",
            "      7        \u001b[36m0.0607\u001b[0m  0.1071\n",
            "      8        \u001b[36m0.0560\u001b[0m  0.1035\n",
            "      9        \u001b[36m0.0516\u001b[0m  0.1028\n",
            "     10        \u001b[36m0.0473\u001b[0m  0.1056\n",
            "     11        \u001b[36m0.0443\u001b[0m  0.1034\n",
            "     12        \u001b[36m0.0405\u001b[0m  0.0979\n",
            "     13        \u001b[36m0.0380\u001b[0m  0.0972\n",
            "     14        \u001b[36m0.0351\u001b[0m  0.0961\n",
            "     15        \u001b[36m0.0336\u001b[0m  0.1000\n",
            "     16        \u001b[36m0.0319\u001b[0m  0.1272\n",
            "     17        \u001b[36m0.0292\u001b[0m  0.1149\n",
            "     18        \u001b[36m0.0272\u001b[0m  0.1122\n",
            "     19        \u001b[36m0.0257\u001b[0m  0.1225\n",
            "     20        \u001b[36m0.0240\u001b[0m  0.1202\n",
            "     21        \u001b[36m0.0223\u001b[0m  0.1245\n",
            "     22        \u001b[36m0.0213\u001b[0m  0.1042\n",
            "     23        \u001b[36m0.0207\u001b[0m  0.0783\n",
            "     24        \u001b[36m0.0194\u001b[0m  0.0791\n",
            "     25        \u001b[36m0.0182\u001b[0m  0.0824\n",
            "     26        \u001b[36m0.0172\u001b[0m  0.0940\n",
            "     27        \u001b[36m0.0167\u001b[0m  0.0875\n",
            "     28        \u001b[36m0.0160\u001b[0m  0.0773\n",
            "     29        \u001b[36m0.0147\u001b[0m  0.0775\n",
            "     30        \u001b[36m0.0140\u001b[0m  0.0776\n",
            "     31        \u001b[36m0.0135\u001b[0m  0.0790\n",
            "     32        \u001b[36m0.0129\u001b[0m  0.0783\n",
            "     33        \u001b[36m0.0125\u001b[0m  0.0778\n",
            "     34        \u001b[36m0.0117\u001b[0m  0.0787\n",
            "     35        \u001b[36m0.0117\u001b[0m  0.0791\n",
            "     36        \u001b[36m0.0113\u001b[0m  0.0786\n",
            "     37        \u001b[36m0.0111\u001b[0m  0.0822\n",
            "     38        \u001b[36m0.0109\u001b[0m  0.0791\n",
            "     39        \u001b[36m0.0106\u001b[0m  0.0968\n",
            "     40        \u001b[36m0.0103\u001b[0m  0.0777\n",
            "     41        \u001b[36m0.0100\u001b[0m  0.0776\n",
            "     42        \u001b[36m0.0098\u001b[0m  0.0792\n",
            "     43        \u001b[36m0.0094\u001b[0m  0.0773\n",
            "     44        \u001b[36m0.0093\u001b[0m  0.0781\n",
            "     45        \u001b[36m0.0090\u001b[0m  0.0800\n",
            "     46        \u001b[36m0.0088\u001b[0m  0.0784\n",
            "     47        \u001b[36m0.0086\u001b[0m  0.0782\n",
            "     48        \u001b[36m0.0086\u001b[0m  0.0785\n",
            "     49        0.0087  0.0796\n",
            "     50        \u001b[36m0.0084\u001b[0m  0.0893\n",
            "     51        \u001b[36m0.0081\u001b[0m  0.1044\n",
            "     52        \u001b[36m0.0080\u001b[0m  0.0771\n",
            "     53        \u001b[36m0.0078\u001b[0m  0.0825\n",
            "     54        0.0079  0.0773\n",
            "     55        \u001b[36m0.0075\u001b[0m  0.0775\n",
            "     56        0.0076  0.0783\n",
            "     57        0.0077  0.0819\n",
            "     58        \u001b[36m0.0073\u001b[0m  0.0772\n",
            "     59        \u001b[36m0.0072\u001b[0m  0.0778\n",
            "     60        0.0073  0.0783\n",
            "     61        \u001b[36m0.0071\u001b[0m  0.0787\n",
            "     62        \u001b[36m0.0070\u001b[0m  0.0806\n",
            "     63        \u001b[36m0.0068\u001b[0m  0.0788\n",
            "     64        0.0068  0.1003\n",
            "     65        \u001b[36m0.0068\u001b[0m  0.0783\n",
            "     66        0.0068  0.0778\n",
            "     67        \u001b[36m0.0067\u001b[0m  0.0778\n",
            "     68        \u001b[36m0.0064\u001b[0m  0.0775\n",
            "     69        0.0066  0.0790\n",
            "     70        0.0065  0.0793\n",
            "     71        \u001b[36m0.0061\u001b[0m  0.0778\n",
            "     72        0.0064  0.0776\n",
            "     73        \u001b[36m0.0061\u001b[0m  0.0786\n",
            "     74        0.0065  0.0817\n",
            "     75        0.0063  0.0772\n",
            "     76        0.0062  0.0795\n",
            "     77        0.0062  0.1074\n",
            "     78        \u001b[36m0.0060\u001b[0m  0.0780\n",
            "     79        0.0060  0.0787\n",
            "     80        \u001b[36m0.0059\u001b[0m  0.0788\n",
            "     81        \u001b[36m0.0057\u001b[0m  0.0788\n",
            "     82        0.0060  0.0786\n",
            "     83        \u001b[36m0.0056\u001b[0m  0.0775\n",
            "     84        0.0058  0.0813\n",
            "     85        \u001b[36m0.0056\u001b[0m  0.0787\n",
            "     86        0.0056  0.0819\n",
            "     87        \u001b[36m0.0055\u001b[0m  0.0792\n",
            "     88        0.0055  0.0857\n",
            "     89        0.0057  0.0919\n",
            "     90        \u001b[36m0.0054\u001b[0m  0.0778\n",
            "     91        0.0055  0.0795\n",
            "     92        \u001b[36m0.0054\u001b[0m  0.0775\n",
            "     93        \u001b[36m0.0054\u001b[0m  0.0773\n",
            "     94        0.0055  0.0801\n",
            "     95        0.0056  0.0783\n",
            "     96        \u001b[36m0.0052\u001b[0m  0.0787\n",
            "     97        \u001b[36m0.0052\u001b[0m  0.0786\n",
            "     98        \u001b[36m0.0051\u001b[0m  0.0798\n",
            "     99        \u001b[36m0.0051\u001b[0m  0.0769\n",
            "    100        \u001b[36m0.0051\u001b[0m  0.0781\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1390\u001b[0m  0.1296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.1031\u001b[0m  0.0947\n",
            "      3        \u001b[36m0.0877\u001b[0m  0.0895\n",
            "      4        \u001b[36m0.0795\u001b[0m  0.0892\n",
            "      5        \u001b[36m0.0724\u001b[0m  0.0908\n",
            "      6        \u001b[36m0.0669\u001b[0m  0.0908\n",
            "      7        \u001b[36m0.0616\u001b[0m  0.0936\n",
            "      8        \u001b[36m0.0583\u001b[0m  0.1083\n",
            "      9        \u001b[36m0.0544\u001b[0m  0.1063\n",
            "     10        \u001b[36m0.0506\u001b[0m  0.0984\n",
            "     11        \u001b[36m0.0476\u001b[0m  0.0918\n",
            "     12        \u001b[36m0.0449\u001b[0m  0.1006\n",
            "     13        \u001b[36m0.0418\u001b[0m  0.0919\n",
            "     14        \u001b[36m0.0390\u001b[0m  0.0915\n",
            "     15        \u001b[36m0.0368\u001b[0m  0.0934\n",
            "     16        \u001b[36m0.0344\u001b[0m  0.0912\n",
            "     17        \u001b[36m0.0322\u001b[0m  0.0966\n",
            "     18        \u001b[36m0.0302\u001b[0m  0.0929\n",
            "     19        \u001b[36m0.0283\u001b[0m  0.0923\n",
            "     20        \u001b[36m0.0263\u001b[0m  0.0904\n",
            "     21        \u001b[36m0.0237\u001b[0m  0.0915\n",
            "     22        \u001b[36m0.0224\u001b[0m  0.0995\n",
            "     23        \u001b[36m0.0205\u001b[0m  0.0984\n",
            "     24        \u001b[36m0.0199\u001b[0m  0.0895\n",
            "     25        \u001b[36m0.0182\u001b[0m  0.0905\n",
            "     26        \u001b[36m0.0169\u001b[0m  0.0904\n",
            "     27        \u001b[36m0.0162\u001b[0m  0.0906\n",
            "     28        \u001b[36m0.0156\u001b[0m  0.0920\n",
            "     29        \u001b[36m0.0147\u001b[0m  0.0907\n",
            "     30        \u001b[36m0.0140\u001b[0m  0.0922\n",
            "     31        \u001b[36m0.0129\u001b[0m  0.0964\n",
            "     32        \u001b[36m0.0123\u001b[0m  0.0895\n",
            "     33        \u001b[36m0.0121\u001b[0m  0.0905\n",
            "     34        \u001b[36m0.0115\u001b[0m  0.1034\n",
            "     35        \u001b[36m0.0112\u001b[0m  0.0894\n",
            "     36        \u001b[36m0.0107\u001b[0m  0.0922\n",
            "     37        \u001b[36m0.0102\u001b[0m  0.0896\n",
            "     38        0.0103  0.1166\n",
            "     39        \u001b[36m0.0099\u001b[0m  0.1318\n",
            "     40        \u001b[36m0.0096\u001b[0m  0.1209\n",
            "     41        \u001b[36m0.0094\u001b[0m  0.1183\n",
            "     42        \u001b[36m0.0091\u001b[0m  0.1176\n",
            "     43        0.0097  0.1294\n",
            "     44        \u001b[36m0.0087\u001b[0m  0.1201\n",
            "     45        \u001b[36m0.0086\u001b[0m  0.1143\n",
            "     46        \u001b[36m0.0084\u001b[0m  0.1115\n",
            "     47        0.0084  0.1129\n",
            "     48        \u001b[36m0.0083\u001b[0m  0.1145\n",
            "     49        \u001b[36m0.0083\u001b[0m  0.1375\n",
            "     50        \u001b[36m0.0082\u001b[0m  0.1311\n",
            "     51        \u001b[36m0.0079\u001b[0m  0.1462\n",
            "     52        \u001b[36m0.0076\u001b[0m  0.1458\n",
            "     53        0.0077  0.1436\n",
            "     54        0.0076  0.1115\n",
            "     55        \u001b[36m0.0075\u001b[0m  0.0914\n",
            "     56        \u001b[36m0.0074\u001b[0m  0.0930\n",
            "     57        \u001b[36m0.0072\u001b[0m  0.0953\n",
            "     58        \u001b[36m0.0072\u001b[0m  0.0895\n",
            "     59        \u001b[36m0.0069\u001b[0m  0.0903\n",
            "     60        \u001b[36m0.0069\u001b[0m  0.0921\n",
            "     61        \u001b[36m0.0069\u001b[0m  0.0958\n",
            "     62        0.0070  0.0977\n",
            "     63        0.0070  0.1001\n",
            "     64        \u001b[36m0.0066\u001b[0m  0.0897\n",
            "     65        \u001b[36m0.0065\u001b[0m  0.0924\n",
            "     66        \u001b[36m0.0065\u001b[0m  0.0928\n",
            "     67        \u001b[36m0.0065\u001b[0m  0.0911\n",
            "     68        \u001b[36m0.0065\u001b[0m  0.0918\n",
            "     69        \u001b[36m0.0062\u001b[0m  0.0952\n",
            "     70        0.0063  0.0901\n",
            "     71        0.0063  0.0909\n",
            "     72        \u001b[36m0.0061\u001b[0m  0.1007\n",
            "     73        0.0063  0.0938\n",
            "     74        0.0062  0.0899\n",
            "     75        0.0063  0.0956\n",
            "     76        \u001b[36m0.0060\u001b[0m  0.0941\n",
            "     77        \u001b[36m0.0060\u001b[0m  0.0917\n",
            "     78        \u001b[36m0.0058\u001b[0m  0.0944\n",
            "     79        0.0060  0.0920\n",
            "     80        \u001b[36m0.0058\u001b[0m  0.0901\n",
            "     81        \u001b[36m0.0056\u001b[0m  0.0912\n",
            "     82        0.0057  0.0897\n",
            "     83        0.0060  0.1184\n",
            "     84        \u001b[36m0.0056\u001b[0m  0.0910\n",
            "     85        \u001b[36m0.0056\u001b[0m  0.0913\n",
            "     86        0.0056  0.0906\n",
            "     87        \u001b[36m0.0056\u001b[0m  0.0930\n",
            "     88        0.0056  0.0907\n",
            "     89        \u001b[36m0.0054\u001b[0m  0.0988\n",
            "     90        \u001b[36m0.0053\u001b[0m  0.0902\n",
            "     91        \u001b[36m0.0052\u001b[0m  0.0903\n",
            "     92        0.0053  0.0906\n",
            "     93        0.0054  0.0908\n",
            "     94        0.0054  0.1038\n",
            "     95        0.0054  0.0897\n",
            "     96        \u001b[36m0.0052\u001b[0m  0.0921\n",
            "     97        0.0054  0.0902\n",
            "     98        0.0053  0.0944\n",
            "     99        0.0054  0.0943\n",
            "    100        0.0053  0.0946\n",
            "Re-initializing module because the following parameters were re-set: module__dilations, module__filters, module__kernel_size.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: dilations, filters, kernel_size, n_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1367\u001b[0m  0.1271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.0989\u001b[0m  0.1158\n",
            "      3        \u001b[36m0.0854\u001b[0m  0.1142\n",
            "      4        \u001b[36m0.0756\u001b[0m  0.1207\n",
            "      5        \u001b[36m0.0684\u001b[0m  0.1055\n",
            "      6        \u001b[36m0.0629\u001b[0m  0.1051\n",
            "      7        \u001b[36m0.0593\u001b[0m  0.1047\n",
            "      8        \u001b[36m0.0542\u001b[0m  0.1063\n",
            "      9        \u001b[36m0.0505\u001b[0m  0.1044\n",
            "     10        \u001b[36m0.0470\u001b[0m  0.1079\n",
            "     11        \u001b[36m0.0434\u001b[0m  0.1073\n",
            "     12        \u001b[36m0.0407\u001b[0m  0.1085\n",
            "     13        \u001b[36m0.0377\u001b[0m  0.1180\n",
            "     14        \u001b[36m0.0343\u001b[0m  0.1023\n",
            "     15        \u001b[36m0.0322\u001b[0m  0.1041\n",
            "     16        \u001b[36m0.0295\u001b[0m  0.1041\n",
            "     17        \u001b[36m0.0266\u001b[0m  0.1046\n",
            "     18        \u001b[36m0.0252\u001b[0m  0.1036\n",
            "     19        \u001b[36m0.0229\u001b[0m  0.1074\n",
            "     20        \u001b[36m0.0205\u001b[0m  0.1098\n",
            "     21        \u001b[36m0.0194\u001b[0m  0.1785\n",
            "     22        \u001b[36m0.0181\u001b[0m  0.1160\n",
            "     23        \u001b[36m0.0168\u001b[0m  0.1031\n",
            "     24        \u001b[36m0.0161\u001b[0m  0.1024\n",
            "     25        \u001b[36m0.0149\u001b[0m  0.1123\n",
            "     26        \u001b[36m0.0141\u001b[0m  0.1046\n",
            "     27        \u001b[36m0.0135\u001b[0m  0.1032\n",
            "     28        \u001b[36m0.0128\u001b[0m  0.1119\n",
            "     29        0.0128  0.1018\n",
            "     30        \u001b[36m0.0125\u001b[0m  0.1043\n",
            "     31        \u001b[36m0.0118\u001b[0m  0.1024\n",
            "     32        0.0118  0.1143\n",
            "     33        \u001b[36m0.0113\u001b[0m  0.1049\n",
            "     34        \u001b[36m0.0109\u001b[0m  0.1051\n",
            "     35        \u001b[36m0.0102\u001b[0m  0.1046\n",
            "     36        \u001b[36m0.0102\u001b[0m  0.1039\n",
            "     37        \u001b[36m0.0099\u001b[0m  0.1076\n",
            "     38        \u001b[36m0.0097\u001b[0m  0.1018\n",
            "     39        \u001b[36m0.0091\u001b[0m  0.1027\n",
            "     40        0.0093  0.1069\n",
            "     41        0.0092  0.1145\n",
            "     42        \u001b[36m0.0090\u001b[0m  0.1067\n",
            "     43        \u001b[36m0.0089\u001b[0m  0.1057\n",
            "     44        \u001b[36m0.0087\u001b[0m  0.1026\n",
            "     45        \u001b[36m0.0082\u001b[0m  0.1034\n",
            "     46        0.0083  0.1064\n",
            "     47        \u001b[36m0.0079\u001b[0m  0.1031\n",
            "     48        0.0079  0.1013\n",
            "     49        0.0080  0.1077\n",
            "     50        0.0080  0.1017\n",
            "     51        \u001b[36m0.0077\u001b[0m  0.1306\n",
            "     52        \u001b[36m0.0075\u001b[0m  0.1555\n",
            "     53        \u001b[36m0.0073\u001b[0m  0.1435\n",
            "     54        0.0076  0.1396\n",
            "     55        \u001b[36m0.0073\u001b[0m  0.1335\n",
            "     56        \u001b[36m0.0072\u001b[0m  0.1531\n",
            "     57        \u001b[36m0.0071\u001b[0m  0.1528\n",
            "     58        \u001b[36m0.0071\u001b[0m  0.1595\n",
            "     59        \u001b[36m0.0067\u001b[0m  0.1387\n",
            "     60        0.0067  0.1387\n",
            "     61        0.0068  0.1575\n",
            "     62        0.0069  0.1510\n",
            "     63        0.0067  0.1603\n",
            "     64        \u001b[36m0.0065\u001b[0m  0.1637\n",
            "     65        0.0068  0.1637\n",
            "     66        \u001b[36m0.0064\u001b[0m  0.1152\n",
            "     67        \u001b[36m0.0063\u001b[0m  0.1045\n",
            "     68        \u001b[36m0.0062\u001b[0m  0.1024\n",
            "     69        \u001b[36m0.0062\u001b[0m  0.1029\n",
            "     70        \u001b[36m0.0062\u001b[0m  0.1036\n",
            "     71        \u001b[36m0.0062\u001b[0m  0.1043\n",
            "     72        \u001b[36m0.0061\u001b[0m  0.1049\n",
            "     73        0.0063  0.1026\n",
            "     74        \u001b[36m0.0061\u001b[0m  0.1179\n",
            "     75        \u001b[36m0.0059\u001b[0m  0.1206\n",
            "     76        \u001b[36m0.0058\u001b[0m  0.1070\n",
            "     77        0.0060  0.1027\n",
            "     78        0.0059  0.1073\n",
            "     79        0.0060  0.1035\n",
            "     80        \u001b[36m0.0058\u001b[0m  0.1046\n",
            "     81        \u001b[36m0.0055\u001b[0m  0.1025\n",
            "     82        0.0056  0.1027\n",
            "     83        \u001b[36m0.0054\u001b[0m  0.1060\n",
            "     84        0.0055  0.1225\n",
            "     85        \u001b[36m0.0053\u001b[0m  0.1037\n",
            "     86        0.0055  0.1045\n",
            "     87        0.0054  0.1036\n",
            "     88        0.0055  0.1017\n",
            "     89        0.0054  0.1062\n",
            "     90        0.0055  0.1019\n",
            "     91        0.0053  0.1023\n",
            "     92        \u001b[36m0.0052\u001b[0m  0.1031\n",
            "     93        \u001b[36m0.0052\u001b[0m  0.1046\n",
            "     94        0.0054  0.1153\n",
            "     95        0.0052  0.1070\n",
            "     96        0.0053  0.1069\n",
            "     97        \u001b[36m0.0051\u001b[0m  0.1027\n",
            "     98        0.0052  0.1031\n",
            "     99        \u001b[36m0.0050\u001b[0m  0.1033\n",
            "    100        \u001b[36m0.0049\u001b[0m  0.1023\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1475\u001b[0m  0.0122\n",
            "      2        \u001b[36m0.0964\u001b[0m  0.0077\n",
            "      3        \u001b[36m0.0722\u001b[0m  0.0072\n",
            "      4        \u001b[36m0.0597\u001b[0m  0.0071\n",
            "      5        \u001b[36m0.0525\u001b[0m  0.0060\n",
            "      6        \u001b[36m0.0478\u001b[0m  0.0060\n",
            "      7        \u001b[36m0.0438\u001b[0m  0.0063\n",
            "      8        \u001b[36m0.0376\u001b[0m  0.0061\n",
            "      9        \u001b[36m0.0344\u001b[0m  0.0061\n",
            "     10        \u001b[36m0.0308\u001b[0m  0.0109\n",
            "     11        \u001b[36m0.0285\u001b[0m  0.0077\n",
            "     12        \u001b[36m0.0266\u001b[0m  0.0060\n",
            "     13        \u001b[36m0.0241\u001b[0m  0.0061\n",
            "     14        \u001b[36m0.0230\u001b[0m  0.0060\n",
            "     15        \u001b[36m0.0209\u001b[0m  0.0059\n",
            "     16        \u001b[36m0.0192\u001b[0m  0.0060\n",
            "     17        \u001b[36m0.0178\u001b[0m  0.0088\n",
            "     18        \u001b[36m0.0168\u001b[0m  0.0073\n",
            "     19        \u001b[36m0.0153\u001b[0m  0.0069\n",
            "     20        \u001b[36m0.0142\u001b[0m  0.0059\n",
            "     21        \u001b[36m0.0128\u001b[0m  0.0070\n",
            "     22        \u001b[36m0.0120\u001b[0m  0.0062\n",
            "     23        \u001b[36m0.0115\u001b[0m  0.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     24        \u001b[36m0.0110\u001b[0m  0.0076\n",
            "     25        \u001b[36m0.0110\u001b[0m  0.0079\n",
            "     26        \u001b[36m0.0096\u001b[0m  0.0075\n",
            "     27        \u001b[36m0.0092\u001b[0m  0.0074\n",
            "     28        0.0093  0.0061\n",
            "     29        \u001b[36m0.0086\u001b[0m  0.0060\n",
            "     30        0.0088  0.0060\n",
            "     31        \u001b[36m0.0075\u001b[0m  0.0061\n",
            "     32        0.0076  0.0060\n",
            "     33        \u001b[36m0.0073\u001b[0m  0.0084\n",
            "     34        0.0074  0.0080\n",
            "     35        \u001b[36m0.0069\u001b[0m  0.0105\n",
            "     36        \u001b[36m0.0066\u001b[0m  0.0087\n",
            "     37        \u001b[36m0.0063\u001b[0m  0.0084\n",
            "     38        0.0064  0.0104\n",
            "     39        0.0063  0.0082\n",
            "     40        \u001b[36m0.0059\u001b[0m  0.0063\n",
            "     41        \u001b[36m0.0055\u001b[0m  0.0065\n",
            "     42        0.0058  0.0075\n",
            "     43        \u001b[36m0.0053\u001b[0m  0.0065\n",
            "     44        0.0054  0.0068\n",
            "     45        \u001b[36m0.0051\u001b[0m  0.0070\n",
            "     46        \u001b[36m0.0051\u001b[0m  0.0072\n",
            "     47        \u001b[36m0.0050\u001b[0m  0.0078\n",
            "     48        0.0052  0.0059\n",
            "     49        0.0053  0.0058\n",
            "     50        \u001b[36m0.0048\u001b[0m  0.0058\n",
            "     51        0.0048  0.0058\n",
            "     52        \u001b[36m0.0045\u001b[0m  0.0057\n",
            "     53        0.0046  0.0102\n",
            "     54        \u001b[36m0.0042\u001b[0m  0.0080\n",
            "     55        0.0044  0.0064\n",
            "     56        0.0044  0.0065\n",
            "     57        0.0043  0.0066\n",
            "     58        \u001b[36m0.0042\u001b[0m  0.0058\n",
            "     59        0.0042  0.0059\n",
            "     60        \u001b[36m0.0040\u001b[0m  0.0058\n",
            "     61        \u001b[36m0.0039\u001b[0m  0.0058\n",
            "     62        0.0040  0.0057\n",
            "     63        0.0039  0.0077\n",
            "     64        0.0039  0.0076\n",
            "     65        \u001b[36m0.0037\u001b[0m  0.0076\n",
            "     66        0.0037  0.0059\n",
            "     67        \u001b[36m0.0035\u001b[0m  0.0077\n",
            "     68        0.0035  0.0060\n",
            "     69        0.0037  0.0062\n",
            "     70        0.0039  0.0079\n",
            "     71        \u001b[36m0.0035\u001b[0m  0.0081\n",
            "     72        \u001b[36m0.0034\u001b[0m  0.0067\n",
            "     73        0.0038  0.0068\n",
            "     74        0.0036  0.0058\n",
            "     75        0.0035  0.0058\n",
            "     76        0.0037  0.0059\n",
            "     77        \u001b[36m0.0033\u001b[0m  0.0058\n",
            "     78        0.0037  0.0059\n",
            "     79        \u001b[36m0.0031\u001b[0m  0.0089\n",
            "     80        0.0032  0.0082\n",
            "     81        0.0035  0.0067\n",
            "     82        0.0035  0.0068\n",
            "     83        0.0032  0.0058\n",
            "     84        0.0033  0.0058\n",
            "     85        \u001b[36m0.0030\u001b[0m  0.0058\n",
            "     86        0.0031  0.0059\n",
            "     87        \u001b[36m0.0030\u001b[0m  0.0062\n",
            "     88        \u001b[36m0.0028\u001b[0m  0.0089\n",
            "     89        0.0033  0.0086\n",
            "     90        0.0029  0.0067\n",
            "     91        0.0030  0.0068\n",
            "     92        0.0030  0.0061\n",
            "     93        0.0029  0.0060\n",
            "     94        0.0030  0.0067\n",
            "     95        0.0031  0.0061\n",
            "     96        0.0030  0.0059\n",
            "     97        0.0028  0.0087\n",
            "     98        0.0031  0.0073\n",
            "     99        0.0029  0.0060\n",
            "    100        0.0029  0.0071\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1401\u001b[0m  0.0217\n",
            "      2        \u001b[36m0.0801\u001b[0m  0.0125\n",
            "      3        \u001b[36m0.0564\u001b[0m  0.0124\n",
            "      4        \u001b[36m0.0455\u001b[0m  0.0120\n",
            "      5        \u001b[36m0.0378\u001b[0m  0.0114\n",
            "      6        \u001b[36m0.0311\u001b[0m  0.0115\n",
            "      7        \u001b[36m0.0273\u001b[0m  0.0144\n",
            "      8        \u001b[36m0.0234\u001b[0m  0.0124\n",
            "      9        \u001b[36m0.0201\u001b[0m  0.0126\n",
            "     10        \u001b[36m0.0174\u001b[0m  0.0115\n",
            "     11        \u001b[36m0.0156\u001b[0m  0.0113\n",
            "     12        \u001b[36m0.0139\u001b[0m  0.0158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     13        \u001b[36m0.0128\u001b[0m  0.0143\n",
            "     14        \u001b[36m0.0113\u001b[0m  0.0124\n",
            "     15        \u001b[36m0.0107\u001b[0m  0.0123\n",
            "     16        \u001b[36m0.0099\u001b[0m  0.0112\n",
            "     17        \u001b[36m0.0091\u001b[0m  0.0124\n",
            "     18        \u001b[36m0.0081\u001b[0m  0.0134\n",
            "     19        0.0082  0.0121\n",
            "     20        \u001b[36m0.0076\u001b[0m  0.0126\n",
            "     21        \u001b[36m0.0073\u001b[0m  0.0130\n",
            "     22        \u001b[36m0.0068\u001b[0m  0.0126\n",
            "     23        \u001b[36m0.0067\u001b[0m  0.0114\n",
            "     24        \u001b[36m0.0065\u001b[0m  0.0114\n",
            "     25        \u001b[36m0.0063\u001b[0m  0.0142\n",
            "     26        0.0065  0.0133\n",
            "     27        \u001b[36m0.0058\u001b[0m  0.0123\n",
            "     28        \u001b[36m0.0057\u001b[0m  0.0120\n",
            "     29        \u001b[36m0.0054\u001b[0m  0.0125\n",
            "     30        0.0055  0.0116\n",
            "     31        0.0055  0.0115\n",
            "     32        \u001b[36m0.0052\u001b[0m  0.0141\n",
            "     33        \u001b[36m0.0051\u001b[0m  0.0120\n",
            "     34        \u001b[36m0.0050\u001b[0m  0.0133\n",
            "     35        \u001b[36m0.0047\u001b[0m  0.0115\n",
            "     36        0.0048  0.0136\n",
            "     37        \u001b[36m0.0045\u001b[0m  0.0203\n",
            "     38        0.0047  0.0168\n",
            "     39        \u001b[36m0.0045\u001b[0m  0.0121\n",
            "     40        0.0047  0.0120\n",
            "     41        0.0045  0.0134\n",
            "     42        \u001b[36m0.0043\u001b[0m  0.0126\n",
            "     43        0.0044  0.0115\n",
            "     44        0.0045  0.0115\n",
            "     45        0.0044  0.0143\n",
            "     46        0.0044  0.0126\n",
            "     47        \u001b[36m0.0042\u001b[0m  0.0138\n",
            "     48        \u001b[36m0.0040\u001b[0m  0.0115\n",
            "     49        0.0041  0.0115\n",
            "     50        0.0041  0.0142\n",
            "     51        0.0040  0.0124\n",
            "     52        0.0041  0.0126\n",
            "     53        \u001b[36m0.0037\u001b[0m  0.0116\n",
            "     54        0.0038  0.0126\n",
            "     55        \u001b[36m0.0037\u001b[0m  0.0140\n",
            "     56        \u001b[36m0.0035\u001b[0m  0.0128\n",
            "     57        0.0038  0.0120\n",
            "     58        \u001b[36m0.0035\u001b[0m  0.0115\n",
            "     59        0.0036  0.0115\n",
            "     60        0.0036  0.0159\n",
            "     61        \u001b[36m0.0035\u001b[0m  0.0122\n",
            "     62        \u001b[36m0.0035\u001b[0m  0.0123\n",
            "     63        \u001b[36m0.0033\u001b[0m  0.0122\n",
            "     64        0.0038  0.0114\n",
            "     65        0.0034  0.0125\n",
            "     66        0.0035  0.0136\n",
            "     67        \u001b[36m0.0031\u001b[0m  0.0124\n",
            "     68        0.0031  0.0127\n",
            "     69        0.0035  0.0124\n",
            "     70        0.0031  0.0122\n",
            "     71        0.0034  0.0114\n",
            "     72        0.0033  0.0118\n",
            "     73        0.0035  0.0164\n",
            "     74        0.0033  0.0122\n",
            "     75        \u001b[36m0.0030\u001b[0m  0.0123\n",
            "     76        0.0031  0.0115\n",
            "     77        \u001b[36m0.0030\u001b[0m  0.0116\n",
            "     78        0.0030  0.0137\n",
            "     79        0.0030  0.0128\n",
            "     80        0.0033  0.0121\n",
            "     81        0.0031  0.0117\n",
            "     82        \u001b[36m0.0029\u001b[0m  0.0116\n",
            "     83        0.0031  0.0149\n",
            "     84        0.0030  0.0127\n",
            "     85        0.0031  0.0126\n",
            "     86        \u001b[36m0.0028\u001b[0m  0.0118\n",
            "     87        0.0030  0.0117\n",
            "     88        0.0029  0.0158\n",
            "     89        \u001b[36m0.0028\u001b[0m  0.0136\n",
            "     90        0.0030  0.0126\n",
            "     91        \u001b[36m0.0028\u001b[0m  0.0126\n",
            "     92        0.0031  0.0130\n",
            "     93        0.0029  0.0125\n",
            "     94        0.0028  0.0124\n",
            "     95        \u001b[36m0.0026\u001b[0m  0.0118\n",
            "     96        0.0028  0.0118\n",
            "     97        0.0030  0.0138\n",
            "     98        0.0029  0.0126\n",
            "     99        0.0027  0.0125\n",
            "    100        0.0026  0.0124\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1273\u001b[0m  0.0254\n",
            "      2        \u001b[36m0.0594\u001b[0m  0.0191\n",
            "      3        \u001b[36m0.0418\u001b[0m  0.0198\n",
            "      4        \u001b[36m0.0331\u001b[0m  0.0196\n",
            "      5        \u001b[36m0.0264\u001b[0m  0.0199\n",
            "      6        \u001b[36m0.0218\u001b[0m  0.0276\n",
            "      7        \u001b[36m0.0186\u001b[0m  0.0289\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      8        \u001b[36m0.0164\u001b[0m  0.0261\n",
            "      9        \u001b[36m0.0144\u001b[0m  0.0205\n",
            "     10        \u001b[36m0.0126\u001b[0m  0.0198\n",
            "     11        \u001b[36m0.0113\u001b[0m  0.0186\n",
            "     12        \u001b[36m0.0104\u001b[0m  0.0209\n",
            "     13        \u001b[36m0.0101\u001b[0m  0.0201\n",
            "     14        \u001b[36m0.0093\u001b[0m  0.0202\n",
            "     15        \u001b[36m0.0088\u001b[0m  0.0189\n",
            "     16        \u001b[36m0.0083\u001b[0m  0.0205\n",
            "     17        \u001b[36m0.0082\u001b[0m  0.0212\n",
            "     18        \u001b[36m0.0079\u001b[0m  0.0185\n",
            "     19        \u001b[36m0.0071\u001b[0m  0.0197\n",
            "     20        \u001b[36m0.0071\u001b[0m  0.0184\n",
            "     21        \u001b[36m0.0068\u001b[0m  0.0184\n",
            "     22        \u001b[36m0.0064\u001b[0m  0.0187\n",
            "     23        0.0064  0.0200\n",
            "     24        \u001b[36m0.0063\u001b[0m  0.0182\n",
            "     25        \u001b[36m0.0059\u001b[0m  0.0180\n",
            "     26        \u001b[36m0.0058\u001b[0m  0.0183\n",
            "     27        \u001b[36m0.0057\u001b[0m  0.0184\n",
            "     28        \u001b[36m0.0055\u001b[0m  0.0186\n",
            "     29        \u001b[36m0.0054\u001b[0m  0.0200\n",
            "     30        0.0056  0.0192\n",
            "     31        \u001b[36m0.0053\u001b[0m  0.0183\n",
            "     32        \u001b[36m0.0050\u001b[0m  0.0184\n",
            "     33        \u001b[36m0.0048\u001b[0m  0.0508\n",
            "     34        0.0050  0.0426\n",
            "     35        0.0050  0.0413\n",
            "     36        0.0048  0.0508\n",
            "     37        \u001b[36m0.0048\u001b[0m  0.0605\n",
            "     38        \u001b[36m0.0047\u001b[0m  0.0361\n",
            "     39        \u001b[36m0.0046\u001b[0m  0.0232\n",
            "     40        \u001b[36m0.0043\u001b[0m  0.0303\n",
            "     41        0.0044  0.0418\n",
            "     42        0.0043  0.0346\n",
            "     43        0.0045  0.0185\n",
            "     44        0.0044  0.0203\n",
            "     45        \u001b[36m0.0042\u001b[0m  0.0195\n",
            "     46        \u001b[36m0.0041\u001b[0m  0.0295\n",
            "     47        0.0045  0.0196\n",
            "     48        0.0043  0.0190\n",
            "     49        \u001b[36m0.0040\u001b[0m  0.0189\n",
            "     50        0.0042  0.0180\n",
            "     51        \u001b[36m0.0039\u001b[0m  0.0198\n",
            "     52        0.0042  0.0196\n",
            "     53        0.0042  0.0224\n",
            "     54        \u001b[36m0.0039\u001b[0m  0.0190\n",
            "     55        \u001b[36m0.0038\u001b[0m  0.0185\n",
            "     56        \u001b[36m0.0038\u001b[0m  0.0210\n",
            "     57        0.0039  0.0200\n",
            "     58        \u001b[36m0.0035\u001b[0m  0.0192\n",
            "     59        0.0037  0.0187\n",
            "     60        0.0035  0.0199\n",
            "     61        0.0039  0.0184\n",
            "     62        \u001b[36m0.0035\u001b[0m  0.0176\n",
            "     63        0.0038  0.0197\n",
            "     64        0.0037  0.0184\n",
            "     65        \u001b[36m0.0034\u001b[0m  0.0186\n",
            "     66        0.0034  0.0209\n",
            "     67        0.0034  0.0532\n",
            "     68        0.0036  0.0524\n",
            "     69        \u001b[36m0.0034\u001b[0m  0.0466\n",
            "     70        0.0035  0.0497\n",
            "     71        0.0035  0.0497\n",
            "     72        \u001b[36m0.0033\u001b[0m  0.0227\n",
            "     73        0.0034  0.0504\n",
            "     74        0.0034  0.0443\n",
            "     75        \u001b[36m0.0032\u001b[0m  0.0184\n",
            "     76        0.0033  0.0173\n",
            "     77        0.0033  0.0193\n",
            "     78        \u001b[36m0.0032\u001b[0m  0.0182\n",
            "     79        0.0034  0.0193\n",
            "     80        0.0033  0.0184\n",
            "     81        0.0032  0.0178\n",
            "     82        0.0032  0.0174\n",
            "     83        \u001b[36m0.0030\u001b[0m  0.0197\n",
            "     84        0.0034  0.0192\n",
            "     85        0.0033  0.0216\n",
            "     86        0.0033  0.0270\n",
            "     87        0.0033  0.0187\n",
            "     88        0.0031  0.0178\n",
            "     89        0.0031  0.0178\n",
            "     90        0.0034  0.0188\n",
            "     91        0.0031  0.0186\n",
            "     92        0.0031  0.0186\n",
            "     93        \u001b[36m0.0029\u001b[0m  0.0216\n",
            "     94        \u001b[36m0.0028\u001b[0m  0.0180\n",
            "     95        0.0030  0.0189\n",
            "     96        0.0029  0.0185\n",
            "     97        0.0030  0.0184\n",
            "     98        0.0031  0.0180\n",
            "     99        0.0028  0.0205\n",
            "    100        0.0031  0.0532\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1188\u001b[0m  0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2        \u001b[36m0.0567\u001b[0m  0.0717\n",
            "      3        \u001b[36m0.0402\u001b[0m  0.0482\n",
            "      4        \u001b[36m0.0305\u001b[0m  0.0338\n",
            "      5        \u001b[36m0.0238\u001b[0m  0.0195\n",
            "      6        \u001b[36m0.0200\u001b[0m  0.0213\n",
            "      7        \u001b[36m0.0160\u001b[0m  0.0214\n",
            "      8        \u001b[36m0.0135\u001b[0m  0.0196\n",
            "      9        \u001b[36m0.0118\u001b[0m  0.0196\n",
            "     10        \u001b[36m0.0111\u001b[0m  0.0229\n",
            "     11        \u001b[36m0.0102\u001b[0m  0.0196\n",
            "     12        \u001b[36m0.0092\u001b[0m  0.0247\n",
            "     13        \u001b[36m0.0083\u001b[0m  0.0191\n",
            "     14        \u001b[36m0.0078\u001b[0m  0.0192\n",
            "     15        \u001b[36m0.0076\u001b[0m  0.0194\n",
            "     16        \u001b[36m0.0070\u001b[0m  0.0194\n",
            "     17        \u001b[36m0.0068\u001b[0m  0.0195\n",
            "     18        \u001b[36m0.0067\u001b[0m  0.0208\n",
            "     19        \u001b[36m0.0065\u001b[0m  0.0185\n",
            "     20        0.0066  0.0198\n",
            "     21        \u001b[36m0.0062\u001b[0m  0.0265\n",
            "     22        \u001b[36m0.0058\u001b[0m  0.0207\n",
            "     23        \u001b[36m0.0058\u001b[0m  0.0191\n",
            "     24        \u001b[36m0.0057\u001b[0m  0.0203\n",
            "     25        \u001b[36m0.0052\u001b[0m  0.0194\n",
            "     26        0.0052  0.0188\n",
            "     27        \u001b[36m0.0050\u001b[0m  0.0192\n",
            "     28        0.0051  0.0193\n",
            "     29        0.0053  0.0190\n",
            "     30        \u001b[36m0.0048\u001b[0m  0.0188\n",
            "     31        \u001b[36m0.0046\u001b[0m  0.0181\n",
            "     32        0.0048  0.0203\n",
            "     33        \u001b[36m0.0045\u001b[0m  0.0188\n",
            "     34        \u001b[36m0.0044\u001b[0m  0.0196\n",
            "     35        0.0046  0.0196\n",
            "     36        \u001b[36m0.0043\u001b[0m  0.0182\n",
            "     37        0.0045  0.0220\n",
            "     38        0.0043  0.0189\n",
            "     39        0.0044  0.0192\n",
            "     40        \u001b[36m0.0043\u001b[0m  0.0181\n",
            "     41        \u001b[36m0.0042\u001b[0m  0.0200\n",
            "     42        \u001b[36m0.0041\u001b[0m  0.0187\n",
            "     43        0.0042  0.0188\n",
            "     44        0.0043  0.0180\n",
            "     45        \u001b[36m0.0038\u001b[0m  0.0198\n",
            "     46        0.0040  0.0189\n",
            "     47        0.0040  0.0188\n",
            "     48        \u001b[36m0.0038\u001b[0m  0.0211\n",
            "     49        0.0038  0.0181\n",
            "     50        \u001b[36m0.0036\u001b[0m  0.0207\n",
            "     51        0.0039  0.0195\n",
            "     52        0.0036  0.0191\n",
            "     53        0.0037  0.0194\n",
            "     54        0.0037  0.0180\n",
            "     55        0.0036  0.0197\n",
            "     56        \u001b[36m0.0035\u001b[0m  0.0199\n",
            "     57        0.0035  0.0193\n",
            "     58        0.0036  0.0191\n",
            "     59        0.0036  0.0208\n",
            "     60        0.0036  0.0266\n",
            "     61        0.0036  0.0278\n",
            "     62        \u001b[36m0.0035\u001b[0m  0.0262\n",
            "     63        \u001b[36m0.0033\u001b[0m  0.0286\n",
            "     64        0.0036  0.0262\n",
            "     65        0.0038  0.0244\n",
            "     66        0.0035  0.0245\n",
            "     67        \u001b[36m0.0032\u001b[0m  0.0228\n",
            "     68        0.0035  0.0240\n",
            "     69        \u001b[36m0.0032\u001b[0m  0.0314\n",
            "     70        0.0032  0.0286\n",
            "     71        \u001b[36m0.0031\u001b[0m  0.0222\n",
            "     72        0.0033  0.0232\n",
            "     73        0.0031  0.0222\n",
            "     74        0.0032  0.0285\n",
            "     75        0.0034  0.0262\n",
            "     76        0.0032  0.0221\n",
            "     77        0.0032  0.0228\n",
            "     78        0.0031  0.0221\n",
            "     79        \u001b[36m0.0031\u001b[0m  0.0221\n",
            "     80        \u001b[36m0.0030\u001b[0m  0.0221\n",
            "     81        0.0031  0.0222\n",
            "     82        0.0031  0.0222\n",
            "     83        \u001b[36m0.0030\u001b[0m  0.0227\n",
            "     84        \u001b[36m0.0029\u001b[0m  0.0246\n",
            "     85        \u001b[36m0.0028\u001b[0m  0.0317\n",
            "     86        0.0029  0.0266\n",
            "     87        0.0030  0.0239\n",
            "     88        \u001b[36m0.0028\u001b[0m  0.0226\n",
            "     89        0.0029  0.0227\n",
            "     90        0.0029  0.0236\n",
            "     91        0.0031  0.0266\n",
            "     92        0.0032  0.0244\n",
            "     93        0.0031  0.0230\n",
            "     94        0.0031  0.0224\n",
            "     95        0.0028  0.0223\n",
            "     96        0.0030  0.0226\n",
            "     97        \u001b[36m0.0028\u001b[0m  0.0223\n",
            "     98        0.0031  0.0223\n",
            "     99        \u001b[36m0.0028\u001b[0m  0.0225\n",
            "    100        0.0029  0.0222\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1295\u001b[0m  0.0491\n",
            "      2        \u001b[36m0.0659\u001b[0m  0.0290\n",
            "      3        \u001b[36m0.0455\u001b[0m  0.0323\n",
            "      4        \u001b[36m0.0339\u001b[0m  0.0300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.0257\u001b[0m  0.0321\n",
            "      6        \u001b[36m0.0203\u001b[0m  0.0324\n",
            "      7        \u001b[36m0.0160\u001b[0m  0.0311\n",
            "      8        \u001b[36m0.0127\u001b[0m  0.0323\n",
            "      9        \u001b[36m0.0110\u001b[0m  0.0312\n",
            "     10        \u001b[36m0.0098\u001b[0m  0.0317\n",
            "     11        \u001b[36m0.0089\u001b[0m  0.0329\n",
            "     12        \u001b[36m0.0084\u001b[0m  0.0304\n",
            "     13        \u001b[36m0.0081\u001b[0m  0.0329\n",
            "     14        \u001b[36m0.0074\u001b[0m  0.0323\n",
            "     15        \u001b[36m0.0070\u001b[0m  0.0348\n",
            "     16        \u001b[36m0.0069\u001b[0m  0.0350\n",
            "     17        \u001b[36m0.0066\u001b[0m  0.0308\n",
            "     18        \u001b[36m0.0060\u001b[0m  0.0314\n",
            "     19        \u001b[36m0.0058\u001b[0m  0.0289\n",
            "     20        \u001b[36m0.0058\u001b[0m  0.0320\n",
            "     21        \u001b[36m0.0057\u001b[0m  0.0308\n",
            "     22        \u001b[36m0.0055\u001b[0m  0.0339\n",
            "     23        \u001b[36m0.0055\u001b[0m  0.0342\n",
            "     24        \u001b[36m0.0053\u001b[0m  0.0358\n",
            "     25        \u001b[36m0.0052\u001b[0m  0.0343\n",
            "     26        0.0055  0.0327\n",
            "     27        \u001b[36m0.0048\u001b[0m  0.0339\n",
            "     28        \u001b[36m0.0048\u001b[0m  0.0331\n",
            "     29        \u001b[36m0.0046\u001b[0m  0.0345\n",
            "     30        0.0047  0.0335\n",
            "     31        \u001b[36m0.0046\u001b[0m  0.0348\n",
            "     32        0.0046  0.0357\n",
            "     33        \u001b[36m0.0044\u001b[0m  0.0311\n",
            "     34        0.0046  0.0300\n",
            "     35        \u001b[36m0.0043\u001b[0m  0.0315\n",
            "     36        0.0044  0.0298\n",
            "     37        \u001b[36m0.0041\u001b[0m  0.0374\n",
            "     38        0.0042  0.0248\n",
            "     39        \u001b[36m0.0040\u001b[0m  0.0256\n",
            "     40        \u001b[36m0.0040\u001b[0m  0.0258\n",
            "     41        0.0040  0.0260\n",
            "     42        0.0041  0.0240\n",
            "     43        \u001b[36m0.0039\u001b[0m  0.0251\n",
            "     44        \u001b[36m0.0038\u001b[0m  0.0248\n",
            "     45        0.0039  0.0244\n",
            "     46        \u001b[36m0.0037\u001b[0m  0.0245\n",
            "     47        0.0038  0.0245\n",
            "     48        0.0039  0.0242\n",
            "     49        \u001b[36m0.0036\u001b[0m  0.0244\n",
            "     50        0.0036  0.0253\n",
            "     51        \u001b[36m0.0034\u001b[0m  0.0243\n",
            "     52        0.0036  0.0239\n",
            "     53        0.0036  0.0242\n",
            "     54        0.0034  0.0254\n",
            "     55        0.0036  0.0242\n",
            "     56        0.0034  0.0247\n",
            "     57        \u001b[36m0.0033\u001b[0m  0.0243\n",
            "     58        0.0034  0.0257\n",
            "     59        0.0034  0.0248\n",
            "     60        0.0034  0.0279\n",
            "     61        0.0034  0.0242\n",
            "     62        \u001b[36m0.0032\u001b[0m  0.0246\n",
            "     63        0.0035  0.0254\n",
            "     64        0.0033  0.0246\n",
            "     65        0.0034  0.0242\n",
            "     66        0.0032  0.0248\n",
            "     67        0.0033  0.0245\n",
            "     68        0.0032  0.0275\n",
            "     69        0.0032  0.0242\n",
            "     70        0.0033  0.0250\n",
            "     71        0.0032  0.0243\n",
            "     72        \u001b[36m0.0030\u001b[0m  0.0242\n",
            "     73        0.0032  0.0240\n",
            "     74        0.0031  0.0239\n",
            "     75        0.0030  0.0238\n",
            "     76        0.0030  0.0241\n",
            "     77        0.0030  0.0353\n",
            "     78        0.0031  0.0261\n",
            "     79        0.0031  0.0240\n",
            "     80        \u001b[36m0.0029\u001b[0m  0.0245\n",
            "     81        0.0030  0.0240\n",
            "     82        0.0030  0.0238\n",
            "     83        0.0030  0.0240\n",
            "     84        0.0029  0.0243\n",
            "     85        0.0030  0.0237\n",
            "     86        0.0029  0.0242\n",
            "     87        0.0030  0.0239\n",
            "     88        0.0032  0.0245\n",
            "     89        0.0031  0.0239\n",
            "     90        \u001b[36m0.0029\u001b[0m  0.0244\n",
            "     91        0.0029  0.0263\n",
            "     92        0.0029  0.0251\n",
            "     93        0.0029  0.0240\n",
            "     94        \u001b[36m0.0027\u001b[0m  0.0238\n",
            "     95        0.0031  0.0242\n",
            "     96        0.0029  0.0239\n",
            "     97        0.0028  0.0243\n",
            "     98        \u001b[36m0.0027\u001b[0m  0.0245\n",
            "     99        0.0029  0.0243\n",
            "    100        0.0028  0.0242\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1108\u001b[0m  0.0380\n",
            "      2        \u001b[36m0.0509\u001b[0m  0.0295\n",
            "      3        \u001b[36m0.0325\u001b[0m  0.0291\n",
            "      4        \u001b[36m0.0230\u001b[0m  0.0293\n",
            "      5        \u001b[36m0.0171\u001b[0m  0.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0137\u001b[0m  0.0324\n",
            "      7        \u001b[36m0.0113\u001b[0m  0.0291\n",
            "      8        \u001b[36m0.0100\u001b[0m  0.0304\n",
            "      9        \u001b[36m0.0090\u001b[0m  0.0298\n",
            "     10        \u001b[36m0.0082\u001b[0m  0.0290\n",
            "     11        \u001b[36m0.0079\u001b[0m  0.0291\n",
            "     12        \u001b[36m0.0073\u001b[0m  0.0294\n",
            "     13        \u001b[36m0.0071\u001b[0m  0.0413\n",
            "     14        \u001b[36m0.0065\u001b[0m  0.0298\n",
            "     15        \u001b[36m0.0063\u001b[0m  0.0304\n",
            "     16        \u001b[36m0.0061\u001b[0m  0.0298\n",
            "     17        \u001b[36m0.0061\u001b[0m  0.0296\n",
            "     18        \u001b[36m0.0057\u001b[0m  0.0294\n",
            "     19        \u001b[36m0.0055\u001b[0m  0.0293\n",
            "     20        0.0056  0.0298\n",
            "     21        \u001b[36m0.0052\u001b[0m  0.0294\n",
            "     22        \u001b[36m0.0052\u001b[0m  0.0297\n",
            "     23        \u001b[36m0.0051\u001b[0m  0.0327\n",
            "     24        \u001b[36m0.0049\u001b[0m  0.0292\n",
            "     25        0.0050  0.0298\n",
            "     26        \u001b[36m0.0046\u001b[0m  0.0297\n",
            "     27        \u001b[36m0.0045\u001b[0m  0.0299\n",
            "     28        0.0048  0.0299\n",
            "     29        0.0047  0.0301\n",
            "     30        0.0046  0.0307\n",
            "     31        0.0046  0.0300\n",
            "     32        0.0045  0.0297\n",
            "     33        \u001b[36m0.0042\u001b[0m  0.0304\n",
            "     34        \u001b[36m0.0042\u001b[0m  0.0362\n",
            "     35        \u001b[36m0.0041\u001b[0m  0.0289\n",
            "     36        0.0045  0.0298\n",
            "     37        \u001b[36m0.0039\u001b[0m  0.0314\n",
            "     38        0.0042  0.0291\n",
            "     39        0.0041  0.0291\n",
            "     40        0.0041  0.0292\n",
            "     41        \u001b[36m0.0039\u001b[0m  0.0298\n",
            "     42        0.0039  0.0297\n",
            "     43        \u001b[36m0.0038\u001b[0m  0.0327\n",
            "     44        \u001b[36m0.0037\u001b[0m  0.0297\n",
            "     45        0.0037  0.0305\n",
            "     46        0.0040  0.0460\n",
            "     47        0.0037  0.0322\n",
            "     48        0.0038  0.0294\n",
            "     49        0.0041  0.0301\n",
            "     50        \u001b[36m0.0035\u001b[0m  0.0292\n",
            "     51        0.0036  0.0307\n",
            "     52        0.0037  0.0296\n",
            "     53        0.0036  0.0299\n",
            "     54        0.0036  0.0303\n",
            "     55        0.0036  0.0300\n",
            "     56        \u001b[36m0.0035\u001b[0m  0.0324\n",
            "     57        \u001b[36m0.0033\u001b[0m  0.0301\n",
            "     58        0.0035  0.0291\n",
            "     59        0.0034  0.0298\n",
            "     60        0.0034  0.0326\n",
            "     61        \u001b[36m0.0033\u001b[0m  0.0303\n",
            "     62        0.0033  0.0295\n",
            "     63        0.0033  0.0305\n",
            "     64        0.0034  0.0303\n",
            "     65        \u001b[36m0.0033\u001b[0m  0.0301\n",
            "     66        0.0033  0.0331\n",
            "     67        \u001b[36m0.0033\u001b[0m  0.0299\n",
            "     68        0.0033  0.0315\n",
            "     69        0.0034  0.0306\n",
            "     70        0.0034  0.0292\n",
            "     71        \u001b[36m0.0031\u001b[0m  0.0294\n",
            "     72        \u001b[36m0.0031\u001b[0m  0.0291\n",
            "     73        0.0033  0.0291\n",
            "     74        0.0031  0.0303\n",
            "     75        \u001b[36m0.0030\u001b[0m  0.0300\n",
            "     76        0.0032  0.0298\n",
            "     77        \u001b[36m0.0030\u001b[0m  0.0305\n",
            "     78        0.0030  0.0302\n",
            "     79        \u001b[36m0.0030\u001b[0m  0.0399\n",
            "     80        0.0032  0.0322\n",
            "     81        0.0031  0.0294\n",
            "     82        0.0031  0.0293\n",
            "     83        0.0030  0.0300\n",
            "     84        \u001b[36m0.0029\u001b[0m  0.0297\n",
            "     85        0.0031  0.0301\n",
            "     86        0.0030  0.0294\n",
            "     87        0.0029  0.0319\n",
            "     88        0.0029  0.0293\n",
            "     89        0.0031  0.0297\n",
            "     90        \u001b[36m0.0029\u001b[0m  0.0292\n",
            "     91        \u001b[36m0.0029\u001b[0m  0.0290\n",
            "     92        0.0029  0.0292\n",
            "     93        \u001b[36m0.0028\u001b[0m  0.0302\n",
            "     94        0.0029  0.0319\n",
            "     95        0.0028  0.0298\n",
            "     96        \u001b[36m0.0027\u001b[0m  0.0295\n",
            "     97        0.0027  0.0299\n",
            "     98        \u001b[36m0.0027\u001b[0m  0.0309\n",
            "     99        0.0029  0.0312\n",
            "    100        \u001b[36m0.0027\u001b[0m  0.0300\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.1085\u001b[0m  0.0376\n",
            "      2        \u001b[36m0.0464\u001b[0m  0.0314\n",
            "      3        \u001b[36m0.0311\u001b[0m  0.0308\n",
            "      4        \u001b[36m0.0222\u001b[0m  0.0307\n",
            "      5        \u001b[36m0.0180\u001b[0m  0.0308\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.0145\u001b[0m  0.0326\n",
            "      7        \u001b[36m0.0122\u001b[0m  0.0314\n",
            "      8        \u001b[36m0.0104\u001b[0m  0.0320\n",
            "      9        \u001b[36m0.0092\u001b[0m  0.0327\n",
            "     10        \u001b[36m0.0089\u001b[0m  0.0302\n",
            "     11        \u001b[36m0.0078\u001b[0m  0.0413\n",
            "     12        \u001b[36m0.0072\u001b[0m  0.0311\n",
            "     13        \u001b[36m0.0070\u001b[0m  0.0310\n",
            "     14        \u001b[36m0.0068\u001b[0m  0.0306\n",
            "     15        \u001b[36m0.0065\u001b[0m  0.0308\n",
            "     16        \u001b[36m0.0061\u001b[0m  0.0311\n",
            "     17        \u001b[36m0.0059\u001b[0m  0.0313\n",
            "     18        \u001b[36m0.0057\u001b[0m  0.0300\n",
            "     19        \u001b[36m0.0054\u001b[0m  0.0302\n",
            "     20        0.0055  0.0337\n",
            "     21        \u001b[36m0.0052\u001b[0m  0.0300\n",
            "     22        0.0053  0.0303\n",
            "     23        \u001b[36m0.0050\u001b[0m  0.0312\n",
            "     24        0.0052  0.0299\n",
            "     25        \u001b[36m0.0048\u001b[0m  0.0333\n",
            "     26        \u001b[36m0.0047\u001b[0m  0.0305\n",
            "     27        \u001b[36m0.0046\u001b[0m  0.0301\n",
            "     28        0.0046  0.0310\n",
            "     29        0.0048  0.0304\n",
            "     30        \u001b[36m0.0044\u001b[0m  0.0319\n",
            "     31        \u001b[36m0.0043\u001b[0m  0.0318\n",
            "     32        \u001b[36m0.0043\u001b[0m  0.0305\n",
            "     33        \u001b[36m0.0041\u001b[0m  0.0306\n",
            "     34        0.0042  0.0297\n",
            "     35        \u001b[36m0.0041\u001b[0m  0.0296\n",
            "     36        0.0041  0.0298\n",
            "     37        0.0041  0.0301\n",
            "     38        \u001b[36m0.0040\u001b[0m  0.0296\n",
            "     39        0.0041  0.0310\n",
            "     40        \u001b[36m0.0039\u001b[0m  0.0304\n",
            "     41        \u001b[36m0.0039\u001b[0m  0.0298\n",
            "     42        \u001b[36m0.0039\u001b[0m  0.0323\n",
            "     43        \u001b[36m0.0038\u001b[0m  0.0397\n",
            "     44        0.0038  0.0312\n",
            "     45        \u001b[36m0.0037\u001b[0m  0.0299\n",
            "     46        0.0039  0.0299\n",
            "     47        0.0037  0.0303\n",
            "     48        0.0038  0.0301\n",
            "     49        \u001b[36m0.0035\u001b[0m  0.0305\n",
            "     50        0.0036  0.0307\n",
            "     51        0.0035  0.0302\n",
            "     52        0.0035  0.0320\n",
            "     53        0.0035  0.0301\n",
            "     54        \u001b[36m0.0034\u001b[0m  0.0301\n",
            "     55        0.0035  0.0311\n",
            "     56        0.0035  0.0302\n",
            "     57        \u001b[36m0.0033\u001b[0m  0.0311\n",
            "     58        \u001b[36m0.0032\u001b[0m  0.0373\n",
            "     59        0.0033  0.0307\n",
            "     60        0.0035  0.0302\n",
            "     61        0.0033  0.0303\n",
            "     62        0.0033  0.0306\n",
            "     63        0.0036  0.0315\n",
            "     64        \u001b[36m0.0031\u001b[0m  0.0302\n",
            "     65        0.0033  0.0312\n",
            "     66        0.0035  0.0311\n",
            "     67        0.0032  0.0308\n",
            "     68        0.0033  0.0304\n",
            "     69        0.0033  0.0384\n",
            "     70        0.0032  0.0310\n",
            "     71        0.0031  0.0312\n",
            "     72        \u001b[36m0.0031\u001b[0m  0.0306\n",
            "     73        \u001b[36m0.0029\u001b[0m  0.0325\n",
            "     74        0.0030  0.0299\n",
            "     75        0.0029  0.0399\n",
            "     76        0.0031  0.0312\n",
            "     77        0.0031  0.0302\n",
            "     78        0.0030  0.0300\n",
            "     79        0.0030  0.0350\n",
            "     80        0.0030  0.0300\n",
            "     81        \u001b[36m0.0029\u001b[0m  0.0306\n",
            "     82        0.0030  0.0304\n",
            "     83        \u001b[36m0.0029\u001b[0m  0.0304\n",
            "     84        0.0029  0.0322\n",
            "     85        0.0029  0.0303\n",
            "     86        0.0030  0.0320\n",
            "     87        \u001b[36m0.0029\u001b[0m  0.0306\n",
            "     88        \u001b[36m0.0028\u001b[0m  0.0299\n",
            "     89        \u001b[36m0.0027\u001b[0m  0.0302\n",
            "     90        0.0030  0.0338\n",
            "     91        0.0029  0.0303\n",
            "     92        0.0029  0.0303\n",
            "     93        0.0029  0.0308\n",
            "     94        0.0028  0.0314\n",
            "     95        0.0028  0.0306\n",
            "     96        0.0028  0.0318\n",
            "     97        0.0028  0.0305\n",
            "     98        \u001b[36m0.0026\u001b[0m  0.0314\n",
            "     99        0.0029  0.0304\n",
            "    100        0.0028  0.0305\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.0891\u001b[0m  0.0408\n",
            "      2        \u001b[36m0.0374\u001b[0m  0.0349\n",
            "      3        \u001b[36m0.0237\u001b[0m  0.0353\n",
            "      4        \u001b[36m0.0169\u001b[0m  0.0354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.0129\u001b[0m  0.0411\n",
            "      6        \u001b[36m0.0106\u001b[0m  0.0447\n",
            "      7        \u001b[36m0.0092\u001b[0m  0.0352\n",
            "      8        \u001b[36m0.0081\u001b[0m  0.0351\n",
            "      9        \u001b[36m0.0073\u001b[0m  0.0353\n",
            "     10        \u001b[36m0.0068\u001b[0m  0.0353\n",
            "     11        \u001b[36m0.0064\u001b[0m  0.0359\n",
            "     12        \u001b[36m0.0060\u001b[0m  0.0410\n",
            "     13        \u001b[36m0.0057\u001b[0m  0.0389\n",
            "     14        \u001b[36m0.0054\u001b[0m  0.0357\n",
            "     15        0.0056  0.0357\n",
            "     16        \u001b[36m0.0050\u001b[0m  0.0363\n",
            "     17        0.0050  0.0359\n",
            "     18        \u001b[36m0.0047\u001b[0m  0.0360\n",
            "     19        0.0047  0.0372\n",
            "     20        0.0047  0.0366\n",
            "     21        0.0047  0.0365\n",
            "     22        \u001b[36m0.0044\u001b[0m  0.0360\n",
            "     23        \u001b[36m0.0043\u001b[0m  0.0368\n",
            "     24        0.0043  0.0358\n",
            "     25        \u001b[36m0.0042\u001b[0m  0.0359\n",
            "     26        \u001b[36m0.0041\u001b[0m  0.0366\n",
            "     27        \u001b[36m0.0040\u001b[0m  0.0350\n",
            "     28        \u001b[36m0.0039\u001b[0m  0.0360\n",
            "     29        0.0039  0.0352\n",
            "     30        0.0039  0.0381\n",
            "     31        \u001b[36m0.0038\u001b[0m  0.0426\n",
            "     32        0.0039  0.0359\n",
            "     33        \u001b[36m0.0036\u001b[0m  0.0473\n",
            "     34        0.0038  0.0379\n",
            "     35        0.0037  0.0359\n",
            "     36        0.0036  0.0355\n",
            "     37        0.0037  0.0361\n",
            "     38        0.0038  0.0354\n",
            "     39        0.0037  0.0354\n",
            "     40        \u001b[36m0.0036\u001b[0m  0.0402\n",
            "     41        \u001b[36m0.0035\u001b[0m  0.0352\n",
            "     42        0.0035  0.0356\n",
            "     43        \u001b[36m0.0033\u001b[0m  0.0357\n",
            "     44        0.0033  0.0352\n",
            "     45        \u001b[36m0.0033\u001b[0m  0.0404\n",
            "     46        \u001b[36m0.0032\u001b[0m  0.0360\n",
            "     47        0.0033  0.0384\n",
            "     48        \u001b[36m0.0032\u001b[0m  0.0383\n",
            "     49        0.0032  0.0359\n",
            "     50        \u001b[36m0.0031\u001b[0m  0.0357\n",
            "     51        0.0031  0.0407\n",
            "     52        0.0033  0.0513\n",
            "     53        0.0032  0.0509\n",
            "     54        0.0032  0.0463\n",
            "     55        0.0032  0.0431\n",
            "     56        \u001b[36m0.0030\u001b[0m  0.0513\n",
            "     57        \u001b[36m0.0030\u001b[0m  0.0485\n",
            "     58        0.0030  0.0562\n",
            "     59        0.0030  0.0446\n",
            "     60        \u001b[36m0.0029\u001b[0m  0.0459\n",
            "     61        0.0030  0.0456\n",
            "     62        0.0030  0.0448\n",
            "     63        0.0030  0.0446\n",
            "     64        \u001b[36m0.0028\u001b[0m  0.0492\n",
            "     65        0.0029  0.0435\n",
            "     66        0.0030  0.0437\n",
            "     67        0.0030  0.0443\n",
            "     68        0.0030  0.0451\n",
            "     69        0.0029  0.0477\n",
            "     70        \u001b[36m0.0028\u001b[0m  0.0482\n",
            "     71        0.0029  0.0425\n",
            "     72        \u001b[36m0.0027\u001b[0m  0.0433\n",
            "     73        \u001b[36m0.0027\u001b[0m  0.0464\n",
            "     74        0.0028  0.0439\n",
            "     75        0.0027  0.0443\n",
            "     76        \u001b[36m0.0027\u001b[0m  0.0442\n",
            "     77        0.0028  0.0433\n",
            "     78        0.0028  0.0432\n",
            "     79        0.0027  0.0432\n",
            "     80        \u001b[36m0.0027\u001b[0m  0.0528\n",
            "     81        0.0027  0.0542\n",
            "     82        0.0028  0.0534\n",
            "     83        \u001b[36m0.0026\u001b[0m  0.0517\n",
            "     84        \u001b[36m0.0026\u001b[0m  0.0491\n",
            "     85        0.0026  0.0465\n",
            "     86        0.0029  0.0468\n",
            "     87        0.0026  0.0553\n",
            "     88        0.0026  0.0778\n",
            "     89        0.0027  0.1074\n",
            "     90        \u001b[36m0.0024\u001b[0m  0.1680\n",
            "     91        0.0027  0.2033\n",
            "     92        0.0026  0.1330\n",
            "     93        0.0026  0.0372\n",
            "     94        0.0025  0.0380\n",
            "     95        0.0026  0.0369\n",
            "     96        0.0026  0.0370\n",
            "     97        0.0026  0.0365\n",
            "     98        0.0025  0.0385\n",
            "     99        0.0026  0.0369\n",
            "    100        0.0025  0.0401\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.0755\u001b[0m  0.0493\n",
            "      2        \u001b[36m0.0297\u001b[0m  0.0421\n",
            "      3        \u001b[36m0.0186\u001b[0m  0.0417\n",
            "      4        \u001b[36m0.0138\u001b[0m  0.0409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m0.0110\u001b[0m  0.0448\n",
            "      6        \u001b[36m0.0093\u001b[0m  0.0441\n",
            "      7        \u001b[36m0.0080\u001b[0m  0.0413\n",
            "      8        \u001b[36m0.0073\u001b[0m  0.0415\n",
            "      9        \u001b[36m0.0070\u001b[0m  0.0413\n",
            "     10        \u001b[36m0.0064\u001b[0m  0.0406\n",
            "     11        \u001b[36m0.0061\u001b[0m  0.0421\n",
            "     12        \u001b[36m0.0059\u001b[0m  0.0417\n",
            "     13        \u001b[36m0.0055\u001b[0m  0.0408\n",
            "     14        \u001b[36m0.0054\u001b[0m  0.0410\n",
            "     15        \u001b[36m0.0052\u001b[0m  0.0482\n",
            "     16        \u001b[36m0.0048\u001b[0m  0.0460\n",
            "     17        0.0049  0.0446\n",
            "     18        0.0048  0.0408\n",
            "     19        \u001b[36m0.0046\u001b[0m  0.0414\n",
            "     20        \u001b[36m0.0045\u001b[0m  0.0413\n",
            "     21        \u001b[36m0.0044\u001b[0m  0.0415\n",
            "     22        0.0045  0.0409\n",
            "     23        \u001b[36m0.0044\u001b[0m  0.0424\n",
            "     24        \u001b[36m0.0042\u001b[0m  0.0421\n",
            "     25        \u001b[36m0.0041\u001b[0m  0.0419\n",
            "     26        \u001b[36m0.0040\u001b[0m  0.0409\n",
            "     27        0.0041  0.0410\n",
            "     28        0.0040  0.0420\n",
            "     29        \u001b[36m0.0039\u001b[0m  0.0426\n",
            "     30        0.0040  0.0405\n",
            "     31        \u001b[36m0.0039\u001b[0m  0.0407\n",
            "     32        \u001b[36m0.0036\u001b[0m  0.0410\n",
            "     33        0.0039  0.0403\n",
            "     34        0.0038  0.0409\n",
            "     35        0.0037  0.0444\n",
            "     36        \u001b[36m0.0035\u001b[0m  0.0428\n",
            "     37        0.0036  0.0406\n",
            "     38        0.0035  0.0410\n",
            "     39        0.0035  0.0411\n",
            "     40        \u001b[36m0.0034\u001b[0m  0.0524\n",
            "     41        0.0035  0.0455\n",
            "     42        0.0034  0.0403\n",
            "     43        0.0034  0.0403\n",
            "     44        0.0034  0.0406\n",
            "     45        0.0035  0.0418\n",
            "     46        \u001b[36m0.0033\u001b[0m  0.0414\n",
            "     47        0.0033  0.0435\n",
            "     48        \u001b[36m0.0033\u001b[0m  0.0412\n",
            "     49        \u001b[36m0.0031\u001b[0m  0.0411\n",
            "     50        0.0033  0.0413\n",
            "     51        0.0032  0.0412\n",
            "     52        \u001b[36m0.0031\u001b[0m  0.0416\n",
            "     53        0.0032  0.0421\n",
            "     54        \u001b[36m0.0030\u001b[0m  0.0406\n",
            "     55        0.0030  0.0427\n",
            "     56        0.0031  0.0408\n",
            "     57        \u001b[36m0.0029\u001b[0m  0.0414\n",
            "     58        0.0031  0.0409\n",
            "     59        0.0031  0.0422\n",
            "     60        0.0030  0.0414\n",
            "     61        0.0029  0.0412\n",
            "     62        0.0030  0.0411\n",
            "     63        0.0029  0.0432\n",
            "     64        \u001b[36m0.0028\u001b[0m  0.0526\n",
            "     65        0.0029  0.0441\n",
            "     66        0.0030  0.0404\n",
            "     67        \u001b[36m0.0027\u001b[0m  0.0410\n",
            "     68        0.0028  0.0410\n",
            "     69        0.0029  0.0413\n",
            "     70        0.0029  0.0405\n",
            "     71        0.0030  0.0427\n",
            "     72        0.0029  0.0403\n",
            "     73        0.0031  0.0401\n",
            "     74        0.0028  0.0434\n",
            "     75        \u001b[36m0.0027\u001b[0m  0.0419\n",
            "     76        0.0028  0.0412\n",
            "     77        0.0028  0.0415\n",
            "     78        0.0028  0.0405\n",
            "     79        0.0027  0.0403\n",
            "     80        0.0027  0.0405\n",
            "     81        0.0027  0.0412\n",
            "     82        \u001b[36m0.0026\u001b[0m  0.0411\n",
            "     83        \u001b[36m0.0026\u001b[0m  0.0470\n",
            "     84        0.0027  0.0423\n",
            "     85        \u001b[36m0.0026\u001b[0m  0.0410\n",
            "     86        \u001b[36m0.0025\u001b[0m  0.0414\n",
            "     87        0.0027  0.0413\n",
            "     88        0.0026  0.0525\n",
            "     89        0.0026  0.0433\n",
            "     90        0.0026  0.0421\n",
            "     91        0.0026  0.0414\n",
            "     92        0.0025  0.0427\n",
            "     93        0.0027  0.0407\n",
            "     94        0.0026  0.0504\n",
            "     95        0.0026  0.0416\n",
            "     96        0.0026  0.0412\n",
            "     97        0.0026  0.0405\n",
            "     98        0.0026  0.0495\n",
            "     99        \u001b[36m0.0025\u001b[0m  0.0541\n",
            "    100        \u001b[36m0.0025\u001b[0m  0.0403\n",
            "Re-initializing module because the following parameters were re-set: module__filters, module__kernel_size, module__rnn_type, module__rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "Re-initializing module because the following parameters were re-set: filters, kernel_size, n_features, rnn_type, rnn_units.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m0.0935\u001b[0m  0.0648\n",
            "      2        \u001b[36m0.0366\u001b[0m  0.0459\n",
            "      3        \u001b[36m0.0227\u001b[0m  0.0459\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      4        \u001b[36m0.0156\u001b[0m  0.0483\n",
            "      5        \u001b[36m0.0123\u001b[0m  0.0470\n",
            "      6        \u001b[36m0.0105\u001b[0m  0.0480\n",
            "      7        \u001b[36m0.0093\u001b[0m  0.0554\n",
            "      8        \u001b[36m0.0083\u001b[0m  0.0469\n",
            "      9        \u001b[36m0.0076\u001b[0m  0.0622\n",
            "     10        \u001b[36m0.0072\u001b[0m  0.0462\n",
            "     11        \u001b[36m0.0067\u001b[0m  0.0467\n",
            "     12        \u001b[36m0.0064\u001b[0m  0.0470\n",
            "     13        \u001b[36m0.0062\u001b[0m  0.0463\n",
            "     14        \u001b[36m0.0060\u001b[0m  0.0477\n",
            "     15        \u001b[36m0.0057\u001b[0m  0.0459\n",
            "     16        \u001b[36m0.0056\u001b[0m  0.0587\n",
            "     17        \u001b[36m0.0055\u001b[0m  0.0478\n",
            "     18        \u001b[36m0.0053\u001b[0m  0.0481\n",
            "     19        0.0054  0.0471\n",
            "     20        \u001b[36m0.0053\u001b[0m  0.0470\n",
            "     21        \u001b[36m0.0051\u001b[0m  0.0472\n",
            "     22        0.0051  0.0469\n",
            "     23        \u001b[36m0.0048\u001b[0m  0.0464\n",
            "     24        \u001b[36m0.0046\u001b[0m  0.0475\n",
            "     25        \u001b[36m0.0045\u001b[0m  0.0464\n",
            "     26        0.0045  0.0462\n",
            "     27        0.0045  0.0469\n",
            "     28        \u001b[36m0.0043\u001b[0m  0.0474\n",
            "     29        \u001b[36m0.0043\u001b[0m  0.0470\n",
            "     30        0.0043  0.0589\n",
            "     31        \u001b[36m0.0041\u001b[0m  0.0462\n",
            "     32        0.0041  0.0462\n",
            "     33        \u001b[36m0.0041\u001b[0m  0.0460\n",
            "     34        \u001b[36m0.0040\u001b[0m  0.0476\n",
            "     35        \u001b[36m0.0039\u001b[0m  0.0547\n",
            "     36        0.0040  0.0465\n",
            "     37        0.0041  0.0457\n",
            "     38        \u001b[36m0.0039\u001b[0m  0.0478\n",
            "     39        \u001b[36m0.0039\u001b[0m  0.0465\n",
            "     40        0.0039  0.0456\n",
            "     41        \u001b[36m0.0038\u001b[0m  0.0550\n",
            "     42        \u001b[36m0.0037\u001b[0m  0.0492\n",
            "     43        \u001b[36m0.0036\u001b[0m  0.0461\n",
            "     44        0.0037  0.0463\n",
            "     45        0.0038  0.0462\n",
            "     46        0.0037  0.0479\n",
            "     47        0.0037  0.0524\n",
            "     48        0.0037  0.0604\n",
            "     49        \u001b[36m0.0035\u001b[0m  0.0521\n",
            "     50        0.0036  0.0556\n",
            "     51        \u001b[36m0.0034\u001b[0m  0.0496\n",
            "     52        \u001b[36m0.0033\u001b[0m  0.0464\n",
            "     53        0.0035  0.0471\n",
            "     54        0.0034  0.0479\n",
            "     55        0.0034  0.0466\n",
            "     56        \u001b[36m0.0033\u001b[0m  0.0468\n",
            "     57        0.0034  0.0483\n",
            "     58        0.0033  0.0473\n",
            "     59        0.0034  0.0575\n",
            "     60        0.0033  0.0537\n",
            "     61        0.0033  0.0459\n",
            "     62        \u001b[36m0.0032\u001b[0m  0.0475\n",
            "     63        0.0032  0.0466\n",
            "     64        \u001b[36m0.0031\u001b[0m  0.0470\n",
            "     65        0.0032  0.0467\n",
            "     66        0.0033  0.0479\n",
            "     67        0.0033  0.0463\n",
            "     68        0.0033  0.0525\n",
            "     69        0.0032  0.0465\n",
            "     70        0.0032  0.0468\n",
            "     71        0.0032  0.0573\n",
            "     72        0.0032  0.0459\n",
            "     73        0.0032  0.0476\n",
            "     74        0.0032  0.0481\n",
            "     75        \u001b[36m0.0029\u001b[0m  0.0479\n",
            "     76        0.0030  0.0490\n",
            "     77        0.0030  0.0531\n",
            "     78        0.0029  0.0547\n",
            "     79        0.0030  0.0500\n",
            "     80        \u001b[36m0.0029\u001b[0m  0.0468\n",
            "     81        0.0030  0.0472\n",
            "     82        0.0030  0.0472\n",
            "     83        0.0029  0.0471\n",
            "     84        0.0029  0.0488\n",
            "     85        0.0029  0.0485\n",
            "     86        0.0029  0.0469\n",
            "     87        \u001b[36m0.0028\u001b[0m  0.0469\n",
            "     88        0.0029  0.0488\n",
            "     89        \u001b[36m0.0028\u001b[0m  0.0471\n",
            "     90        0.0030  0.0503\n",
            "     91        0.0030  0.0462\n",
            "     92        0.0030  0.0573\n",
            "     93        0.0030  0.0465\n",
            "     94        0.0029  0.0480\n",
            "     95        0.0029  0.0471\n",
            "     96        0.0030  0.0460\n",
            "     97        0.0029  0.0482\n",
            "     98        0.0028  0.0473\n",
            "     99        0.0028  0.0474\n",
            "    100        \u001b[36m0.0028\u001b[0m  0.0475\n",
            "MAE médio (PCA): 0.03152331764959513\n",
            "MAE médio (CNN-AE): 0.07706428319215775\n",
            "MAE médio (TCN-AE): 0.07632026933133602\n",
            "MAE médio (CNN-RNN-CNN): 0.04969687778502703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "def run_10fold_pipeline(pipe, best_params, threshold_q=THRESHOLD_Q):\n",
        "    tscv10 = TimeSeriesSplit(n_splits=FOLDS)\n",
        "    fold_metrics = []\n",
        "    for k, (tr, va) in enumerate(tscv10.split(X_full)):\n",
        "        Xtr, Xva = X_full[tr], X_full[va]\n",
        "        # fit até window no treino\n",
        "        pipe.set_params(**best_params)\n",
        "        Xw_tr = pipe[:-1].fit_transform(Xtr)\n",
        "        model = pipe.named_steps[\"model\"]\n",
        "        model.fit(Xw_tr, Xw_tr)  # AE\n",
        "        # calibrar limiar em erros do treino\n",
        "        yhat_tr = model.predict(Xw_tr)\n",
        "        errs_tr = np.mean(np.abs(yhat_tr - Xw_tr), axis=(1,2))\n",
        "        thr = np.quantile(errs_tr, threshold_q)\n",
        "        # avaliar no val\n",
        "        Xw_va = pipe[:-1].transform(Xva)\n",
        "        yhat_va = model.predict(Xw_va)\n",
        "        errs_va = np.mean(np.abs(yhat_va - Xw_va), axis=(1,2))\n",
        "        fold_metrics.append({\"val_mae\": float(np.mean(errs_va)), \"thr\": float(thr), \"errs_va\": errs_va})\n",
        "    return fold_metrics\n",
        "\n",
        "def run_10fold_pca(n_components=0.95):\n",
        "    tscv10 = TimeSeriesSplit(n_splits=FOLDS)\n",
        "    out = []\n",
        "    for k, (tr, va) in enumerate(tscv10.split(X_full)):\n",
        "        Xtr, Xva = X_full[tr], X_full[va]\n",
        "        Xw_tr = pca_pipeline.fit_transform(Xtr)  # (N,T,F)\n",
        "        Ntr,T,F = Xw_tr.shape\n",
        "        pca = PCA(n_components=n_components, svd_solver='full') if isinstance(n_components, float) else PCA(n_components=n_components)\n",
        "        Xtr_flat = Xw_tr.reshape(Ntr, T*F)\n",
        "        pca.fit(Xtr_flat)\n",
        "        # treino errs\n",
        "        Xr_tr = pca.inverse_transform(pca.transform(Xtr_flat)).reshape(Ntr,T,F)\n",
        "        errs_tr = np.mean(np.abs(Xr_tr - Xw_tr), axis=(1,2))\n",
        "        thr = np.quantile(errs_tr, THRESHOLD_Q)\n",
        "        # val\n",
        "        Xw_va = pca_pipeline.transform(Xva)\n",
        "        Nva = Xw_va.shape[0]\n",
        "        Xr_va = pca.inverse_transform(pca.transform(Xw_va.reshape(Nva,T*F))).reshape(Nva,T,F)\n",
        "        errs_va = np.mean(np.abs(Xr_va - Xw_va), axis=(1,2))\n",
        "        out.append({\"val_mae\": float(np.mean(errs_va)), \"thr\": float(thr), \"errs_va\": errs_va})\n",
        "    return out\n",
        "\n",
        "metrics_pca = run_10fold_pca(n_components=best_pca[\"n_components\"]) if 'best_pca' in globals() else run_10fold_pca()\n",
        "metrics_cnn = run_10fold_pipeline(cnn_ae_pipeline, best_cnn_params)\n",
        "metrics_tcn = run_10fold_pipeline(tcn_ae_pipeline, best_tcn_params)\n",
        "metrics_crnn = run_10fold_pipeline(crnn_ae_pipeline, best_crnn_params)\n",
        "\n",
        "print(\"MAE médio (PCA):\", np.mean([m['val_mae'] for m in metrics_pca]))\n",
        "print(\"MAE médio (CNN-AE):\", np.mean([m['val_mae'] for m in metrics_cnn]))\n",
        "print(\"MAE médio (TCN-AE):\", np.mean([m['val_mae'] for m in metrics_tcn]))\n",
        "print(\"MAE médio (CNN-RNN-CNN):\", np.mean([m['val_mae'] for m in metrics_crnn]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9cc940a",
      "metadata": {
        "id": "d9cc940a"
      },
      "source": [
        "## Célula 6 — Métricas dos resultados (acc, f1, auc, recall, precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c59ee698",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c59ee698",
        "outputId": "7e4df02f-abb1-483a-cdb2-725a59b0ec12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PCA: {'acc': 0.09186046511627907, 'f1': 0.03626753058125607, 'auc': 0.5247158761028443, 'recall': 0.019905072344171208, 'precision': 0.4818181818181818}\n",
            "CNN-AE: {'acc': 0.5593023255813953, 'f1': 0.6547082296367865, 'auc': 0.4119974240797637, 'recall': 0.5749441579041227, 'precision': 0.8724739733094948}\n",
            "TCN-AE: {'acc': 0.4244186046511628, 'f1': 0.5078524814950486, 'auc': 0.48318359361024754, 'recall': 0.4271064693691704, 'precision': 0.8957216260280252}\n",
            "CNN-RNN-CNN: {'acc': 0.6244186046511628, 'f1': 0.7198819943138873, 'auc': 0.5116477786790166, 'recall': 0.6424802707335161, 'precision': 0.9206335986474945}\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import numpy as np\n",
        "\n",
        "def window_labels(y, T=WINDOW_SIZE, stride=STRIDE):\n",
        "    if y is None:\n",
        "        return None\n",
        "    return np.array([y[i:i+T].max() for i in range(0, len(y)-T+1, stride)], dtype=int)\n",
        "\n",
        "def metrics_binary_from_errors(errs, thr, y_win=None):\n",
        "    y_pred = (errs > thr).astype(int)\n",
        "    out = {}\n",
        "    if y_win is None:\n",
        "        out.update({\"acc\": np.nan, \"f1\": np.nan, \"auc\": np.nan, \"recall\": np.nan, \"precision\": np.nan})\n",
        "    else:\n",
        "        out[\"acc\"] = metrics.accuracy_score(y_win, y_pred)\n",
        "        out[\"f1\"] = metrics.f1_score(y_win, y_pred, zero_division=0)\n",
        "        try:\n",
        "            out[\"auc\"] = metrics.roc_auc_score(y_win, errs)  # usa score contínuo\n",
        "        except Exception:\n",
        "            out[\"auc\"] = np.nan\n",
        "        out[\"recall\"] = metrics.recall_score(y_win, y_pred, zero_division=0)\n",
        "        out[\"precision\"] = metrics.precision_score(y_win, y_pred, zero_division=0)\n",
        "    return out\n",
        "\n",
        "def metrics_multiclass_from_predictions(y_true, y_pred, y_proba=None):\n",
        "    # macro por padrão (equilibra classes)\n",
        "    out = {\n",
        "        \"acc\": metrics.accuracy_score(y_true, y_pred),\n",
        "        \"f1\": metrics.f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"recall\": metrics.recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"precision\": metrics.precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "    }\n",
        "    if y_proba is not None:\n",
        "        try:\n",
        "            out[\"auc\"] = metrics.roc_auc_score(y_true, y_proba, multi_class=\"ovr\")\n",
        "        except Exception:\n",
        "            out[\"auc\"] = np.nan\n",
        "    else:\n",
        "        out[\"auc\"] = np.nan\n",
        "    return out\n",
        "\n",
        "def _get_fold_label_mask_and_labels():\n",
        "    \"\"\"Pré-calcula centros de janela e labels por janela no dataset inteiro.\"\"\"\n",
        "    if not (HAS_LABELS and (y_full is not None)):\n",
        "        return None, None, None\n",
        "    idxs = list(range(0, len(X_full)-WINDOW_SIZE+1, STRIDE))\n",
        "    centers = np.array([i + WINDOW_SIZE//2 for i in idxs])\n",
        "\n",
        "    # Escolhe o alvo de labels para métricas:\n",
        "    # 1) multiclass + classificador disponível -> usar multiclass\n",
        "    # 2) caso contrário -> binário (one-vs-all) se multiclass, ou binário original\n",
        "    if multiclass and not USE_ONE_VS_ALL:\n",
        "        # manter multiclass; SE não houver classificador por fold, faremos fallback binário abaixo\n",
        "        y_target = y_full\n",
        "    else:\n",
        "        y_target = (y_full != 0).astype(int) if multiclass else y_full\n",
        "\n",
        "    yw_all = window_labels(y_target, WINDOW_SIZE, STRIDE)\n",
        "    return centers, yw_all, y_target\n",
        "\n",
        "def agg_metrics_generic(fold_results):\n",
        "    \"\"\"\n",
        "    Aceita resultados por fold de dois tipos:\n",
        "      - AE (contém 'errs_va' e 'thr' por fold) -> métricas binárias\n",
        "      - Classificador (contém 'y_pred' e opcional 'y_proba') -> métricas multiclass\n",
        "    Se multiclass e NÃO houver classificador -> fallback para binário (one-vs-all).\n",
        "    \"\"\"\n",
        "    centers, yw_all, y_target = _get_fold_label_mask_and_labels()\n",
        "    if yw_all is None:\n",
        "        return {k: np.nan for k in [\"acc\",\"f1\",\"auc\",\"recall\",\"precision\"]}\n",
        "\n",
        "    tscv10 = TimeSeriesSplit(n_splits=FOLDS)\n",
        "    fold_mets = []\n",
        "\n",
        "    for (tr, va), fr in zip(tscv10.split(X_full), fold_results):\n",
        "        # Detecta tipo do resultado do fold:\n",
        "        is_classifier = (\"y_pred\" in fr) or (\"y_proba\" in fr)\n",
        "\n",
        "        # Seleciona as janelas do trecho de validação (aproxima pelo centro)\n",
        "        mask = (centers >= va[0]) & (centers <= va[-1])\n",
        "\n",
        "        if is_classifier:\n",
        "            # Expectativa: fr[\"y_pred\"] (N_val,), fr[\"y_proba\"] (N_val, C) opcional\n",
        "            yv_true = window_labels(y_target, WINDOW_SIZE, STRIDE)[mask]\n",
        "            yv_pred = fr[\"y_pred\"][:len(yv_true)]\n",
        "            yv_prob = fr.get(\"y_proba\", None)\n",
        "            if yv_prob is not None:\n",
        "                yv_prob = yv_prob[:len(yv_true)]\n",
        "            # Métricas multiclass\n",
        "            m = metrics_multiclass_from_predictions(yv_true, yv_pred, yv_prob)\n",
        "            fold_mets.append(m)\n",
        "        else:\n",
        "            # AE: usar erros + thr -> métricas BINÁRIAS\n",
        "            # Se o target original for multiclass e não queremos binário, caímos em fallback one-vs-all\n",
        "            if multiclass and not USE_ONE_VS_ALL:\n",
        "                y_target_fallback = (y_full != 0).astype(int)\n",
        "                yw_all_bin = window_labels(y_target_fallback, WINDOW_SIZE, STRIDE)\n",
        "                yv_true = yw_all_bin[mask][:len(fr[\"errs_va\"])]\n",
        "            else:\n",
        "                yv_true = yw_all[mask][:len(fr[\"errs_va\"])]\n",
        "            errs_va = fr[\"errs_va\"][:len(yv_true)]\n",
        "            m = metrics_binary_from_errors(errs_va, fr[\"thr\"], yv_true)\n",
        "            fold_mets.append(m)\n",
        "\n",
        "    # média dos folds\n",
        "    keys = [\"acc\",\"f1\",\"auc\",\"recall\",\"precision\"]\n",
        "    return {k: float(np.nanmean([d.get(k, np.nan) for d in fold_mets])) for k in keys}\n",
        "\n",
        "# ---- Chamada para os 4 modelos já treinados (metrics_* vêm da Célula 5) ----\n",
        "res_pca  = agg_metrics_generic(metrics_pca)\n",
        "res_cnn  = agg_metrics_generic(metrics_cnn)\n",
        "res_tcn  = agg_metrics_generic(metrics_tcn)\n",
        "res_crnn = agg_metrics_generic(metrics_crnn)\n",
        "\n",
        "print(\"PCA:\", res_pca)\n",
        "print(\"CNN-AE:\", res_cnn)\n",
        "print(\"TCN-AE:\", res_tcn)\n",
        "print(\"CNN-RNN-CNN:\", res_crnn)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yykT5YcC2wx"
      },
      "id": "4yykT5YcC2wx",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f45a8a78",
        "outputId": "b6f38cfa-0aed-4be0-ba60-30875372f6fa"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a table with the mean MAE for each model\n",
        "mae_data = {\n",
        "    'Model': ['PCA', 'CNN-AE', 'TCN-AE', 'CNN-RNN-CNN'],\n",
        "    'Mean MAE': [\n",
        "        np.mean([m['val_mae'] for m in metrics_pca]),\n",
        "        np.mean([m['val_mae'] for m in metrics_cnn]),\n",
        "        np.mean([m['val_mae'] for m in metrics_tcn]),\n",
        "        np.mean([m['val_mae'] for m in metrics_crnn])\n",
        "    ]\n",
        "}\n",
        "mae_df = pd.DataFrame(mae_data)\n",
        "\n",
        "print(\"Mean MAE for each model:\")\n",
        "display(mae_df)\n",
        "\n",
        "# If labels are available, create a table with other metrics\n",
        "if HAS_LABELS and 'y_full' in globals() and y_full is not None:\n",
        "    metrics_data = {\n",
        "        'Model': ['PCA', 'CNN-AE', 'TCN-AE', 'CNN-RNN-CNN'],\n",
        "        'Accuracy': [res_pca['acc'], res_cnn['acc'], res_tcn['acc'], res_crnn['acc']],\n",
        "        'F1-score': [res_pca['f1'], res_cnn['f1'], res_tcn['f1'], res_crnn['f1']],\n",
        "        'AUC': [res_pca['auc'], res_cnn['auc'], res_tcn['auc'], res_crnn['auc']],\n",
        "        'Recall': [res_pca['recall'], res_cnn['recall'], res_tcn['recall'], res_crnn['recall']],\n",
        "        'Precision': [res_pca['precision'], res_cnn['precision'], res_tcn['precision'], res_crnn['precision']]\n",
        "    }\n",
        "    metrics_df = pd.DataFrame(metrics_data)\n",
        "\n",
        "    print(\"\\nOther metrics for each model:\")\n",
        "    display(metrics_df)\n",
        "\n",
        "# Create a bar chart for mean MAE\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='Model', y='Mean MAE', data=mae_df)\n",
        "plt.title('Mean MAE for Anomaly Detection Models')\n",
        "plt.ylabel('Mean MAE')\n",
        "plt.show()\n",
        "\n",
        "# If labels are available, create bar charts for other metrics\n",
        "if HAS_LABELS and 'y_full' in globals() and y_full is not None:\n",
        "    metrics_df_melted = metrics_df.melt(id_vars='Model', var_name='Metric', value_name='Score')\n",
        "\n",
        "    g = sns.catplot(x='Model', y='Score', col='Metric', data=metrics_df_melted, kind='bar', col_wrap=3, height=4, sharey=False)\n",
        "    g.fig.suptitle('Performance Metrics for Anomaly Detection Models', y=1.02)\n",
        "    g.set_titles(\"{col_name}\")\n",
        "    plt.show()"
      ],
      "id": "f45a8a78",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean MAE for each model:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Model  Mean MAE\n",
              "0          PCA  0.031523\n",
              "1       CNN-AE  0.077064\n",
              "2       TCN-AE  0.076320\n",
              "3  CNN-RNN-CNN  0.049697"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d099c4fd-c37a-4a97-a36a-37da60174a4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Mean MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCA</td>\n",
              "      <td>0.031523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN-AE</td>\n",
              "      <td>0.077064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCN-AE</td>\n",
              "      <td>0.076320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN-RNN-CNN</td>\n",
              "      <td>0.049697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d099c4fd-c37a-4a97-a36a-37da60174a4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d099c4fd-c37a-4a97-a36a-37da60174a4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d099c4fd-c37a-4a97-a36a-37da60174a4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d5677b3-233a-4964-ba50-cce098ce50b2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d5677b3-233a-4964-ba50-cce098ce50b2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d5677b3-233a-4964-ba50-cce098ce50b2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4ff513ed-66e0-4e59-bce6-945db600b394\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('mae_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4ff513ed-66e0-4e59-bce6-945db600b394 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('mae_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mae_df",
              "summary": "{\n  \"name\": \"mae_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"CNN-AE\",\n          \"CNN-RNN-CNN\",\n          \"PCA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02211590325853902,\n        \"min\": 0.03152331764959513,\n        \"max\": 0.07706428319215775,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.07706428319215775,\n          0.04969687778502703,\n          0.03152331764959513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Other metrics for each model:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         Model  Accuracy  F1-score       AUC    Recall  Precision\n",
              "0          PCA  0.091860  0.036268  0.524716  0.019905   0.481818\n",
              "1       CNN-AE  0.559302  0.654708  0.411997  0.574944   0.872474\n",
              "2       TCN-AE  0.424419  0.507852  0.483184  0.427106   0.895722\n",
              "3  CNN-RNN-CNN  0.624419  0.719882  0.511648  0.642480   0.920634"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47403721-f733-411a-ac8c-1f5d16f57362\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1-score</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PCA</td>\n",
              "      <td>0.091860</td>\n",
              "      <td>0.036268</td>\n",
              "      <td>0.524716</td>\n",
              "      <td>0.019905</td>\n",
              "      <td>0.481818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CNN-AE</td>\n",
              "      <td>0.559302</td>\n",
              "      <td>0.654708</td>\n",
              "      <td>0.411997</td>\n",
              "      <td>0.574944</td>\n",
              "      <td>0.872474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCN-AE</td>\n",
              "      <td>0.424419</td>\n",
              "      <td>0.507852</td>\n",
              "      <td>0.483184</td>\n",
              "      <td>0.427106</td>\n",
              "      <td>0.895722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CNN-RNN-CNN</td>\n",
              "      <td>0.624419</td>\n",
              "      <td>0.719882</td>\n",
              "      <td>0.511648</td>\n",
              "      <td>0.642480</td>\n",
              "      <td>0.920634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47403721-f733-411a-ac8c-1f5d16f57362')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47403721-f733-411a-ac8c-1f5d16f57362 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47403721-f733-411a-ac8c-1f5d16f57362');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-33a4cee1-f5a4-4cde-97c6-280b7c4438bc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33a4cee1-f5a4-4cde-97c6-280b7c4438bc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-33a4cee1-f5a4-4cde-97c6-280b7c4438bc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3eb4e6a8-57bc-4abf-b86a-209aa1bd2860\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3eb4e6a8-57bc-4abf-b86a-209aa1bd2860 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metrics_df",
              "summary": "{\n  \"name\": \"metrics_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"CNN-AE\",\n          \"CNN-RNN-CNN\",\n          \"PCA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23719695210287553,\n        \"min\": 0.09186046511627907,\n        \"max\": 0.6244186046511628,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5593023255813953,\n          0.6244186046511628,\n          0.09186046511627907\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3086206873428611,\n        \"min\": 0.03626753058125607,\n        \"max\": 0.7198819943138873,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.6547082296367865,\n          0.7198819943138873,\n          0.03626753058125607\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05033970336756382,\n        \"min\": 0.4119974240797637,\n        \"max\": 0.5247158761028443,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.4119974240797637,\n          0.5116477786790166,\n          0.5247158761028443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2790287059440093,\n        \"min\": 0.019905072344171208,\n        \"max\": 0.6424802707335161,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.5749441579041227,\n          0.6424802707335161,\n          0.019905072344171208\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2081600721902437,\n        \"min\": 0.4818181818181818,\n        \"max\": 0.9206335986474945,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8724739733094948,\n          0.9206335986474945,\n          0.4818181818181818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1211.11x800 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}